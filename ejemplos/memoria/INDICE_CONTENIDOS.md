# √çndice de Contenidos - M√≥dulo Memoria y Contexto

√çndice completo de ejemplos y recursos educativos sobre memoria y contexto en agentes de IA.

---

## üìÅ Estructura de Archivos

```
ejemplos/memoria/
‚îú‚îÄ‚îÄ 01_tipos_memoria.py            # 5 tipos de memoria (neurobiol√≥gicos)
‚îú‚îÄ‚îÄ 02_gestion_estado.py           # Estado + Event Sourcing + Persistencia
‚îú‚îÄ‚îÄ 03_buffer_contexto.py          # Buffer de contexto + L√≠mites LLMs
‚îú‚îÄ‚îÄ 04_embeddings_busqueda.py      # Embeddings + B√∫squeda Sem√°ntica
‚îú‚îÄ‚îÄ 05_rag_retrieval.py            # RAG (Retrieval-Augmented Generation)
‚îú‚îÄ‚îÄ 06_memoria_conversacional.py   # Conversaci√≥n + NER + Privacidad
‚îú‚îÄ‚îÄ 07_memoria_jerarquica.py       # Arquitectura Jer√°rquica + Consolidaci√≥n
‚îú‚îÄ‚îÄ README.md                        # Gu√≠a principal (100+ l√≠neas)
‚îî‚îÄ‚îÄ INDICE_CONTENIDOS.md           # Este archivo
```

**Total**: 7 ejemplos funcionales + 156 KB de c√≥digo educativo

---

## üéì Correlaci√≥n con Temario

### M√≥dulo 1: Tipos de Memoria en Agentes
**Archivo**: `01_tipos_memoria.py`

Implementa:
- ‚úì Memoria sensorial (milisegundos, gran capacidad)
- ‚úì Memoria de trabajo (4-7 items, limitada)
- ‚úì Memoria epis√≥dica (eventos cronol√≥gicos)
- ‚úì Memoria sem√°ntica (conocimiento abstracto)
- ‚úì Memoria procedural (habilidades)

Clases principales:
- `MemoriaSensorial`: Buffer con expiraci√≥n temporal
- `MemoriaTrabajoLimitada`: Capacidad limitada + envejecimiento
- `MemoriaEpisodica`: Timeline de eventos
- `MemoriaSemantica`: Grafo de conocimiento (hechos + relaciones)
- `MemoriaProcedural`: Habilidades con mejora

**Tiempo aprendizaje**: ~30 minutos
**C√≥digo**: ~400 l√≠neas
**Conceptos**: 5 tipos neurobiol√≥gicos de memoria

---

### M√≥dulo 2: Gesti√≥n de Estado en Agentes
**Archivo**: `02_gestion_estado.py`

Implementa:
- ‚úì Representaci√≥n de estado (identidad, posici√≥n, recursos, objetivos, creencias)
- ‚úì Estado local vs compartido
- ‚úì Persistencia y recuperaci√≥n
- ‚úì Serializaci√≥n a JSON
- ‚úì Event sourcing (registro inmutable)
- ‚úì Versionado de estado

Clases principales:
- `Identidad`: ID, nombre, tipo, versi√≥n
- `EstadoAgenteLLM`: Estado completo multicomponente
- `Evento`: Para event sourcing
- `PersistenciaEstado`: Guardado/carga de snapshots

**Tiempo aprendizaje**: ~30 minutos
**C√≥digo**: ~450 l√≠neas
**Conceptos**: State management, event sourcing, persistencia

---

### M√≥dulo 3: Memoria a Corto Plazo y Contexto
**Archivo**: `03_buffer_contexto.py`

Implementa:
- ‚úì Buffer de contexto (ventana m√≥vil)
- ‚úì L√≠mites de contexto en LLMs
- ‚úì Selecci√≥n de informaci√≥n relevante
- ‚úì 4 estrategias de eliminaci√≥n (FIFO, LRU, importancia, relevancia)
- ‚úì Compresi√≥n de contexto

Clases principales:
- `BufferContexto`: Buffer circular con l√≠mite de tokens
- `ItemContexto`: Item con importancia, accesos, envejecimiento
- `CompresorContexto`: Resumen y compresi√≥n
- Enums: `EstrategiaEliminacion`

**Tiempo aprendizaje**: ~25 minutos
**C√≥digo**: ~350 l√≠neas
**Conceptos**: Context windows, token limits, compression strategies

---

### M√≥dulo 4: Memoria a Largo Plazo
**Archivos**: `04_embeddings_busqueda.py`, `05_rag_retrieval.py`

#### 04 - Embeddings y B√∫squeda Sem√°ntica
Implementa:
- ‚úì Generaci√≥n de embeddings (TF-IDF simplificado)
- ‚úì B√∫squeda vectorial (similitud coseno)
- ‚úì B√∫squeda por palabras clave (Jaccard)
- ‚úì B√∫squeda h√≠brida (combinada)
- ‚úì Indexaci√≥n de documentos

Clases principales:
- `GeneradorEmbeddings`: Conversi√≥n texto ‚Üí vectores
- `IndiceVectorial`: √çndice de b√∫squeda
- `BuscadorHibrido`: Combina keyword + semantic
- `CalculadorSimilitud`: Coseno, Jaccard, Euclidiana

**Tiempo aprendizaje**: ~40 minutos
**C√≥digo**: ~380 l√≠neas
**Conceptos**: Embeddings, similarity search, hybrid search

#### 05 - RAG (Retrieval-Augmented Generation)
Implementa:
- ‚úì Pipeline RAG completo (5 pasos)
- ‚úì Base de conocimiento
- ‚úì Recuperaci√≥n de documentos
- ‚úì Construcci√≥n de contexto
- ‚úì Enriquecimiento de prompts
- ‚úì Generaci√≥n de respuestas

Clases principales:
- `BaseConocimiento`: Almac√©n de documentos
- `PipelineRAG`: Orquestaci√≥n del flujo
- `DocumentoFuente`: Con metadata y tipo de fuente

**Tiempo aprendizaje**: ~35 minutos
**C√≥digo**: ~420 l√≠neas
**Conceptos**: RAG pipeline, information retrieval, prompt engineering

---

### M√≥dulo 5: Recuperaci√≥n de Informaci√≥n Relevante
**Archivo**: `04_embeddings_busqueda.py` (secci√≥n b√∫squeda h√≠brida)

Implementa:
- ‚úì Algoritmos de b√∫squeda (BM25 simulado, TF-IDF, vectorial)
- ‚úì Ranking de relevancia
- ‚úì Filtrado y pre-filtrado
- ‚úì Consultas multi-criterio
- ‚úì M√©tricas de similitud

---

### M√≥dulo 6: Memoria en Agentes Conversacionales
**Archivo**: `06_memoria_conversacional.py`

Implementa:
- ‚úì Historial de conversaci√≥n
- ‚úì Seguimiento de entidades (NER b√°sica)
- ‚úì Resoluci√≥n de referencias anaf√≥ricas
- ‚úì Personalizaci√≥n basada en memoria
- ‚úì Cumplimiento de privacidad (GDPR)
- ‚úì Filtrado de datos sensibles

Clases principales:
- `HistorialConversacion`: Gesti√≥n de turnos
- `SeguimientoEntidades`: NER y coreference resolution
- `Mensaje`: Con entidades y referencias resueltas
- Tipos: Email, tel√©fono, productos, fechas

**Tiempo aprendizaje**: ~30 minutos
**C√≥digo**: ~400 l√≠neas
**Conceptos**: Conversational AI, NER, anaphora resolution, privacy

---

### M√≥dulo 7: Arquitecturas de Memoria Avanzadas
**Archivo**: `07_memoria_jerarquica.py`

Implementa:
- ‚úì Memoria jer√°rquica en 3 niveles
- ‚úì Consolidaci√≥n de memoria (epis√≥dico ‚Üí t√°ctico ‚Üí estrat√©gico)
- ‚úì Olvido adaptativo
- ‚úì Compresi√≥n autom√°tica
- ‚úì Interferencia y recuperaci√≥n
- ‚úì Event-driven consolidation

Clases principales:
- `MemoriaJerarquica`: Gestor de 3 niveles
- `RegistroEpisodico`: Detalles espec√≠ficos
- `PatronTactico`: Patrones frecuentes
- `ReglaBstracia`: Reglas generalizadas

**Tiempo aprendizaje**: ~40 minutos
**C√≥digo**: ~420 l√≠neas
**Conceptos**: Hierarchical memory, consolidation, adaptive forgetting

---

## üöÄ Gu√≠a de Ejecuci√≥n Recomendada

### Para Principiantes (Orden sugerido)

1. **D√≠a 1**: Ejecutar `01_tipos_memoria.py`
   - Comprender fundamentos biol√≥gicos
   - Ejecutar: `python 01_tipos_memoria.py`
   - Tiempo: 20 minutos

2. **D√≠a 2**: Ejecutar `02_gestion_estado.py`
   - Entender persistencia de estado
   - Ejecutar: `python 02_gestion_estado.py`
   - Tiempo: 25 minutos

3. **D√≠a 3**: Ejecutar `03_buffer_contexto.py`
   - Problema pr√°ctico de l√≠mites
   - Ejecutar: `python 03_buffer_contexto.py`
   - Tiempo: 20 minutos

4. **D√≠a 4**: Ejecutar `04_embeddings_busqueda.py`
   - Fundamentos de b√∫squeda sem√°ntica
   - Ejecutar: `python 04_embeddings_busqueda.py`
   - Tiempo: 25 minutos

5. **D√≠a 5**: Ejecutar `05_rag_retrieval.py`
   - Aplicaci√≥n pr√°ctica RAG
   - Ejecutar: `python 05_rag_retrieval.py`
   - Tiempo: 25 minutos

6. **D√≠a 6**: Ejecutar `06_memoria_conversacional.py`
   - Conversaciones coherentes
   - Ejecutar: `python 06_memoria_conversacional.py`
   - Tiempo: 20 minutos

7. **D√≠a 7**: Ejecutar `07_memoria_jerarquica.py`
   - Arquitectura avanzada
   - Ejecutar: `python 07_memoria_jerarquica.py`
   - Tiempo: 25 minutos

**Total**: ~2 horas de ejecuci√≥n + comprensi√≥n te√≥rica

### Para Avanzados

Ejecutar en paralelo o modificar seg√∫n necesidad:

```bash
# Crear agente que combine todos
python -c "
# Importar todas las clases
from 01_tipos_memoria import *
from 02_gestion_estado import *
# ... etc
# Crear agente complejo
"
```

---

## üìä Estad√≠sticas de C√≥digo

| Archivo | L√≠neas | Clases | Funciones | Complejidad |
|---------|--------|--------|-----------|-------------|
| 01_tipos_memoria.py | 410 | 5 | 35+ | ‚≠ê‚≠ê |
| 02_gestion_estado.py | 450 | 10 | 40+ | ‚≠ê‚≠ê |
| 03_buffer_contexto.py | 350 | 3 | 25+ | ‚≠ê‚≠ê |
| 04_embeddings_busqueda.py | 380 | 4 | 30+ | ‚≠ê‚≠ê‚≠ê |
| 05_rag_retrieval.py | 420 | 4 | 28+ | ‚≠ê‚≠ê‚≠ê |
| 06_memoria_conversacional.py | 400 | 3 | 30+ | ‚≠ê‚≠ê |
| 07_memoria_jerarquica.py | 420 | 4 | 35+ | ‚≠ê‚≠ê‚≠ê |
| **TOTAL** | **2,830** | **33** | **223+** | - |

---

## üîß Configuraci√≥n T√©cnica

### Dependencias M√≠nimas
```bash
pip install pydantic  # Para dataclasses
```

### Dependencias Opcionales (para integraci√≥n)
```bash
pip install langchain ollama sentence-transformers numpy scikit-learn
```

### Requisitos de Sistema
- Python 3.8+
- 50 MB de espacio en disco
- Sin dependencias externas para ejemplos 1-7

---

## üíª Uso en Producci√≥n

Cada ejemplo es adaptable a producci√≥n:

### Reemplazar componentes:

1. **Embeddings**: GeneradorEmbeddings ‚Üí SentenceTransformer
2. **B√∫squeda**: IndiceVectorial ‚Üí Pinecone/Weaviate/Chroma
3. **LLM**: Respuesta simulada ‚Üí Ollama/OpenAI/Anthropic
4. **Storage**: JSON ‚Üí PostgreSQL/MongoDB

Ejemplo de integraci√≥n:
```python
# Reemplazar
from sentence_transformers import SentenceTransformer
model = SentenceTransformer('all-MiniLM-L6-v2')

# En GeneradorEmbeddings
def generar_embedding(self, texto):
    return model.encode(texto).tolist()
```

---

## üìö Recursos de Referencia

### Conceptos Clave por Archivo

**01_tipos_memoria.py**:
- Inspiration from neuroscience (Baddeley, Atkinson-Shiffrin)
- Working memory limitation (Magic number 7¬±2)
- Episodic vs semantic memory distinction

**02_gestion_estado.py**:
- Event sourcing pattern
- CQRS (Command Query Responsibility Segregation)
- State machines and transitions

**03_buffer_contexto.py**:
- Sliding window algorithms
- LRU cache policies
- Context compression

**04_embeddings_busqueda.py**:
- TF-IDF (Term Frequency-Inverse Document Frequency)
- Vector similarity metrics
- Hybrid search combining signals

**05_rag_retrieval.py**:
- Information Retrieval (IR) basics
- Prompt engineering
- Knowledge augmentation

**06_memoria_conversacional.py**:
- Coreference resolution (anaphora)
- Named Entity Recognition (NER)
- Privacy-preserving techniques (GDPR)

**07_memoria_jerarquica.py**:
- Levels of abstraction
- Consolidation mechanisms
- Adaptive forgetting (importance-weighted)

---

## üéØ Casos de Uso por Archivo

### 01 - Tipos de Memoria
**Usar para**:
- Entender arquitectura cognitiva
- Dise√±ar sistemas multi-escala
- Educaci√≥n

**Casos reales**:
- Sistema de sensor ‚Üí procesamiento ‚Üí respuesta
- Web scraping ‚Üí √≠ndice ‚Üí queries
- Chat ‚Üí context ‚Üí generation

### 02 - Gesti√≥n de Estado
**Usar para**:
- Persistencia de agentes
- Auditor√≠a y cumplimiento
- Recuperaci√≥n de fallos

**Casos reales**:
- Agentes de trading
- Bots conversacionales con memoria
- Sistemas de recomendaci√≥n stateful

### 03 - Buffer de Contexto
**Usar para**:
- Aplicaciones con l√≠mites de contexto
- Gesti√≥n de memoria en embeddings
- Compresi√≥n de informaci√≥n

**Casos reales**:
- ChatGPT-like applications
- Long document processing
- Real-time monitoring systems

### 04 - Embeddings y B√∫squeda
**Usar para**:
- Semantic search
- Document similarity
- Recommendation systems

**Casos reales**:
- E-commerce search
- Document repositories
- Content recommendation

### 05 - RAG
**Usar para**:
- Reducir alucinaciones
- Domain-specific QA
- Knowledge base integration

**Casos reales**:
- Customer support bots
- Technical documentation systems
- Internal knowledge bases

### 06 - Memoria Conversacional
**Usar para**:
- Multi-turn dialogues
- Personalized responses
- Privacy-compliant systems

**Casos reales**:
- Virtual assistants
- Chatbots
- Customer service systems

### 07 - Memoria Jer√°rquica
**Usar para**:
- Escalabilidad
- Pattern recognition
- Long-term learning

**Casos reales**:
- Learning systems
- Complex agent architectures
- Knowledge consolidation

---

## ‚úÖ Checklist Completo de Aprendizaje

### Conceptual (Teor√≠a)
- [ ] Entiendo 5 tipos de memoria humana
- [ ] S√© diferenciar epis√≥dico vs sem√°ntico
- [ ] Conozco limitaciones de transformers (O(n¬≤))
- [ ] Entiendo RAG y por qu√© reduce alucinaciones
- [ ] S√© qu√© es coreference resolution

### Pr√°ctico (C√≥digo)
- [ ] Ejecut√© todos los 7 ejemplos
- [ ] Modifiqu√© par√°metros en cada ejemplo
- [ ] Entiendo cada clase principal
- [ ] Puedo explicar flujos de datos
- [ ] Combino ejemplos en c√≥digo personalizado

### Aplicaci√≥n (Producci√≥n)
- [ ] Adapt√© ejemplos a mi caso de uso
- [ ] Integr√© con Ollama/LangChain
- [ ] Consider√© privacidad (GDPR)
- [ ] Optimic√© para rendimiento
- [ ] Document√© mis cambios

---

## üìû Preguntas Frecuentes

**P: ¬øCu√°l ejemplo debo aprender primero?**
R: Comienza con `01_tipos_memoria.py` para fundamentos

**P: ¬øPuedo combinar m√∫ltiples ejemplos?**
R: S√≠, la arquitectura es modular. Ver ejemplo 7 como referencia

**P: ¬øC√≥mo integro con mi modelo LLM?**
R: Reemplaza la funci√≥n `_generar_respuesta()` en ejemplo 5

**P: ¬øSon estos ejemplos production-ready?**
R: Son educativos, pero estructurados para facilitar adaptaci√≥n

**P: ¬øQu√© modelo de Ollama recomiendan?**
R: Comienza con `mistral` (r√°pido, buena relaci√≥n) o `neural-chat` (optimizado)

---

## üìñ Referencias Bibliogr√°ficas

Consulta el archivo `02-memoria-contexto.adoc` (l√≠neas 511-532) para:
- Libros recomendados (Russell & Norvig, Goodfellow et al., Baddeley)
- Papers acad√©micos (Attention is All You Need, RAG papers, Memory Networks)
- Librer√≠as espec√≠ficas (sentence-transformers, pinecone, langchain)

---

## üèÜ Objetivos de Aprendizaje (Alcanzados)

Al completar estos 7 ejemplos, habr√°s alcanzado todos los objetivos de aprendizaje del m√≥dulo:

‚úÖ M√≥dulo 1: Entender taxonom√≠a de memoria y distinguir tipos
‚úÖ M√≥dulo 2: Representar estado de agente y persistirlo
‚úÖ M√≥dulo 3: Dise√±ar buffers de contexto y manejar l√≠mites
‚úÖ M√≥dulo 4: Almacenar y recuperar informaci√≥n a largo plazo
‚úÖ M√≥dulo 5: Implementar algoritmos de ranking y b√∫squeda
‚úÖ M√≥dulo 6: Mantener coherencia conversacional
‚úÖ M√≥dulo 7: Dise√±ar arquitecturas jer√°rquicas

---

**Documento actualizado**: Noviembre 2024
**Versi√≥n**: 1.0
**Autores**: Ejemplos educativos del Curso de Agentes de IA
