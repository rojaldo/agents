# ğŸš€ Langflow - Quick Start Guide

## En 5 Minutos

### Paso 1: Validar (sin instalar nada)
```bash
cd /home/rojaldo/cursos/agents/ejemplos/langflow
python test_syntax.py
```
**Resultado esperado:** âœ… Todos los archivos son vÃ¡lidos

### Paso 2: Instalar dependencias mÃ­nimas
```bash
pip install langchain-core langchain-community
```

### Paso 3: Instalar Ollama (una sola vez)
```bash
# Linux/macOS
curl https://ollama.ai/install.sh | sh

# Descargar modelo
ollama pull mistral
```

### Paso 4: Ejecutar ejemplo
```bash
# Terminal 1: Iniciar Ollama
ollama serve

# Terminal 2: Ejecutar ejemplo
python 01_chatbot_simple.py
```

---

## ğŸ“š Ejemplos Quick Reference

### Ejemplo 1: Chat Simple
```bash
python 01_chatbot_simple.py
```
**AprenderÃ¡s:** Prompts, memoria, conversaciones

### Ejemplo 2: Integraciones
```bash
python 02_componentes_integracion.py
```
**AprenderÃ¡s:** Web search, APIs, JSON parsing

### Ejemplo 3: RAG
```bash
python 03_rag_document_processing.py
```
**AprenderÃ¡s:** Embeddings, vector stores, RAG

### Ejemplo 4: Patrones
```bash
python 04_patrones_avanzados.py
```
**AprenderÃ¡s:** Routing, fallbacks, error handling

### Ejemplo 5: API
```bash
python 05_exportacion_api.py
```
**AprenderÃ¡s:** FastAPI, autenticaciÃ³n, monitoreo

### Ejemplo 6: Proyecto Final
```bash
python 06_proyecto_final.py
```
**AprenderÃ¡s:** Arquitectura integrada

---

## ğŸ¯ Ruta de Aprendizaje (Recomendada)

**DÃ­a 1 (2-3 horas):**
1. âœ… Validar con `test_syntax.py`
2. âœ… Ejecutar `01_chatbot_simple.py`
3. âœ… Ejecutar `02_componentes_integracion.py`

**DÃ­a 2 (2-3 horas):**
1. âœ… Ejecutar `03_rag_document_processing.py`
2. âœ… Ejecutar `04_patrones_avanzados.py`

**DÃ­a 3 (2-3 horas):**
1. âœ… Ejecutar `05_exportacion_api.py`
2. âœ… Ejecutar `06_proyecto_final.py`

**Total:** 6-9 horas

---

## ğŸ” Conceptos Clave

### 1. Prompts
```python
prompt = ChatPromptTemplate.from_messages([
    ("system", "Eres un asistente Ãºtil"),
    ("user", "{input}")
])
cadena = prompt | llm
respuesta = cadena.invoke({"input": "Â¿Hola?"})
```

### 2. Memoria
```python
memoria = ConversationBufferMemory(return_messages=True)
historial = memoria.load_memory_variables({})
# ... usar historial
memoria.save_context({"input": entrada}, {"output": respuesta})
```

### 3. Web Search
```python
search = DuckDuckGoSearchRun()
resultados = search.run("Â¿QuÃ© tiempo hace?")
```

### 4. RAG
```python
from langchain_community.vectorstores import FAISS
vector_store = FAISS.from_documents(documentos, embeddings)
docs = vector_store.similarity_search(query, k=2)
```

### 5. Error Handling
```python
try:
    respuesta = cadena.invoke({...})
except TimeoutError:
    respuesta = "Timeout"
except Exception as e:
    respuesta = f"Error: {e}"
```

---

## ğŸ“Š Estructura de Archivos

```
ejemplos/langflow/
â”œâ”€â”€ 01_chatbot_simple.py          â† Comienza aquÃ­
â”œâ”€â”€ 02_componentes_integracion.py
â”œâ”€â”€ 03_rag_document_processing.py
â”œâ”€â”€ 04_patrones_avanzados.py
â”œâ”€â”€ 05_exportacion_api.py
â”œâ”€â”€ 06_proyecto_final.py
â”œâ”€â”€ test_syntax.py                â† Valida primero
â”œâ”€â”€ README.md                     â† DocumentaciÃ³n completa
â””â”€â”€ SUMMARY.md                    â† Resumen detallado
```

---

## â“ Preguntas Frecuentes

**P: Â¿Puedo ejecutar ejemplos sin Ollama?**
R: SÃ­, con `test_syntax.py`. Para los demÃ¡s ejemplos necesitas Ollama.

**P: Â¿Puedo usar ChatGPT en lugar de Ollama?**
R: SÃ­, modifica el LLM en los ejemplos:
```python
from langchain_openai import ChatOpenAI
llm = ChatOpenAI(api_key="...", model="gpt-4")
```

**P: Â¿DÃ³nde estÃ¡ la documentaciÃ³n?**
R:
- TeorÃ­a: `docs/langflow.adoc` (1,870 lÃ­neas)
- Resumen: `SUMMARY.md` (este archivo)
- Completa: `README.md`

**P: Â¿CuÃ¡nto tiempo toma completar?**
R: 6-9 horas (1-2 horas por mÃ³dulo)

**P: Â¿Hay certificado?**
R: No, pero aprenderÃ¡s habilidades productivas.

---

## ğŸ”§ Troubleshooting

| Problema | SoluciÃ³n |
|----------|----------|
| `ModuleNotFoundError` | `pip install langchain-core langchain-community` |
| Ollama no responde | AsegÃºrate que `ollama serve` estÃ¡ ejecutÃ¡ndose |
| Error de timeout | Aumenta timeout en cÃ³digo o espera mÃ¡s |
| Error de embedding | Descarga modelo: `ollama pull mistral` |

---

## ğŸ“– Recursos Adicionales

- **DocumentaciÃ³n oficial:** https://docs.langchain.com
- **Ollama:** https://ollama.ai
- **Langflow:** https://github.com/logspace-ai/langflow
- **LangChain:** https://github.com/langchain-ai/langchain

---

## âœ¨ PrÃ³ximos Pasos

1. **Completar ejemplos** (1-3 dÃ­as)
2. **Modificar ejemplos** para tus casos de uso
3. **Crear proyecto propio** usando patrones aprendidos
4. **Desplegar API** usando ejemplo 05 como base

---

## ğŸ“ Notas

- Todos los ejemplos usan **Ollama local** (http://localhost:11434)
- CÃ³digo con **patrones profesionales** (tipo hints, logging, error handling)
- **100% validado** - sintaxis correcta garantizada
- **Totalmente extensible** - personaliza segÃºn necesites

---

**Â¡Listo para empezar!** ğŸš€

Ejecuta: `python test_syntax.py` â†’ `python 01_chatbot_simple.py`
