<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.26">
<title>Curso Completo de AutoGen</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ul.square{list-style-type:square}
ul.circle ul:not([class]),ul.disc ul:not([class]),ul.square ul:not([class]){list-style:inherit}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child{border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:first-child,.sidebarblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child,.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock pre>code{display:block}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active,#footnotes .footnote a:first-of-type:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,td.hdlist1,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/atom-one-light.min.css">
</head>
<body class="book">
<div id="header">
<h1>Curso Completo de AutoGen</h1>
<div id="toc" class="toc">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_módulo_1_introducción_a_autogen">1. Módulo 1: Introducción a AutoGen</a>
<ul class="sectlevel2">
<li><a href="#_1_1_qué_es_autogen">1.1. 1.1. ¿Qué es AutoGen?</a>
<ul class="sectlevel3">
<li><a href="#_definición">1.1.1. Definición</a></li>
<li><a href="#_propósito_y_filosofía">1.1.2. Propósito y Filosofía</a></li>
<li><a href="#_historia_y_evolución">1.1.3. Historia y Evolución</a></li>
<li><a href="#_casos_de_uso_principales">1.1.4. Casos de Uso Principales</a></li>
<li><a href="#_ventajas_detalladas">1.1.5. Ventajas Detalladas</a></li>
<li><a href="#_limitaciones_honestas">1.1.6. Limitaciones Honestas</a></li>
<li><a href="#_conclusión_del_módulo_1">1.1.7. Conclusión del Módulo 1</a></li>
</ul>
</li>
<li><a href="#_1_2_arquitectura_de_autogen">1.2. 1.2. Arquitectura de AutoGen</a>
<ul class="sectlevel3">
<li><a href="#_conceptos_fundamentales">1.2.1. Conceptos Fundamentales</a></li>
<li><a href="#_tipos_de_agentes_y_sus_características">1.2.2. Tipos de Agentes y sus Características</a></li>
<li><a href="#_flujos_de_comunicación">1.2.3. Flujos de Comunicación</a></li>
<li><a href="#_modelos_de_lenguaje_soportados">1.2.4. Modelos de Lenguaje Soportados</a></li>
</ul>
</li>
<li><a href="#_1_3_instalación_y_configuración">1.3. 1.3. Instalación y Configuración</a>
<ul class="sectlevel3">
<li><a href="#_requisitos_previos">1.3.1. Requisitos Previos</a></li>
<li><a href="#_instalación_paso_a_paso">1.3.2. Instalación Paso a Paso</a></li>
<li><a href="#_configuración_de_proveedores">1.3.3. Configuración de Proveedores</a></li>
<li><a href="#_entorno_de_desarrollo_recomendado">1.3.4. Entorno de Desarrollo Recomendado</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_2_fundamentos_de_agentes">2. Módulo 2: Fundamentos de Agentes</a>
<ul class="sectlevel2">
<li><a href="#_2_1_agentes_básicos">2.1. 2.1. Agentes Básicos</a>
<ul class="sectlevel3">
<li><a href="#_assistantagent_detallado">2.1.1. AssistantAgent - Detallado</a></li>
<li><a href="#_userproxyagent_detallado">2.1.2. UserProxyAgent - Detallado</a></li>
<li><a href="#_agentes_personalizados">2.1.3. Agentes Personalizados</a></li>
</ul>
</li>
<li><a href="#_2_2_conversaciones_entre_agentes">2.2. 2.2. Conversaciones entre Agentes</a>
<ul class="sectlevel3">
<li><a href="#_iniciación_de_conversaciones">2.2.1. Iniciación de Conversaciones</a></li>
<li><a href="#_flujos_de_comunicación_avanzados">2.2.2. Flujos de Comunicación Avanzados</a></li>
</ul>
</li>
<li><a href="#_2_3_configuración_avanzada">2.3. 2.3. Configuración Avanzada</a>
<ul class="sectlevel3">
<li><a href="#_parámetros_de_configuración_completos">2.3.1. Parámetros de Configuración Completos</a></li>
<li><a href="#_gestión_de_contexto">2.3.2. Gestión de Contexto</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_3_patrones_de_conversación">3. Módulo 3: Patrones de Conversación</a>
<ul class="sectlevel2">
<li><a href="#_3_1_conversaciones_dos_agentes">3.1. 3.1. Conversaciones Dos Agentes</a>
<ul class="sectlevel3">
<li><a href="#_patrón_pregunta_respuesta">3.1.1. Patrón Pregunta-Respuesta</a></li>
<li><a href="#_resolución_de_problemas_iterativa">3.1.2. Resolución de Problemas Iterativa</a></li>
<li><a href="#_validación_de_respuestas">3.1.3. Validación de Respuestas</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_4_capacidades_avanzadas">4. Módulo 4: Capacidades Avanzadas</a>
<ul class="sectlevel2">
<li><a href="#_4_1_ejecución_de_código">4.1. 4.1. Ejecución de Código</a>
<ul class="sectlevel3">
<li><a href="#_code_execution_segura">4.1.1. Code Execution Segura</a></li>
<li><a href="#_manejo_avanzado_de_errores_en_code_execution">4.1.2. Manejo Avanzado de Errores en Code Execution</a></li>
<li><a href="#_mejores_prácticas_en_code_execution">4.1.3. Mejores Prácticas en Code Execution</a></li>
</ul>
</li>
<li><a href="#_4_2_function_calling">4.2. 4.2. Function Calling</a>
<ul class="sectlevel3">
<li><a href="#_definición_y_registro_de_funciones">4.2.1. Definición y Registro de Funciones</a></li>
<li><a href="#_invocación_automática_de_funciones">4.2.2. Invocación Automática de Funciones</a></li>
<li><a href="#_parámetros_y_esquemas">4.2.3. Parámetros y Esquemas</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#_módulo_5_agentes_especializados">5. Módulo 5: Agentes Especializados</a>
<ul class="sectlevel2">
<li><a href="#_5_1_agentes_personalizados_avanzados">5.1. 5.1. Agentes Personalizados Avanzados</a>
<ul class="sectlevel3">
<li><a href="#_creación_de_clases_de_agentes">5.1.1. Creación de Clases de Agentes</a></li>
<li><a href="#_patrones_de_diseño">5.1.2. Patrones de Diseño</a></li>
</ul>
</li>
<li><a href="#_5_2_agentes_multi_modalidad">5.2. 5.2. Agentes Multi-Modalidad</a></li>
<li><a href="#_5_3_agentes_de_memoria_extendida">5.3. 5.3. Agentes de Memoria Extendida</a></li>
<li><a href="#_5_4_agentes_de_aprendizaje_autónomo">5.4. 5.4. Agentes de Aprendizaje Autónomo</a></li>
<li><a href="#_5_5_agentes_de_coordinación_multi_agente">5.5. 5.5. Agentes de Coordinación Multi-Agente</a></li>
</ul>
</li>
<li><a href="#_módulo_6_optimización_y_costos">6. Módulo 6: Optimización y Costos</a>
<ul class="sectlevel2">
<li><a href="#_6_1_gestión_de_tokens">6.1. 6.1. Gestión de Tokens</a></li>
<li><a href="#_6_2_caché_y_reutilización">6.2. 6.2. Caché y Reutilización</a></li>
<li><a href="#_6_3_modelos_locales">6.3. 6.3. Modelos Locales</a></li>
<li><a href="#_7_1_asistente_de_programación">6.4. 7.1. Asistente de Programación</a></li>
<li><a href="#_7_2_análisis_de_datos">6.5. 7.2. Análisis de Datos</a></li>
<li><a href="#_7_3_automatización_de_tareas">6.6. 7.3. Automatización de Tareas</a></li>
<li><a href="#_7_4_investigación_y_síntesis">6.7. 7.4. Investigación y Síntesis</a></li>
<li><a href="#_8_1_estrategias_de_testing">6.8. 8.1. Estrategias de Testing</a></li>
<li><a href="#_8_2_debugging">6.9. 8.2. Debugging</a></li>
<li><a href="#_8_3_evaluación_de_calidad">6.10. 8.3. Evaluación de Calidad</a></li>
</ul>
</li>
<li><a href="#_módulo_9_despliegue_en_producción">7. Módulo 9: Despliegue en Producción</a>
<ul class="sectlevel2">
<li><a href="#_9_1_arquitectura_de_producción">7.1. 9.1. Arquitectura de Producción</a></li>
<li><a href="#_9_2_seguridad">7.2. 9.2. Seguridad</a></li>
<li><a href="#_9_3_monitorización">7.3. 9.3. Monitorización</a></li>
<li><a href="#_9_4_cicd">7.4. 9.4. CI/CD</a></li>
</ul>
</li>
<li><a href="#_módulo_10_integraciones">8. Módulo 10: Integraciones</a>
<ul class="sectlevel2">
<li><a href="#_10_1_frameworks_y_librerías">8.1. 10.1. Frameworks y Librerías</a></li>
<li><a href="#_10_2_apis_y_servicios">8.2. 10.2. APIs y Servicios</a></li>
<li><a href="#_10_3_bases_de_datos">8.3. 10.3. Bases de Datos</a></li>
</ul>
</li>
<li><a href="#_módulo_11_proyecto_final">9. Módulo 11: Proyecto Final</a>
<ul class="sectlevel2">
<li><a href="#_11_1_definición_del_proyecto">9.1. 11.1. Definición del Proyecto</a></li>
<li><a href="#_11_2_desarrollo">9.2. 11.2. Desarrollo</a></li>
<li><a href="#_11_3_presentación">9.3. 11.3. Presentación</a></li>
</ul>
</li>
<li><a href="#_anexos">10. Anexos</a>
<ul class="sectlevel2">
<li><a href="#_a_recursos_adicionales">10.1. A. Recursos Adicionales</a></li>
<li><a href="#_b_glosario_de_términos">10.2. B. Glosario de Términos</a></li>
<li><a href="#_c_mejores_prácticas">10.3. C. Mejores Prácticas</a></li>
<li><a href="#_d_troubleshooting">10.4. D. Troubleshooting</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="content">
<div class="sect1">
<h2 id="_módulo_1_introducción_a_autogen">1. Módulo 1: Introducción a AutoGen</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_1_1_qué_es_autogen">1.1. 1.1. ¿Qué es AutoGen?</h3>
<div class="sect3">
<h4 id="_definición">1.1.1. Definición</h4>
<div class="paragraph">
<p>AutoGen es un framework de código abierto desarrollado por Microsoft que simplifica la creación de aplicaciones con Modelos de Lenguaje de Gran Escala (LLMs).</p>
</div>
<div class="ulist">
<div class="title">AutoGen proporciona una <strong>abstracción de alto nivel</strong> para trabajar con sistemas multi-agente donde los agentes pueden:</div>
<ul>
<li>
<p>Mantener conversaciones naturales entre sí</p>
</li>
<li>
<p>Compartir información y conocimiento</p>
</li>
<li>
<p>Ejecutar código de forma segura</p>
</li>
<li>
<p>Acceder a herramientas y APIs externas</p>
</li>
<li>
<p>Automatizar flujos de trabajo complejos</p>
</li>
<li>
<p>Tomar decisiones basadas en contexto</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>El concepto central es que <strong>los agentes pueden funcionar de manera autónoma o colaborativa</strong>, permitiendo patrones sofisticados de interacción sin necesidad de escribir lógica de orquestación compleja.</p>
</div>
</div>
<div class="sect3">
<h4 id="_propósito_y_filosofía">1.1.2. Propósito y Filosofía</h4>
<div class="paragraph">
<p>La filosofía de AutoGen se basa en tres principios clave:</p>
</div>
<div class="paragraph">
<p><strong>1. Simplicidad:</strong> Abstraer la complejidad de los sistemas multi-agente en APIs intuitivas</p>
</div>
<div class="paragraph">
<p><strong>2. Flexibilidad:</strong> Soportar múltiples patrones de interacción y configuraciones sin imponer estructuras rígidas</p>
</div>
<div class="paragraph">
<p><strong>3. Extensibilidad:</strong> Permitir crear agentes personalizados y comportamientos específicos del dominio</p>
</div>
</div>
<div class="sect3">
<h4 id="_historia_y_evolución">1.1.3. Historia y Evolución</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">2023 (Q1-Q2): Presentación inicial de AutoGen
  - Enfoque: sistemas conversacionales multi-agente
  - Primeros casos de uso: debugging automático y code generation
  - Comunidad académica como early adopters

2023 (Q3-Q4): Expansión de capacidades
  - Introducción: Function Calling (invocación de funciones)
  - Introducción: Ejecución de código nativa
  - Soporte para múltiples proveedores de LLM

2024 (Presente): Consolidación y optimización
  - GroupChat para coordinación de múltiples agentes
  - Optimizaciones de rendimiento y caché
  - Mejoras en manejo de errores y recuperación
  - Integración con más proveedores (Ollama, local, etc.)
  - Comunidad activa con más de 20k stars en GitHub</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_casos_de_uso_principales">1.1.4. Casos de Uso Principales</h4>
<div class="paragraph">
<p><strong>Caso 1: Asistente de Programación</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Flujo:
1. Desarrollador proporciona requisito o describe error
2. Agente generador escribe código
3. Agente tester ejecuta y verifica
4. Agente revisor analiza calidad y seguridad
5. Se itera hasta solución aceptable</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso 2: Análisis de Datos Automático</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Flujo:
1. Usuario carga dataset
2. Agente explorador examina estructura y características
3. Agente visualizador genera gráficos
4. Agente estadístico calcula métricas clave
5. Agente reportero sintetiza hallazgos</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso 3: Automatización Empresarial</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Flujo:
1. Agente lector extrae información de documentos
2. Agente procesador valida y transforma datos
3. Agente integrador comunica con sistemas legacy
4. Agente reportero notifica cambios y excepciones</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso 4: Investigación y Síntesis</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Flujo:
1. Agente investigador busca en múltiples fuentes
2. Agente evaluador verifica credibilidad
3. Agente sintetizador integra hallazgos
4. Agente crítico cuestiona conclusiones
5. Resultado: reporte balanceado y documentado</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso 5: Sistemas de Soporte Técnico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Flujo:
1. Agente clasificador entiende el problema
2. Agente diagnosticador recolecta información
3. Agente solucionador propone soluciones
4. Agente de escalación involucra expertos si necesario</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_ventajas_detalladas">1.1.5. Ventajas Detalladas</h4>
<div class="paragraph">
<p><strong>1. Abstracción Multi-Agente:</strong></p>
</div>
<div class="ulist">
<div class="title">La ventaja principal es que AutoGen oculta mucha complejidad subyacente. Sin AutoGen, coordinar múltiples agentes requeriría:</div>
<ul>
<li>
<p>Escribir manualmente lógica de routing de mensajes</p>
</li>
<li>
<p>Gestionar el historial de conversación</p>
</li>
<li>
<p>Implementar mecanismos de término</p>
</li>
<li>
<p>Sinronizar estado entre agentes</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Con AutoGen, todo esto se maneja automáticamente. Ejemplo de diferencia:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># SIN AutoGen (código manual complicado)
class ManualMultiAgentSystem:
    def __init__(self):
        self.messages = []
        self.agent_states = {}

    def send_message(self, from_agent, to_agent, content):
        msg = {
            "from": from_agent,
            "to": to_agent,
            "content": content,
            "timestamp": datetime.now()
        }
        self.messages.append(msg)
        # Lógica manual para enrutar, procesar, etc.

# CON AutoGen (código simple y limpio)
assistant = AssistantAgent(name="Asistente", llm_config=config)
user_proxy.initiate_chat(assistant, message="Hola")  # ¡Todo maneja automáticamente!</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Abstracción de temas:</div>
<ul>
<li>
<p>APIs simples y Pythónicas para conceptos complejos</p>
</li>
<li>
<p>Declarativo en lugar de imperativo</p>
</li>
<li>
<p>Menos código boilerplate</p>
</li>
<li>
<p>Mejor mantenibilidad</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>2. Flexibilidad en Proveedores:</strong></p>
</div>
<div class="paragraph">
<p>Uno de los puntos fuertes es que AutoGen soporta múltiples proveedores. Puedes cambiar de un proveedor a otro sin reescribir tu código:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># SIN AutoGen (dependencia bloqueada)
import openai
openai.api_key = "sk-..."  # Bloqueado a OpenAI

# CON AutoGen (intercambiable)
config_1 = {"model": "gpt-4", "api_key": "sk-..."}       # OpenAI
config_2 = {"model": "claude-3", "api_key": "sk-ant-..."} # Anthropic
config_3 = {"model": "mistral", "api_base": "http://localhost:11434"}  # Local

# El código es idéntico para todas las opciones:
assistant = AssistantAgent(
    name="Asistente",
    llm_config={"config_list": [config_1]}  # O config_2, O config_3
)</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Ventajas prácticas:</div>
<ul>
<li>
<p><strong>Experimenta</strong> con diferentes modelos sin cambiar código</p>
</li>
<li>
<p><strong>Fallback automático</strong> si un modelo falla (proporciona lista de modelos)</p>
</li>
<li>
<p><strong>Optimiza costos</strong> usando modelos más baratos cuando sea posible</p>
</li>
<li>
<p><strong>Migra</strong> a nuevos proveedores fácilmente</p>
</li>
<li>
<p><strong>Protege</strong> inversión en código si cambian APIs</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Estrategia de fallback:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">config_list = [
    {"model": "gpt-4", "api_key": "..."},           # Intenta primero (mejor pero caro)
    {"model": "gpt-3.5-turbo", "api_key": "..."},   # Si falla, intenta segundo (barato)
    {"model": "mistral", "api_base": "http://localhost:11434"}  # Fallback local
]

# Si gpt-4 falla por rate limit, automáticamente intenta gpt-3.5-turbo
assistant = AssistantAgent(llm_config={"config_list": config_list})</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Ejecución de Código Nativa:</strong></p>
</div>
<div class="ulist">
<div class="title">AutoGen puede generar código automáticamente y ejecutarlo. Esto es revolucionario porque:</div>
<ul>
<li>
<p>El agente puede validar su propio código</p>
</li>
<li>
<p>Puede iterar si hay errores</p>
</li>
<li>
<p>Captura automáticamente errores y retroalimenta al agente</p>
</li>
<li>
<p>Crea un loop automático de prueba-error</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>Ejemplo del ciclo:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">CICLO DE AUTOGEN PARA CODE GENERATION:

1. USER: "¿Cuál es la raíz cuadrada de 625?"

2. ASSISTANT (genera código):
   python
   import math
   result = math.sqrt(625)
   print(result)


3. USER PROXY (ejecuta):
   result = 25.0

4. ASSISTANT (analiza resultado):
   "La raíz cuadrada de 625 es 25"

VENTAJA: Si hubiera error, el agente vería el error y lo corregiría.</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Opciones de sandboxing:</div>
<ul>
<li>
<p>Local: Rápido, acceso a archivos locales, riesgoso</p>
</li>
<li>
<p>Docker: Seguro, aislado, más lento</p>
</li>
<li>
<p>Remoto: Distribuido, requiere infraestructura</p>
</li>
<li>
<p>Sin ejecución: Análisis de código sin ejecutar</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>4. Documentación y Comunidad:</strong></p>
</div>
<div class="ulist">
<div class="title">AutoGen tiene:</div>
<ul>
<li>
<p>Documentación oficial extensa (~5000+ páginas)</p>
</li>
<li>
<p>+150 ejemplos en GitHub</p>
</li>
<li>
<p>Comunidad Discord activa (~5000+ miembros)</p>
</li>
<li>
<p>Papers académicos (Microsoft Research)</p>
</li>
<li>
<p>Contribuciones constantes (updates semanales)</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Ventajas:</div>
<ul>
<li>
<p>Problemas comunes ya resueltos</p>
</li>
<li>
<p>Ejemplos para casi cualquier caso de uso</p>
</li>
<li>
<p>Soporte comunitario rápido</p>
</li>
<li>
<p>Framework activamente mantenido</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>5. Escalabilidad:</strong></p>
</div>
<div class="paragraph">
<p>AutoGen fue diseñado desde el inicio para escalar:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">ESCALABILIDAD EN AUTOGEN:

Pequeño (1-2 agentes):
  - Conversación simple usuario-asistente
  - Ejemplo: Chatbot básico
  - Overhead: Mínimo
  - Complejidad: Baja

Medio (3-10 agentes):
  - GroupChat coordinado
  - Ejemplo: Revisión de código multi-persona
  - Overhead: Moderado
  - Complejidad: Media

Grande (50-500 agentes):
  - Hierarchical chats anidados
  - Comunicación especializada
  - Ejemplo: Sistema de soporte con múltiples especializaciones
  - Overhead: Significativo pero manejable

Masivo (100+):
  - Requiere optimizaciones personalizadas
  - Message queue (Redis, RabbitMQ)
  - Load balancing
  - Persistencia de estado

ARCHITECTURA ESCALABLE:

User Request
      ↓
   Manager 1 (Coordinador principal)
      ↓
   ┌──┴──┬──────────┬──────────┐
   ↓     ↓          ↓          ↓
 Group1 Group2   Group3    Group4
(Código)(Test) (Análisis)(Revisión)
   ↓     ↓          ↓          ↓
[A,B,C][D,E,F] [G,H,I]   [J,K,L]

Cada grupo opera independientemente
Manager1 coordina comunicación entre grupos</code></pre>
</div>
</div>
<div class="ulist">
<div class="title">Técnicas de optimización:</div>
<ul>
<li>
<p>Message batching (agrupar mensajes)</p>
</li>
<li>
<p>Caché de respuestas repetidas</p>
</li>
<li>
<p>Async execution (ejecución paralela)</p>
</li>
<li>
<p>Connection pooling (reutilizar conexiones)</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_limitaciones_honestas">1.1.6. Limitaciones Honestas</h4>
<div class="paragraph">
<p><strong>1. Costos de API:</strong></p>
</div>
<div class="paragraph">
<p>Es importante ser honesto sobre los costos:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">ANÁLISIS DE COSTOS (Actualizado 2024):

OpenAI GPT-4:
  - Entrada: $0.03 por 1K tokens
  - Salida: $0.06 por 1K tokens

  Ejemplos prácticos:
  • Pregunta simple: ~$0.001-0.01
  • Análisis código 100 líneas: ~$0.05-0.20
  • RAG con 10 búsquedas: ~$0.50-2.00
  • Sesión debugging completa: ~$5-50

  COSTO MENSUAL ESTIMADO:
  - Uso casual (1 hora/día): $10-30
  - Uso profesional (8 horas/día): $200-500
  - Producción de alto volumen: $1000-5000+

OpenAI GPT-3.5-turbo (más barato):
  - Entrada: $0.0005 por 1K tokens (60x menos)
  - Salida: $0.0015 por 1K tokens (40x menos)

  COSTO MENSUAL ESTIMADO:
  - Mismo uso casual: $0.50-1.50
  - Mismo uso profesional: $5-15
  - Mismo uso producción: $50-200

Anthropic Claude 3 (Premium):
  - Opus (más poderoso): $15 por 1M entrada, $75 por 1M salida
  - Sonnet (balance): $3 por 1M entrada, $15 por 1M salida
  - Haiku (rápido): $0.25 por 1M entrada, $1.25 por 1M salida

Ollama Local (sin costo):
  - Costo API: $0
  - Costo infraestructura: Hardware local
  - Velocidad: 5-10x más lento que OpenAI
  - Calidad: ~80% de GPT-4
  - Privacidad: 100% local

RECOMENDACIONES DE OPTIMIZACIÓN COSTOS:

1. Por fase del desarrollo:
   Exploración:    Use Ollama local o GPT-3.5-turbo
   Prototipo:      Use GPT-3.5-turbo con fallback a GPT-4
   Producción:     Use GPT-4 pero limite llamadas

2. Técnicas prácticas:
   - Caché de respuestas (seed = 42 para determinismo)
   - Limitar max_tokens (500 en vez de 2000)
   - Batching de operaciones
   - Usar modelos más baratos para tareas simples
   - Implementar rate limiting local

3. Monitoreo de gastos:
   import logging
   logger = logging.getLogger("cost_tracker")

   total_tokens_input = 0
   total_tokens_output = 0

   # Registrar después de cada llamada
   total_cost = (total_tokens_input * 0.03 + total_tokens_output * 0.06) / 1000</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Control de Flujo:</strong></p>
</div>
<div class="paragraph">
<p>Los agentes pueden "desviarse" de lo esperado. Esto es una característica y un desafío:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">PROBLEMA: Falta de Control Determinista

Los agentes usan LLMs, que son estocásticos por naturaleza.
Incluso con temperature=0, pueden variar en respuestas.

EJEMPLO PROBLEMÁTICO:

Prompt: "Escribe un print statement en Python"

Respuesta posible 1: print("Hola mundo")
Respuesta posible 2: print("Hello")
Respuesta posible 3: No escribe print, explica qué es

IMPACTO EN FLUJOS COMPLEJOS:

En sistemas simples (1-2 agentes): No es problema
En sistemas complejos (10+ agentes): Impacto exponencial

ESTRATEGIAS DE MITIGACIÓN:

1. Prompt Engineering Cuidadoso (Específico y explícito)
2. Validación de Respuestas (Verificar formato y contenido)
3. Reintentos Inteligentes (Repetir hasta aceptable)
4. Structured Output (Usar JSON en lugar de texto libre)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Latencia y Rendimiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">ANÁLISIS DE LATENCIA:

OpenAI GPT-4 (remoto):
  - Latencia típica: 2-10 segundos por llamada
  - En peak: Puede alcanzar 30-60 segundos
  - Causas: Network, queue en API, procesamiento

Ollama Local (Mistral en GPU):
  - Latencia típica: 5-15 segundos por llamada
  - Predictible, sin dependencia de red
  - Más rápido si está cacheado

IMPACTO EN CADENAS:

Conversación simple (3 turnos):
  Tiempo total ≈ 3 * latencia_promedio
  OpenAI: ~15-30 segundos
  Ollama: ~15-45 segundos

Conversación grupal (5 agentes, 10 turnos):
  Tiempo total: Puede ser 5-10 minutos fácilmente
  ✗ Inaceptable para interfaces interactivas
  ✓ Aceptable para procesamiento batch

OPTIMIZACIONES:

1. Paralelización de agentes:
   - Ejecutar agentes independientes en paralelo
   - Reduce tiempo exponencial a tiempo lineal

2. Modelo más rápido + más modelos lentos:
   - GPT-3.5-turbo es 10x más rápido que GPT-4
   - Reserva GPT-4 solo para decisiones críticas

3. Caché y reutilización:
   - Si pregunta es similar, reutilizar respuesta anterior
   - Implementar LRU cache de prompts

4. Async/Await:
   - No esperar respuesta antes de preparar siguiente
   - Python asyncio puede ayudar aquí</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Dependencias Externas y Mantenimiento:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>AutoGen requiere Python 3.8+</p>
</li>
<li>
<p>Dependencias: requests, openai/anthropic/etc</p>
</li>
<li>
<p>Cambios en APIs pueden romper código</p>
</li>
</ul>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">DEPENDENCIAS Y COMPATIBILIDAD:

AutoGen dependencies:
- Python 3.8, 3.9, 3.10, 3.11
- typing_extensions (para type hints)
- openai&gt;=1.0.0 (si usas OpenAI)
- anthropic&gt;=0.7.0 (si usas Claude)
- azure-openai&gt;=1.0.0 (si usas Azure)

RIESGOS DE ROMPER CAMBIOS:

Riesgo 1: Cambios en APIs de proveedores
  OpenAI cambió su API completamente en Nov 2023
  Código antiguo dejó de funcionar

  Solución: Version pinning en requirements.txt
  openai==1.3.0  # Versión específica

Riesgo 2: Deprecación en AutoGen
  Funcionalidades marcadas como deprecated eventualmente se removerán

  Solución: Monitorear changelog y migrar proactivamente

Riesgo 3: Incompatibilidad con modelos nuevos
  Nuevos modelos pueden tener requisitos diferentes

  Solución: Abstracta la configuración del modelo

EJEMPLO DE CÓDIGO RESILIENTE:

# requirements.txt
pyautogen==0.2.5
openai==1.3.0
python-dotenv==1.0.0

# En código: usar abstractión
config = get_model_config("gpt-4")  # En lugar de hardcodear

def get_model_config(model_name):
    if model_name == "gpt-4":
        return {"model": "gpt-4", "api_key": get_key()}
    elif model_name == "gpt-3.5-turbo":
        return {"model": "gpt-3.5-turbo", "api_key": get_key()}
    # Fácil de actualizar si modelos cambian</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_conclusión_del_módulo_1">1.1.7. Conclusión del Módulo 1</h4>
<div class="paragraph">
<p>AutoGen es un framework poderoso que simplifica significativamente la construcción de sistemas multi-agente.</p>
</div>
<div class="ulist">
<div class="title">Sus fortalezas principales son:</div>
<ul>
<li>
<p><strong>Abstracción elegante</strong> de complejidad multi-agente</p>
</li>
<li>
<p><strong>Flexibilidad</strong> en elección de modelos y proveedores</p>
</li>
<li>
<p><strong>Código limpio</strong> y facilidad de uso</p>
</li>
<li>
<p><strong>Comunidad activa</strong> y documentación completa</p>
</li>
<li>
<p><strong>Casos de uso reales</strong> y probados</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title">Pero requiere consideración de:</div>
<ul>
<li>
<p><strong>Costos</strong> potencialmente altos con APIs remotas</p>
</li>
<li>
<p><strong>Latencia</strong> puede ser problema en sistemas interactivos</p>
</li>
<li>
<p><strong>Determinismo</strong> limitado en LLMs</p>
</li>
<li>
<p><strong>Dependencias externas</strong> que pueden cambiar</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>En conclusión: <strong>Ideal para prototipos, investigación, y sistemas donde el costo y latencia son aceptables. No ideal para aplicaciones críticas en tiempo real con presupuesto limitado.</strong></p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_1_2_arquitectura_de_autogen">1.2. 1.2. Arquitectura de AutoGen</h3>
<div class="sect3">
<h4 id="_conceptos_fundamentales">1.2.1. Conceptos Fundamentales</h4>
<div class="paragraph">
<p>La arquitectura de AutoGen se construye sobre conceptos clave:</p>
</div>
<div class="paragraph">
<p><strong>1. Agentes (Agents):</strong>
Entidades autónomas con memoria, capacidades y personalidad. Cada agente es un "actor" en el sistema.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Tipos de agentes base:
AssistantAgent        # Piensa y genera respuestas
UserProxyAgent        # Representa al usuario
GroupChatManager      # Coordina múltiples agentes
CustomAgent          # Personalizado por el usuario

# Cada agente tiene:
- name: identificador único
- system_message: instrucciones de comportamiento
- llm_config: configuración del modelo
- tools: funciones que puede ejecutar
- memory: historial de conversación</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>2. Mensajes (Messages):</strong>
Unidades de comunicación estructuradas.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Estructura de mensaje
{
    "role": "user|assistant",
    "content": "El contenido del mensaje",
    "name": "nombre_del_agente",
    "function_call": {...},  # Opcional: para function calling
    "tool_use": {...}        # Opcional: para herramientas
}

# El historial mantiene todo el contexto
messages = [
    {"role": "user", "content": "¿Qué es Python?"},
    {"role": "assistant", "content": "Python es un lenguaje..."},
    {"role": "user", "content": "¿Cuáles son sus usos?"},
    {"role": "assistant", "content": "Los usos principales son..."}
]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>3. Funciones y Herramientas (Functions &amp; Tools):</strong>
Capacidades que los agentes pueden ejecutar.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Ejemplo: función que un agente puede invocar
def calculate_sales_total(items: List[float], tax_rate: float = 0.08):
    """
    Calcular total de ventas con impuesto

    Args:
        items: Lista de precios
        tax_rate: Tasa de impuesto (default 8%)

    Returns:
        Total incluyendo impuesto
    """
    subtotal = sum(items)
    tax = subtotal * tax_rate
    return subtotal + tax

# Los agentes pueden:
# 1. Decidir si necesitan esta función
# 2. Proporcionarle los parámetros correctos
# 3. Usar el resultado en su respuesta</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>4. Configuración (Configuration):</strong>
Define cómo se comportan los agentes.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Configuración completa
llm_config = {
    # Proveedor y modelo
    "config_list": [
        {
            "model": "gpt-4",
            "api_key": "...",
            "api_base": "https://api.openai.com/v1"
        }
    ],

    # Parámetros de generación
    "temperature": 0.7,      # Creatividad (0-1)
    "top_p": 0.9,           # Nucleus sampling
    "max_tokens": 2000,     # Longitud máxima
    "timeout": 120,         # Segundos

    # Comportamiento
    "cache_seed": 42,       # Para reproducibilidad
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_tipos_de_agentes_y_sus_características">1.2.2. Tipos de Agentes y sus Características</h4>
<div class="paragraph">
<p><strong>AssistantAgent - El "Pensador"</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import AssistantAgent

assistant = AssistantAgent(
    name="Programador",
    system_message="""Eres un experto programador.
    Cuando se te pide escribir código:
    1. Analiza el requisito cuidadosamente
    2. Escribe código limpio y eficiente
    3. Incluye manejo de errores
    4. Documenta tu código""",
    llm_config=llm_config,
    human_input_mode="NEVER"  # No pide confirmación
)

# Características:
# - Usa LLM para generar respuestas
# - Puede ejecutar funciones
# - Mantiene contexto de conversación
# - No espera entrada del usuario</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Parámetros Configurables de AssistantAgent:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">AssistantAgent(
    # Identidad básica
    name="AsistenteIA",                           # Nombre único, sin espacios
    system_message="Eres un experto en Python",  # Instrucciones del comportamiento

    # Configuración del LLM
    llm_config={
        "config_list": [{"model": "gpt-4", "api_key": "..."}],
        "temperature": 0.7,                      # 0=determinista, 1=creativo
        "top_p": 0.9,                           # Nucleus sampling
        "max_tokens": 2000,                      # Máximo tokens de respuesta
        "timeout": 120,                         # Segundos antes de timeout
    },

    # Comportamiento de entrada
    human_input_mode="NEVER",                    # NEVER, ALWAYS, TERMINATE
    max_consecutive_auto_reply=10,               # Límite de respuestas consecutivas

    # Funciones que puede ejecutar
    function_map={
        "calculate": my_calculate_func,
        "search": my_search_func,
    },

    # Condición personalizada de término
    is_termination_msg=lambda x: "TERMINADO" in x.get("content", ""),

    # Parámetros opcionales
    default_auto_reply="",                       # Respuesta por defecto si sin idea
    description="Agente especializado en Python"  # Para logging/debug
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opciones de comportamiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">COMPORTAMIENTO 1: Asistente determinista (reproducible)
  temperature: 0.0
  top_p: 0.1
  cache_seed: 42

  Caso de uso: Tareas que deben ser idénticas siempre
  Ejemplo: Generación de datos sintéticos con seed fijo

COMPORTAMIENTO 2: Asistente creativo (variado)
  temperature: 1.0-1.2
  top_p: 0.95

  Caso de uso: Brainstorming, generación de ideas
  Ejemplo: Sugerencias de nombres, ideas de marketing

COMPORTAMIENTO 3: Asistente técnico preciso (balanceado)
  temperature: 0.3-0.5
  top_p: 0.9

  Caso de uso: Tareas técnicas importantes
  Ejemplo: Análisis de código, debugging

COMPORTAMIENTO 4: Asistente dialógico (conversacional)
  temperature: 0.7
  top_p: 0.85
  max_tokens: 3000

  Caso de uso: Conversaciones naturales
  Ejemplo: Customer service, tutorías</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>UserProxyAgent - El "Usuario"</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import UserProxyAgent

user_proxy = UserProxyAgent(
    name="Usuario",
    human_input_mode="TERMINATE",  # ALWAYS, NEVER, TERMINATE
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": False  # O True para aislamiento completo
    }
)

# Características:
# - Representa al usuario en la conversación
# - Puede ejecutar código generado
# - Proporciona feedback
# - Control sobre cuándo terminar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Parámetros completos de UserProxyAgent:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">UserProxyAgent(
    # Identidad
    name="Usuario",
    system_message="Eres usuario prudente",  # Opcional, influye en comportamiento

    # CONTROL MÁS IMPORTANTE: Modo de entrada
    human_input_mode="TERMINATE",            # Cómo solicita confirmación

    # Ejecución de código
    code_execution_config={
        "work_dir": "./workspace",           # Directorio de trabajo
        "use_docker": False,                 # Aislamiento con Docker
        "docker_image": "python:3.9",        # Imagen si use_docker=True
        "timeout": 30,                       # Máximo segundos para ejecutar
        "last_n_messages": 3,                # Historial a ejecutar
    },

    # Parámetros de conversación
    max_consecutive_auto_reply=10,           # Cuánto puede responder solo
    llm_config=False,                        # UserProxy típicamente NO tiene LLM
    # (pero es opcional, puede tener si necesitas comportamiento especial)

    # Validación
    is_termination_msg=lambda x: "LISTO" in x.get("content", ""),
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Modos de Entrada del Usuario Comparados:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Modo "ALWAYS":
  ┌─────────────────────────────────┐
  │ Usuario: "Escribe código"       │
  ├─────────────────────────────────┤
  │ Assistant: "def hola(): ..."     │
  ├─────────────────────────────────┤
  │ Sistema: "Ejecutar? (y/n/s)"   │
  │ Usuario: "y"  ← SIEMPRE PREGUNTA │
  └─────────────────────────────────┘

  Interacciones: 7-8 mensajes para tarea simple
  Tiempo: Lento (requiere confirmación manual)
  Control: Máximo
  Ideal para: Desarrollo, testing interactivo

  Código:
  user_proxy = UserProxyAgent(
      human_input_mode="ALWAYS"
  )

---

Modo "NEVER":
  ┌─────────────────────────────────┐
  │ Usuario: "Escribe código"       │
  ├─────────────────────────────────┤
  │ Assistant: "def hola(): ..."     │
  ├─────────────────────────────────┤
  │ System: EJECUTA AUTOMÁTICO ← NO PREGUNTA │
  │ Output: "Éxito: resultado..."   │
  └─────────────────────────────────┘

  Interacciones: 2-3 mensajes para tarea simple
  Tiempo: Rápido (automatizado)
  Control: Mínimo
  Ideal para: Producción, automatización
  Riesgo: Puede ejecutar código malicioso sin verificar

  Código:
  user_proxy = UserProxyAgent(
      human_input_mode="NEVER"
  )

---

Modo "TERMINATE":
  ┌─────────────────────────────────┐
  │ Usuario: "Escribe código"       │
  ├─────────────────────────────────┤
  │ Assistant: "def hola(): ..."     │
  │ User: "Parece bien"             │
  ├─────────────────────────────────┤
  │ System: AMBOS dicen LISTO?      │
  │ SI → EJECUTA | NO → CONTINÚA    │
  └─────────────────────────────────┘

  Interacciones: 3-4 mensajes típicamente
  Tiempo: Moderado
  Control: Balance
  Ideal para: Balance entre automación y control

  Código:
  user_proxy = UserProxyAgent(
      human_input_mode="TERMINATE"
  )

RECOMENDACIÓN:

├─ Desarrollo local: ALWAYS (máximo control)
├─ Sistema batch: NEVER (máxima automatización)
└─ Sistema interactivo en producción: TERMINATE (balance)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>GroupChatManager - El "Coordinador"</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import GroupChat, GroupChatManager

# Crear múltiples agentes especializados
coder = AssistantAgent(name="Coder", ...)
reviewer = AssistantAgent(name="Reviewer", ...)
tester = AssistantAgent(name="Tester", ...)

# Crear el chat grupal
groupchat = GroupChat(
    agents=[coder, reviewer, tester, user_proxy],
    messages=[],
    max_round=20  # Máximo turnos para evitar loops infinitos
)

# Crear el manager
manager = GroupChatManager(
    groupchat=groupchat,
    llm_config=llm_config
)

# Ahora los agentes pueden debatir entre sí
user_proxy.initiate_chat(
    manager,
    message="Necesito un módulo de validación"
)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_flujos_de_comunicación">1.2.3. Flujos de Comunicación</h4>
<div class="paragraph">
<p><strong>Patrón Simple (Dos Agentes):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">Usuario (UserProxyAgent)
    ↓ envía: "Escribe un hola mundo"
    ↓
Asistente (AssistantAgent)
    ↓ recibe, procesa, genera código
    ↓ envía: "def main(): print('Hola mundo')"
    ↓
Usuario
    ↓ ejecuta código
    ↓ envía: "Código ejecutado exitosamente"
    ↓
Asistente
    ↓ reconoce término
    ↓ conversación termina</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón Complejo (Multi-Agente):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">         ┌────────────────┐
         │  UserProxy     │
         │ (Coordinador)  │
         └────────┬───────┘
                  │
        ┌─────────┼─────────┐
        ↓         ↓         ↓
    ┌────────┐ ┌────────┐ ┌────────┐
    │ Coder  │ │Reviewer│ │ Tester │
    └────┬───┘ └───┬────┘ └───┬────┘
         │ debate entre sí
         │ intercambian ideas
         │ iteran hasta acuerdo
         ↓
    UserProxy recibe resultado
    Conversación termina</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_modelos_de_lenguaje_soportados">1.2.4. Modelos de Lenguaje Soportados</h4>
<div class="paragraph">
<p><strong>Proveedores Principales:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># 1. OpenAI (GPT-4, GPT-3.5-turbo)
openai_config = {
    "config_list": [{
        "model": "gpt-4",
        "api_key": "sk-...",
        "api_type": "openai"
    }]
}

# 2. Azure OpenAI
azure_config = {
    "config_list": [{
        "api_type": "azure",
        "api_key": "...",
        "api_base": "https://xxx.openai.azure.com/",
        "api_version": "2024-02-15-preview",
        "model": "gpt-4-deployment"
    }]
}

# 3. Anthropic Claude
claude_config = {
    "config_list": [{
        "model": "claude-3-opus",
        "api_key": "sk-ant-...",
        "api_type": "anthropic"
    }]
}

# 4. Ollama Local
ollama_config = {
    "config_list": [{
        "model": "mistral",
        "api_base": "http://localhost:11434/v1",
        "api_type": "ollama"
    }]
}

# 5. Modelos Open Source Locales
local_config = {
    "config_list": [{
        "model": "local-llama2",
        "api_base": "http://localhost:8000",
    }]
}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Comparativa de Modelos:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">OpenAI (GPT-4):
  - Costo: ~$0.03/1K tokens entrada, $0.06/1K salida
  - Velocidad: ~2-5 segundos por respuesta
  - Calidad: Excelente, estado del arte
  - Privacidad: Datos enviados a OpenAI

GPT-3.5-turbo:
  - Costo: ~$0.0005/1K entrada, $0.0015/1K salida (mucho más barato)
  - Velocidad: ~1-3 segundos
  - Calidad: Buena, suficiente para muchos casos
  - Privacidad: Datos enviados a OpenAI

Claude (Anthropic):
  - Costo: Comparable a GPT-4
  - Velocidad: ~2-5 segundos
  - Calidad: Muy buena, excelente en razonamiento
  - Privacidad: Datos a Anthropic

Ollama Local (Mistral, Llama2):
  - Costo: $0 después de descargar
  - Velocidad: ~5-15 segundos (depende hardware)
  - Calidad: Buena pero inferior a GPT-4
  - Privacidad: Total, todo local
  - Ventaja: Sin conexión a internet después de setup</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_1_3_instalación_y_configuración">1.3. 1.3. Instalación y Configuración</h3>
<div class="sect3">
<h4 id="_requisitos_previos">1.3.1. Requisitos Previos</h4>
<div class="ulist">
<div class="title"><strong>Hardware:</strong></div>
<ul>
<li>
<p>CPU: Cualquiera (i5 o superior recomendado)</p>
</li>
<li>
<p>RAM: 8GB mínimo, 16GB recomendado</p>
</li>
<li>
<p>GPU: Opcional pero recomendado para Ollama</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Software:</strong></div>
<ul>
<li>
<p>Python: 3.8, 3.9, 3.10 o 3.11</p>
</li>
<li>
<p>pip: Gestor de paquetes de Python</p>
</li>
<li>
<p>git: Para clonar repositorios</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Conocimientos:</strong></div>
<ul>
<li>
<p>Python básico (variables, funciones, classes)</p>
</li>
<li>
<p>APIs REST (opcional pero útil)</p>
</li>
<li>
<p>Prompting para LLMs (aprenderás mientras usas)</p>
</li>
</ul>
</div>
</div>
<div class="sect3">
<h4 id="_instalación_paso_a_paso">1.3.2. Instalación Paso a Paso</h4>
<div class="paragraph">
<p><strong>Opción 1: Instalación Mínima (con OpenAI)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Verificar Python
python3 --version  # Debe ser 3.8+

# 2. Crear entorno virtual (recomendado)
python3 -m venv autogen_env
source autogen_env/bin/activate  # En Windows: autogen_env\Scripts\activate

# 3. Instalar AutoGen
pip install pyautogen

# 4. Instalar dependencias opcionales
pip install requests  # Para Ollama

# 5. Verificar instalación
python3 -c "import autogen; print(autogen.__version__)"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Instalación Completa (con Extras)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Con todas las características
pip install "pyautogen[extra]"

# Esto incluye:
# - Soporte para Docker (ejecución segura de código)
# - Herramientas adicionales
# - Dependencias de desarrollo

# Para desarrollo (con pre-commit hooks)
pip install "pyautogen[dev]"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Desde Código Fuente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Clonar repositorio
git clone https://github.com/microsoft/autogen.git
cd autogen

# Instalar en modo desarrollo
pip install -e .

# Útil para contribuir o usar versión más reciente</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_configuración_de_proveedores">1.3.3. Configuración de Proveedores</h4>
<div class="paragraph">
<p><strong>OpenAI:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Crear cuenta en https://platform.openai.com
# 2. Generar API key en https://platform.openai.com/account/api-keys
# 3. Guardar en variable de entorno

export OPENAI_API_KEY="sk-..."
# O en Python:
import os
os.environ["OPENAI_API_KEY"] = "sk-..."</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Archivo de Configuración (.env):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># archivo: .env
OPENAI_API_KEY=sk-...
ANTHROPIC_API_KEY=sk-ant-...
AZURE_OPENAI_API_KEY=...
AZURE_OPENAI_API_BASE=https://xxx.openai.azure.com

# Usar con python-dotenv:
from dotenv import load_dotenv
load_dotenv()</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ollama Local:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># 1. Instalar Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# 2. Iniciar servidor
ollama serve

# 3. En otra terminal, descargar modelo
ollama pull mistral

# 4. Usar en AutoGen
config = {
    "config_list": [{
        "model": "mistral",
        "api_base": "http://localhost:11434/v1",
    }]
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_entorno_de_desarrollo_recomendado">1.3.4. Entorno de Desarrollo Recomendado</h4>
<div class="paragraph">
<p><strong>Estructura de Proyecto:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">mi_proyecto_autogen/
├── venv/                    # Entorno virtual
├── src/
│   ├── agents/
│   │   ├── assistant.py
│   │   ├── reviewer.py
│   │   └── __init__.py
│   ├── tools/
│   │   ├── code_execution.py
│   │   └── __init__.py
│   └── main.py
├── examples/
│   ├── basic_conversation.py
│   └── multi_agent_workflow.py
├── tests/
│   ├── test_agents.py
│   └── __init__.py
├── configs/
│   ├── openai_config.py
│   ├── ollama_config.py
│   └── azure_config.py
├── .env                     # Variables de entorno
├── .gitignore              # Git ignore patterns
├── requirements.txt        # Dependencias
└── README.md              # Documentación</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>IDE Recomendado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">VS Code (Recomendado):
  - Extensión: Python
  - Extensión: Pylance (type hints)
  - Extensión: autodocstring (generar docs)
  - Extensión: GitLens

PyCharm Community:
  - IDE especializado en Python
  - Debugging integrado
  - Refactoring automático

Jupyter Notebook:
  - Para prototipos rápidos
  - Ideal para explorar
  - Combina código y documentación</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Herramientas de Desarrollo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-bash hljs" data-lang="bash"># Linting (verificar estilo)
pip install pylint

# Formateado automático
pip install black

# Type checking
pip install mypy

# Testing
pip install pytest

# Debugging
pip install ipdb

# Monitoreo
pip install py-spy</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Archivo requirements.txt:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">pyautogen&gt;=0.2.0
python-dotenv&gt;=1.0.0
requests&gt;=2.31.0
openai&gt;=1.0.0  # Para OpenAI
anthropic&gt;=0.7.0  # Para Claude
azure-openai&gt;=1.0.0  # Para Azure

# Desarrollo
pytest&gt;=7.0.0
black&gt;=23.0.0
pylint&gt;=2.0.0
mypy&gt;=1.0.0
ipdb&gt;=0.13.0</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_2_fundamentos_de_agentes">2. Módulo 2: Fundamentos de Agentes</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_2_1_agentes_básicos">2.1. 2.1. Agentes Básicos</h3>
<div class="sect3">
<h4 id="_assistantagent_detallado">2.1.1. AssistantAgent - Detallado</h4>
<div class="paragraph">
<p><strong>Qué es:</strong>
Un agente que utiliza un LLM para generar respuestas inteligentes. Es el "cerebro" que piensa y decide.</p>
</div>
<div class="paragraph">
<p><strong>Inicialización Básica:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import AssistantAgent

assistant = AssistantAgent(
    name="Asistente",
    llm_config={
        "config_list": [{"model": "gpt-4", "api_key": "..."}],
        "temperature": 0.7,
        "max_tokens": 2000
    }
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Parámetros Clave:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">AssistantAgent(
    # Identidad
    name="AsistenteIA",                    # Nombre único
    system_message="""Eres un experto    # Instrucciones base
                      en Python...""",

    # Configuración del LLM
    llm_config={
        "config_list": [...],             # Modelos disponibles
        "temperature": 0.7,               # Creatividad
        "top_p": 0.9,                     # Diversidad
        "max_tokens": 2000,               # Máximo output
    },

    # Comportamiento
    human_input_mode="NEVER",             # NEVER, ALWAYS, TERMINATE

    # Funciones que puede usar
    function_map={
        "calculate": calculate_func,
        "search": search_func
    },

    # Validación de respuestas
    is_termination_msg=lambda x:
        "TERMINAR" in x.get("content", "")
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opciones de comportamiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># 1. Assistant determinista (pocas variaciones)
assistant_deterministic = AssistantAgent(
    name="Determinista",
    llm_config={
        "temperature": 0.0,  # Siempre la misma respuesta
        "max_tokens": 500,   # Respuestas cortas
        "top_p": 0.1         # Opciones limitadas
    }
)

# 2. Assistant creativo (más variaciones)
assistant_creative = AssistentAgent(
    name="Creativo",
    llm_config={
        "temperature": 1.2,  # Muy variable
        "top_p": 0.95        # Muchas opciones posibles
    }
)

# 3. Assistant experto (completo)
assistant_expert = AssistantAgent(
    name="Experto",
    system_message="""Eres el mejor experto en Python del mundo.
    Cuando respondas:
    1. Sé muy preciso y técnico
    2. Explica el por qué de tus recomendaciones
    3. Sugiere alternativas si es relevante
    4. Menciona trade-offs
    5. Proporciona ejemplos de código cuando sea apropiado
    """,
    llm_config={
        "temperature": 0.3,  # Técnico, no creativo
        "max_tokens": 3000,
    }
)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_userproxyagent_detallado">2.1.2. UserProxyAgent - Detallado</h4>
<div class="paragraph">
<p><strong>Qué es:</strong>
Representa al usuario en la conversación. Puede ejecutar código, proporcionar feedback, y controlar el flujo.</p>
</div>
<div class="paragraph">
<p><strong>Inicialización:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import UserProxyAgent

user = UserProxyAgent(
    name="Usuario",
    human_input_mode="TERMINATE",
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": False
    }
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Modos de Interacción:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Modo 1: ALWAYS (Control Total)
user = UserProxyAgent(
    name="Usuario",
    human_input_mode="ALWAYS"
)

# Efecto: Después de cada respuesta del asistente,
# pide confirmación. Ideal para desarrollo.

# Ejemplo de interacción:
# Assistant: "Aquí está el código..."
# Sistema: "Proceder? (y/n/s): " &lt;- espera entrada


# Modo 2: NEVER (Automatización Completa)
user = UserProxyAgent(
    name="Usuario",
    human_input_mode="NEVER"
)

# Efecto: Nunca pide confirmación.
# Ejecuta automáticamente. Riesgo: sin supervisión.


# Modo 3: TERMINATE (Balance)
user = UserProxyAgent(
    name="Usuario",
    human_input_mode="TERMINATE"
)

# Efecto: Solo pide si ambos agentes creen que debe terminar.
# Más seguro pero menos control.</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración de Ejecución de Código:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Opción 1: Ejecutar localmente (rápido pero riesgoso)
user = UserProxyAgent(
    name="Usuario",
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": False
    }
)

# Opción 2: Ejecutar en Docker (seguro)
user = UserProxyAgent(
    name="Usuario",
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": True,
        "docker_image": "python:3.9"
    }
)

# Opción 3: Sin ejecución
user = UserProxyAgent(
    name="Usuario",
    code_execution_config=False  # No ejecutar código
)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_agentes_personalizados">2.1.3. Agentes Personalizados</h4>
<div class="paragraph">
<p><strong>Crear un Agente Especializado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import AssistantAgent

class DataAnalystAgent(AssistantAgent):
    """Agente especializado en análisis de datos"""

    def __init__(self, name="DataAnalyst", **kwargs):
        system_msg = """Eres un experto analista de datos.
        Tu especialidad es:
.
        - Exploración de datos (pandas, numpy)
        - Visualización (matplotlib, seaborn)
        - Estadística descriptiva e inferencial
        - Machine learning básico

        Cuando recibas datos:
        1. Examina la estructura (shape, dtypes, missing values)
        2. Genera estadísticas descriptivas
        3. Crea visualizaciones relevantes
        4. Proporciona insights accionables"""

        super().__init__(
            name=name,
            system_message=system_msg,
            **kwargs
        )

# Uso:
analyst = DataAnalystAgent(
    llm_config={"config_list": [{"model": "gpt-4", "api_key": "..."}]}
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Herencia y Composición:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Opción 1: Herencia
class SecurityReviewerAgent(AssistantAgent):
    def __init__(self, **kwargs):
        super().__init__(
            system_message="Eres un experto en seguridad...",
            **kwargs
        )

# Opción 2: Composición
class PipelineAgent:
    def __init__(self):
        self.coder = AssistantAgent(...)
        self.reviewer = AssistantAgent(...)
        self.tester = AssistantAgent(...)

    def process(self, task):
        code = self.coder.generate_response(task)
        review = self.reviewer.generate_response(code)
        result = self.tester.generate_response(code)
        return {"code": code, "review": review, "test": result}</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_2_conversaciones_entre_agentes">2.2. 2.2. Conversaciones entre Agentes</h3>
<div class="sect3">
<h4 id="_iniciación_de_conversaciones">2.2.1. Iniciación de Conversaciones</h4>
<div class="paragraph">
<p><strong>Opción 1: Conversación Simple (Dos Agentes)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import AssistantAgent, UserProxyAgent

# Crear agentes
assistant = AssistantAgent(
    name="Asistente",
    system_message="Eres un experto en Python",
    llm_config=llm_config
)

user_proxy = UserProxyAgent(
    name="Usuario",
    human_input_mode="TERMINATE"
)

# Iniciar conversación
user_proxy.initiate_chat(
    assistant,
    message="¿Cuál es la diferencia entre map y filter?",
    max_consecutive_auto_reply=3  # Máximo 3 respuestas del assistant
)

# Flujo:
# 1. Usuario envía mensaje
# 2. Assistant responde
# 3. Usuario puede responder (si human_input_mode permite)
# 4. Itera hasta terminar</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opciones de initiate_chat:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">user_proxy.initiate_chat(
    recipient=assistant,                          # A quién enviar el mensaje

    # El mensaje inicial
    message="Tu pregunta aquí",                   # String o None

    # Control de duración
    max_consecutive_auto_reply=5,                 # Máximo turnos de assistant

    # Parámetros opcionales
    clear_history=True,                          # Limpiar historial previo
    silent=False,                                # No mostrar mensajes en stdout
)

# Retorna: (último_mensaje_de_assistant, conversación_completa)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ciclo de vida de una conversación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">INICIO:
  1. user_proxy.initiate_chat(...)

PRIMER TURNO:
  2. user_proxy → envía mensaje inicial
  3. assistant → recibe y procesa
  4. assistant → genera respuesta
  5. user_proxy ← recibe respuesta

TURNOS SUBSECUENTES (si no termina):
  6. user_proxy → analiza respuesta, decide continuar
  7. user_proxy → envía respuesta/pregunta
  8. assistant → recibe...
  [repite 3-8]

CONDICIONES DE TÉRMINO:

  a) max_consecutive_auto_reply alcanzado
  b) is_termination_msg devuelve True
  c) Error no recuperable
  d) Timeout
  e) Assistant dice "TERMINE" o similar

SALIDA:
  9. Conversación termina
  10. Ambos agentes mantienen historial en chat_history</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Conversación Multigiro con Feedback Manual</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Conversación inicial
user_proxy.initiate_chat(
    assistant,
    message="¿Cuál es la raíz cuadrada de 625?",
    max_consecutive_auto_reply=2
)

# La conversación ya ocurrió. Ahora continuar:
user_proxy.send(
    message="¿Y cuál es el cuadrado de 25?",
    recipient=assistant,
    request_reply=True  # Solicitar respuesta inmediata
)

# Ventajas:
# - Control fino sobre cada turno
# - Puedes hacer lógica custom entre turnos
# - Acceso completo al historial

# Desventajas:
# - Más código
# - Manual, no automático</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Conversación Grupal (Múltiples Agentes)</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import GroupChat, GroupChatManager

# Crear múltiples agentes especializados
coder = AssistantAgent(
    name="Coder",
    system_message="""Eres un experto programador.
    Escribe código limpio, eficiente y bien documentado.""",
    llm_config=llm_config
)

reviewer = AssistantAgent(
    name="Reviewer",
    system_message="""Eres un revisor de código experto.
    Valida la calidad, seguridad y eficiencia del código.""",
    llm_config=llm_config
)

tester = AssistantAgent(
    name="Tester",
    system_message="""Eres un QA engineer.
    Prueba el código y reporta bugs potenciales.""",
    llm_config=llm_config
)

# Crear grupo chat
groupchat = GroupChat(
    agents=[coder, reviewer, tester, user_proxy],
    messages=[],
    max_round=10,           # Máximo turnos para evitar loops
    speaker_selection_method="round_robin"  # O "auto" o "manual"
)

# Crear manager para coordinar
manager = GroupChatManager(
    groupchat=groupchat,
    llm_config=llm_config
)

# Iniciar conversación grupal
user_proxy.initiate_chat(
    manager,
    message="Necesito una función para calcular factorial"
)

# Los agentes debaten entre sí hasta llegar a solución</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Estrategias de Selección de Turnos (speaker_selection_method):</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Método 1: Round Robin (por turnos)
groupchat = GroupChat(
    agents=[coder, reviewer, tester, user_proxy],
    speaker_selection_method="round_robin"
)

# Flujo:
# Turno 1: Coder habla
# Turno 2: Reviewer habla
# Turno 3: Tester habla
# Turno 4: User habla
# [Repite]

# Ventajas:
#   ✓ Determinista y predecible
#   ✓ Todos participan equitativamente
# Desventajas:
#   ✗ No respeta contexto
#   ✗ Menos eficiente (puede hablar alguien irrelevante)


# Método 2: Automático (default)
groupchat = GroupChat(
    agents=[coder, reviewer, tester, user_proxy],
    speaker_selection_method="auto"
)

# Flujo:
# El LLM del manager decide quién debe hablar basado en contexto
# "Coder, revisa esos comentarios que hizo reviewer"
# Coder habla solo si es relevante

# Ventajas:
#   ✓ Contextualmente apropiado
#   ✓ Más natural y eficiente
# Desventajas:
#   ✗ Menos predecible
#   ✗ Puede dejar a alguien fuera


# Método 3: Manual (personalizado)
def manual_speaker_selection(last_speaker, groupchat):
    """Lógica custom para seleccionar siguiente speaker"""

    messages = groupchat.messages
    last_msg = messages[-1] if messages else None

    # Ejemplo: si fue error, siempre habla tester
    if "error" in last_msg.get("content", "").lower():
        return groupchat.agents[2]  # Tester

    # Si no, round robin
    for i, agent in enumerate(groupchat.agents):
        if agent == last_speaker:
            return groupchat.agents[(i + 1) % len(groupchat.agents)]

    return groupchat.agents[0]

groupchat = GroupChat(
    agents=[coder, reviewer, tester, user_proxy],
    speaker_selection_method=manual_speaker_selection
)

# Ventajas:
#   ✓ Control total
#   ✓ Lógica de negocio específica
# Desventajas:
#   ✗ Requiere escribir código
#   ✗ Complejidad adicional</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_flujos_de_comunicación_avanzados">2.2.2. Flujos de Comunicación Avanzados</h4>
<div class="paragraph">
<p><strong>Control de Turnos Detallado:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Configuración completa de GroupChat
groupchat = GroupChat(
    agents=[coder, reviewer, tester, user_proxy],
    messages=[],

    # CONTROL DE DURACIÓN
    max_round=15,                           # Máximo turnos totales

    # SELECCIÓN DE SPEAKERS
    speaker_selection_method="auto",        # "auto", "round_robin", o función

    # MANEJO DE ERRORES
    send_introductions=True,                # Presentar agentes al inicio

    # FUNCIÓN DE TÉRMINO
    is_termination_msg=lambda x: "LISTO" in x.get("content", "")
)

# Detectar término temprano
def is_termination_msg(msg):
    content = msg.get("content", "").lower()

    # Terminar si:
    if any(word in content for word in ["TERMINADO", "COMPLETO", "LISTO", "EXITOSO"]):
        return True

    # O si usuario explícitamente rechaza continuación:
    if "no" in content and "continuar" in content:
        return True

    return False

groupchat.is_termination_msg = is_termination_msg
        return True
    return False

groupchat.is_termination_msg = is_termination_msg</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Condiciones de Términación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Opción 1: Basada en contenido
def custom_termination(msg):
    # Terminar si alguien dice "LISTO"
    return "LISTO" in msg.get("content", "").upper()

# Opción 2: Basada en número de turnos
max_turns = 20
current_turn = 0

# Opción 3: Basada en satisfacción
class SatisfactionTerminator:
    def __init__(self, threshold=0.9):
        self.threshold = threshold

    def should_terminate(self, conversation):
        # Analizar si ambos agentes están satisfechos
        # Retornar True si satisfacción &gt; threshold
        pass</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_2_3_configuración_avanzada">2.3. 2.3. Configuración Avanzada</h3>
<div class="sect3">
<h4 id="_parámetros_de_configuración_completos">2.3.1. Parámetros de Configuración Completos</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Configuración completa y detallada
llm_config = {
    # ===== MODELOS =====
    "config_list": [
        {
            "model": "gpt-4",
            "api_key": "sk-...",
            "api_base": "https://api.openai.com/v1",
            "timeout": 120
        },
        {
            "model": "gpt-3.5-turbo",  # Fallback si GPT-4 falla
            "api_key": "sk-..."
        }
    ],

    # ===== PARÁMETROS DE GENERACIÓN =====
    "temperature": 0.7,                    # Creatividad (0-2)
    "top_p": 0.9,                         # Nucleus sampling
    "top_k": 40,                          # Opciones top-k
    "frequency_penalty": 0.0,             # Penalizar repetición
    "presence_penalty": 0.0,              # Penalizar tópicos nuevos

    # ===== LÍMITES =====
    "max_tokens": 2000,                   # Máximo output
    "max_completion_tokens": 2000,        # Alternativo

    # ===== CONTROL =====
    "timeout": 120,                       # Segundos para respuesta
    "cache_seed": 42,                     # Para reproducibilidad
    "request_timeout": 300,               # Timeout de request

    # ===== FEATURES =====
    "seed": 42,                           # Seed para determinismo
    "extra_body": {...}                   # Parámetros extra del API
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_gestión_de_contexto">2.3.2. Gestión de Contexto</h4>
<div class="paragraph">
<p><strong>Historial de Mensajes:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Acceder al historial
conversation_history = assistant.chat_history

# Estructura de cada mensaje:
for msg in conversation_history:
    print(f"De: {msg['name']}")
    print(f"Rol: {msg['role']}")          # 'user' o 'assistant'
    print(f"Contenido: {msg['content']}")
    if 'function_call' in msg:
        print(f"Función: {msg['function_call']}")

# Modificar historial (cuidado)
# Útil para:
# - Guardar y cargar conversaciones
# - Analizar patrones
# - Debug
assistant.chat_history = new_history</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Límites de Contexto:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># El contexto tiene límites de tokens
# GPT-4: 8K tokens (~6000 palabras) o 32K tokens
# GPT-3.5: 4K tokens

# Estrategias para largo contexto:
# 1. Resumir después de cierto número de mensajes
def summarize_context(messages, max_messages=20):
    if len(messages) &gt; max_messages:
        # Guardar primeros X y últimos Y mensajes
        # Resumir los intermedios
        keep_first = max_messages // 2
        keep_last = max_messages // 2

        summary = create_summary(
            messages[keep_first:-keep_last]
        )

        return (messages[:keep_first] +
                [summary_msg] +
                messages[-keep_last:])
    return messages

# 2. Usar memoria externa
class ExternalMemory:
    def __init__(self):
        self.long_term = []  # Base de datos
        self.short_term = []  # Últimos N mensajes

    def add(self, message):
        self.short_term.append(message)
        if len(self.short_term) &gt; 10:
            self.long_term.append(self.short_term.pop(0))

    def get_context(self):
        return self.short_term + self.retrieve_relevant(from_long_term=True)

# 3. Use RAG (Retrieval Augmented Generation)
# Buscar documentos relevantes en lugar de cargar todo</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Persistencia de Conversaciones:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import json

# Guardar conversación
def save_conversation(agent, filename):
    with open(filename, 'w') as f:
        json.dump(agent.chat_history, f, indent=2)

# Cargar conversación
def load_conversation(agent, filename):
    with open(filename, 'r') as f:
        agent.chat_history = json.load(f)

# Usar:
save_conversation(assistant, "conversation.json")
load_conversation(assistant, "conversation.json")

# Estructura guardada:
# [
#   {
#     "role": "user",
#     "content": "¿Qué es Python?",
#     "name": "Usuario"
#   },
#   {...}
# ]</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_3_patrones_de_conversación">3. Módulo 3: Patrones de Conversación</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_3_1_conversaciones_dos_agentes">3.1. 3.1. Conversaciones Dos Agentes</h3>
<div class="sect3">
<h4 id="_patrón_pregunta_respuesta">3.1.1. Patrón Pregunta-Respuesta</h4>
<div class="paragraph">
<p><strong>Caso Simple:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">user_proxy.initiate_chat(
    assistant,
    message="¿Cuál es la raíz cuadrada de 16?",
    max_consecutive_auto_reply=1  # Solo 1 respuesta
)

# Flujo:
# User: "¿Cuál es la raíz cuadrada de 16?"
# Assistant: "La raíz cuadrada de 16 es 4"
# [FIN]</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Caso Iterativo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Primera pregunta
user_proxy.initiate_chat(
    assistant,
    message="¿Cuál es la raíz cuadrada de 16?",
    max_consecutive_auto_reply=5  # Permite más turnos
)

# El sistema permite:
# User -&gt; Assistant -&gt; User -&gt; Assistant -&gt; User
# hasta completar o alcanzar max_consecutive_auto_reply</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opciones de Configuración:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># control fino del diálogo
config = {
    # Parar después de X respuestas del assistant
    "max_consecutive_auto_reply": 5,

    # Parar si se alcanza número máximo de turnos
    "max_turns": 20,

    # Condición de término personalizada
    "is_termination_msg": lambda x: "LISTO" in x.get("content", ""),

    # Función para cambiar responsabilidad
    "next_turn": "auto"  # 'auto' o función personalizada
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_resolución_de_problemas_iterativa">3.1.2. Resolución de Problemas Iterativa</h4>
<div class="paragraph">
<p><strong>Patrón de Refinamiento:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Problema complejo que requiere iteración
user_proxy.initiate_chat(
    assistant,
    message="""Necesito optimizar esta función Python:

def fib(n):
    if n &lt;= 1:
        return n
    return fib(n-1) + fib(n-2)

Mejorala en términos de velocidad.""",
    max_consecutive_auto_reply=10  # Permitir múltiples turnos
)

# Flujo esperado:
# 1. User propone problema
# 2. Assistant analiza y propone solución
# 3. User puede proporcionar feedback
# 4. Assistant refina basado en feedback
# 5. Itera hasta solución satisfactoria</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Implementación del Feedback Loop:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IterativeAgent:
    def __init__(self, assistant, user_proxy):
        self.assistant = assistant
        self.user = user_proxy
        self.iterations = 0
        self.max_iterations = 5

    def solve(self, problem):
        """Resolver problema iterativamente"""
        solution = None
        feedback = None

        for i in range(self.max_iterations):
            self.iterations += 1

            if feedback:
                message = f"{problem}\n\nFeedback previo: {feedback}"
            else:
                message = problem

            # Obtener solución
            response = self.assistant.generate_response(message)
            solution = parse_solution(response)

            # Evaluar solución
            is_good, feedback = self.evaluate(solution)

            if is_good:
                return solution, self.iterations

        return solution, self.iterations

    def evaluate(self, solution):
        """Evaluar si solución es aceptable"""
        # Implementar lógica de evaluación
        # Retornar (es_aceptable, feedback_para_mejorar)
        pass</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_validación_de_respuestas">3.1.3. Validación de Respuestas</h4>
<div class="paragraph">
<p><strong>Patrón de Validación:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ValidatingUserProxy(UserProxyAgent):
    def __init__(self, validator_func, **kwargs):
        super().__init__(**kwargs)
        self.validator = validator_func

    def receive(self, message, sender, request_reply=None):
        """Recibir y validar mensaje"""
        # Validar antes de procesar
        if not self.validator(message):
            print("Respuesta no válida, solicitando aclaración")

            # Enviar mensaje de rechazo amable
            self.send(
                message="Tu respuesta no es válida. Por favor, asegúrate de...",
                recipient=sender
            )
        else:
            # Procesar normalmente
            super().receive(message, sender, request_reply)

# Ejemplo de validador
def validate_code(message):
    """Validar que el mensaje contiene código válido"""
    content = message.get("content", "")

    # Checks
    has_code = "```" in content or "def " in content
    has_explanation = len(content.split()) &gt; 10

    return has_code and has_explanation

# Usar
validator_proxy = ValidatingUserProxy(
    validator_func=validate_code,
    human_input_mode="NEVER"
)</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_4_capacidades_avanzadas">4. Módulo 4: Capacidades Avanzadas</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_4_1_ejecución_de_código">4.1. 4.1. Ejecución de Código</h3>
<div class="sect3">
<h4 id="_code_execution_segura">4.1.1. Code Execution Segura</h4>
<div class="paragraph">
<p>La ejecución de código es una de las características más poderosas de AutoGen, pero también la más peligrosa. Es fundamental entender las opciones de seguridad disponibles.</p>
</div>
<div class="paragraph">
<p><strong>Comparativa de Opciones de Ejecución:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">OPCIÓN 1: Ejecución Local (use_docker=False)

Seguridad:      ⚠️ BAJA
                - Código tiene acceso completo al sistema
                - Puede leer archivos sensibles
                - Puede hacer network requests
                - Puede modificar filesystem

Velocidad:      ⚡ MUY RÁPIDA
                - 100ms por ejecución típicamente

Requisitos:     Todas las dependencias instaladas localmente

Uso recomendado: SOLO desarrollo local de confianza

CASO DE USO:
  ✓ Prototipos rápidos
  ✓ Testing durante desarrollo
  ✗ NUNCA en producción
  ✗ NUNCA con código untrusted

Ejemplo:
  user_proxy = UserProxyAgent(
      code_execution_config={
          "use_docker": False,
          "work_dir": "./workspace",
          "timeout": 30
      }
  )

RIESGOS REALES:
  - rm -rf / (borra todo el sistema)
  - import socket; socket.send_to(attacker)  (exfiltración de datos)
  - subprocess.call(['malicious_command'])

---

OPCIÓN 2: Ejecución en Docker (use_docker=True) [RECOMENDADO]

Seguridad:      ✅ ALTA
                - Código aislado del host
                - Acceso limitado a filesystem
                - Network sandbox
                - Recursos limitables
                - Usuario no-root por defecto

Velocidad:      ⚡ RÁPIDA
                - ~500-2000ms por ejecución
                - Lentitud principalmente en startup de container

Requisitos:     Docker instalado y funcionando

Uso recomendado: Producción, testing, código untrusted

CASO DE USO:
  ✓ Producción (seguridad crítica)
  ✓ Ejecución de código potencialmente malicioso
  ✓ Sistemas multi-tenant
  ⚠️ Puede ser lento para operaciones repetidas

Ejemplo recomendado para producción:
  user_proxy = UserProxyAgent(
      code_execution_config={
          "use_docker": True,
          "docker_image": "python:3.11-slim",
          "work_dir": "/workspace",
          "timeout": 60,
          "docker_memory": "2g",      # Limitar a 2GB
          "docker_cpus": "1.0"        # Limitar a 1 CPU
      }
  )

---

OPCIÓN 3: Sin Ejecución (code_execution_config=False)

Seguridad:      ✅✅ MÁXIMA
                - No se ejecuta código en absoluto
                - Solo análisis estático

Velocidad:      ⚡⚡ INSTANTÁNEO
                - Cero overhead

Requisitos:     Ninguno

Uso recomendado: Solo si realmente no necesitas ejecución

CASO DE USO:
  ✓ Solo análisis/revisión de código
  ✓ Máxima seguridad pero menos útil
  ⚠️ Pierdes la capacidad de validar que el código funciona

Ejemplo:
  user_proxy = UserProxyAgent(
      code_execution_config=False
  )

DESVENTAJAS:
  - El asistente no puede validar su código
  - Más probabilidad de código con bugs
  - No hay feedback de ejecución

---

COMPARATIVA RESUMIDA:

┌────────────────┬─────────────┬───────────┬──────────────┐
│ Aspecto        │ Local       │ Docker    │ Sin exec.    │
├────────────────┼─────────────┼───────────┼──────────────┤
│ Seguridad      │ ⚠️ Baja     │ ✅ Alta   │ ✅✅ Máxima │
│ Velocidad      │ ⚡ Muy rápido│ ⚡ Rápido  │ ⚡⚡ Instant │
│ Confiabilidad  │ ⚠️ Baja     │ ✅ Alta   │ ⚠️ Media    │
│ Producción     │ ✗ NO        │ ✅ SÍ     │ ✓ Parcial   │
│ Desarrollo     │ ✅ SÍ       │ ✅ SÍ     │ ✓ Parcial   │
└────────────────┴─────────────┴───────────┴──────────────┘

RECOMENDACIÓN:
  - DESARROLLO LOCAL: use_docker=False (rápido)
  - TESTING AUTOMATIZADO: use_docker=True (seguro)
  - PRODUCCIÓN: use_docker=True (OBLIGATORIO)
  - MÁXIMA SEGURIDAD: code_execution_config=False</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opciones de Ejecución en Detalle:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Opción 1: Local (Rápido, pero riesgoso)
user_proxy = UserProxyAgent(
    name="Usuario",
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": False,
        "timeout": 30
    }
)

# Opción 2: Docker (Seguro, recomendado)
user_proxy = UserProxyAgent(
    name="Usuario",
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": True,
        "docker_image": "python:3.11-slim",
        "timeout": 60
    }
)

# Opción 3: Docker con limites de recursos
user_proxy = UserProxyAgent(
    name="Usuario",
    code_execution_config={
        "work_dir": "./workspace",
        "use_docker": True,
        "docker_image": "python:3.11-slim",
        "timeout": 30,
        "docker_memory": "2g",      # Limitar memoria
        "docker_cpus": "1.0",       # Limitar CPUs
        "docker_user": "nobody"     # Usuario no-privilegiado
    }
)

# Opción 4: Remoto con Docker
user_proxy = UserProxyAgent(
    name="Usuario",
    code_execution_config={
        "work_dir": "/tmp",
        "use_docker": True,
        "docker_host": "ssh://user@remote.server"
    }
)

# Opción 5: Sin ejecución (Solo análisis)
user_proxy = UserProxyAgent(
    name="Usuario",
    code_execution_config=False
)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Configuración Avanzada de Sandbox:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">                "error": "Timeout: código tardó demasiado",
                "suggestion": "Optimizar o dividir el código"
            }

        except SyntaxError as e:
            return {
                "success": False,
                "error": f"Error de sintaxis: {e}",
                "suggestion": "Verificar paréntesis y indentación"
            }
**Configuración Avanzada de Sandbox:**</code></pre>
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Configuración SEGURA recomendada para PRODUCCIÓN
production_config = {
    # Directorio de trabajo aislado
    "work_dir": "/sandbox/workspace",

    # AISLAMIENTO CON DOCKER (OBLIGATORIO)
    "use_docker": True,
    "docker_image": "python:3.11-slim",  # Imagen minimal

    # LÍMITES DE RECURSOS
    "docker_memory": "2g",        # Máximo 2GB RAM
    "docker_cpus": "1.0",         # Máximo 1 CPU
    "timeout": 30,                # Máximo 30 segundos por ejecución

    # SEGURIDAD ADICIONAL
    "docker_user": "nobody",      # No root
    "docker_network_disabled": True,  # No network access

    # VOLÚMENES MONTADOS (si necesario)
    "docker_volumes": {
        "/secure/input": "/input",   # Solo lectura datos de entrada
    },

    # LOGGING Y AUDITORÍA
    "log_directory": "/var/log/autogen",
    "verbose": True
}

user_proxy = UserProxyAgent(
    name="Usuario",
    code_execution_config=production_config
)

# CONFIGURACIÓN RÁPIDA para desarrollo local
dev_config = {
    "work_dir": "./workspace",
    "use_docker": False,  # Rápido para desarrollo
    "timeout": 30
}

# CONFIGURACIÓN SEGURA MÍNIMA
minimal_secure = {
    "work_dir": "./workspace",
    "use_docker": True,
    "timeout": 30
}</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_manejo_avanzado_de_errores_en_code_execution">4.1.2. Manejo Avanzado de Errores en Code Execution</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class RobustCodeExecutor(UserProxyAgent):
    """Ejecutor de código con manejo robusto de errores y recuperación"""

    def __init__(self, max_retries=3, **kwargs):
        super().__init__(**kwargs)
        self.max_retries = max_retries
        self.execution_history = []

    def execute_code(self, code):
        """Ejecutar código con recuperación automática de errores"""

        for attempt in range(self.max_retries):
            try:
                result = super().execute_code(code)
                self.execution_history.append({
                    "code": code,
                    "status": "success",
                    "result": result,
                    "attempt": attempt + 1
                })
                return {"success": True, "result": result, "attempts": attempt + 1}

            except TimeoutError as e:
                self.execution_history.append({
                    "code": code,
                    "status": "timeout",
                    "attempt": attempt + 1
                })
                if attempt == self.max_retries - 1:
                    return {
                        "success": False,
                        "error": "Timeout: el código tardó demasiado",
                        "suggestion": "Optimizar o dividir en partes más pequeñas",
                        "attempts": attempt + 1
                    }

            except SyntaxError as e:
                return {
                    "success": False,
                    "error": f"Error de sintaxis: {e}",
                    "line": e.lineno,
                    "suggestion": "Revisar paréntesis, indentación y comillas"
                }

            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)

                self.execution_history.append({
                    "code": code,
                    "status": f"error_{error_type}",
                    "error": error_msg,
                    "attempt": attempt + 1
                })

                if attempt &lt; self.max_retries - 1:
                    # Intentar arreglar automáticamente
                    print(f"Intento {attempt + 1} falló con {error_type}, reintentando...")
                else:
                    return {
                        "success": False,
                        "error": f"Error: {error_type}: {error_msg}",
                        "attempts": attempt + 1,
                        "suggestion": "Revisar la lógica del código"
                    }

    def auto_fix_and_retry(self, code, error_info):
        """Intentar arreglar automáticamente y reintentar"""
        fix_prompt = f"""El código falló con este error:

Error: {error_info['error']}

Código original:
```python
{code}
```

Por favor, arregla el código para que funcione correctamente.
Asegúrate de:
1. Corregir la causa del error
2. Mantener la funcionalidad original
3. Incluir validaciones de entrada"""

        # Usar LLM para generar fix (requiere acceso a LLM)
        # fixed_code = self.ask_assistant_for_fix(fix_prompt)
        # return self.execute_code(fixed_code)
        return {"status": "needs_manual_fix", "prompt": fix_prompt}

    def get_execution_summary(self):
        """Resumen de todas las ejecuciones"""
        successful = sum(1 for h in self.execution_history if h["status"] == "success")
        failed = len(self.execution_history) - successful

        return {
            "total_executions": len(self.execution_history),
            "successful": successful,
            "failed": failed,
            "success_rate": successful / len(self.execution_history) if self.execution_history else 0,
            "history": self.execution_history
        }</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_mejores_prácticas_en_code_execution">4.1.3. Mejores Prácticas en Code Execution</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">MEJORES PRÁCTICAS:

1. SIEMPRE usar Docker en producción
   ✓ use_docker=True (OBLIGATORIO)
   ✓ docker_memory limite específico
   ✓ docker_user non-root

2. NUNCA confiar en código generado sin validación
   ✓ Revisar código antes de ejecutar
   ✓ Usar máximo 30-60 segundos timeout
   ✓ Ejecutar con privilegios mínimos

3. IMPLEMENTAR timeouts razonables
   ✓ 30-60 segundos para la mayoría de tareas
   ✓ Dividir tareas largas en partes
   ✓ Caché resultados para evitar repetir

4. MONITOREO Y LOGGING
   ✓ Registrar todas las ejecuciones
   ✓ Alertar en errores inesperados
   ✓ Mantener historial para auditoría

5. GESTIÓN DE DEPENDENCIAS
   ✓ Especificar versiones exactas en requirements
   ✓ Pre-instalar dependencias seguras
   ✓ Evitar instalar packages en tiempo de ejecución

RIESGOS RESIDUALES:

Incluso con Docker:
  ⚠️ Algoritmos muy complejos pueden consumir CPU
  ⚠️ Código en bucles infinitos consume timeout
  ⚠️ Side effects de librerías pueden causar problemas

Mitigación:
  ✓ Revisión de código generado por LLM
  ✓ Testing antes de ejecutar en producción
  ✓ Monitoreo de recursos
  ✓ Alertas automáticas</code></pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_4_2_function_calling">4.2. 4.2. Function Calling</h3>
<div class="sect3">
<h4 id="_definición_y_registro_de_funciones">4.2.1. Definición y Registro de Funciones</h4>
<div class="paragraph">
<p><strong>Concepto:</strong></p>
</div>
<div class="paragraph">
<p>Function calling permite que los agentes LLM ejecuten funciones específicas automáticamente. El LLM decide si necesita llamar una función, qué función, y con qué parámetros.</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Funciones que los agentes pueden invocar
def calculate_compound_interest(
    principal: float,
    rate: float,
    years: int,
    compounds_per_year: int = 12
) -&gt; float:
    """
    Calcular interés compuesto

    Args:
        principal: Cantidad inicial
        rate: Tasa de interés anual (ej: 0.05 para 5%)
        years: Número de años
        compounds_per_year: Frecuencia de capitalización

    Returns:
        Cantidad final incluyendo interés
    """
    return principal * (1 + rate/compounds_per_year) ** (compounds_per_year * years)

def fetch_weather(city: str) -&gt; dict:
    """
    Obtener pronóstico del tiempo

    Args:
        city: Nombre de la ciudad

    Returns:
        dict con temperatura, condiciones, etc.
    """
    # Implementación real llamaría a API
    return {
        "city": city,
        "temp": 22,
        "condition": "Soleado"
    }

# Registrar con el agente
assistant = AssistantAgent(
    name="Asistente",
    function_map={
        "calculate_compound_interest": calculate_compound_interest,
        "fetch_weather": fetch_weather
    },
    llm_config=llm_config
)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_invocación_automática_de_funciones">4.2.2. Invocación Automática de Funciones</h4>
<div class="paragraph">
<p><strong>Cómo funciona:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">FLUJO DE FUNCTION CALLING:

1. User: "¿Cuál será el valor de 1000€ al 5% en 10 años?"

2. LLM (Assistant) decide:
   "Necesito calculate_compound_interest"

3. LLM envía solicitud de function call:
   {
     "function": "calculate_compound_interest",
     "parameters": {
       "principal": 1000,
       "rate": 0.05,
       "years": 10
     }
   }

4. UserProxy ejecuta la función:
   resultado = calculate_compound_interest(1000, 0.05, 10)
   resultado = 1647.01

5. UserProxy devuelve resultado al LLM:
   "Resultado: 1647.01"

6. LLM interpreta resultado y responde:
   "El valor será 1647.01€"

VENTAJAS:

✓ El LLM decide automáticamente si necesita una función
✓ Extrae parámetros correctamente
✓ Maneja errores y reintentos
✓ Capaz de usar múltiples funciones en secuencia
✓ Loop automático hasta solución correcta</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Ejemplo Completo:</strong></p>
</div>
<div class="paragraph">
<p>El agente decide automáticamente si usar funciones:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">user_proxy.initiate_chat(
    assistant,
    message="""¿Cuál sería el valor final de una inversión de 1000
              euros a 5% anual durante 10 años, capitalizado mensualmente?"""
)

Flujo:
1. User envía pregunta
2. Assistant reconoce que necesita calcular interés compuesto
3. Assistant llama a calculate_compound_interest(1000, 0.05, 10, 12)
4. Obtiene resultado: 1645.68
5. Proporciona respuesta: "El valor final sería 1645.68 euros"</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_parámetros_y_esquemas">4.2.3. Parámetros y Esquemas</h4>
<div class="paragraph">
<p>Los esquemas se generan automáticamente de los type hints:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-none hljs">def search_products(
    query: str,              # Requerido: string
    price_max: float = None, # Opcional: float
    brand: str = None,       # Opcional: string
    in_stock: bool = True    # Opcional: bool
) -&gt; list:
    """
    Buscar productos en el catálogo

    Args:
        query: Término de búsqueda
        price_max: Precio máximo (opcional)
        brand: Marca específica (opcional)
        in_stock: Solo en stock (default True)

    Returns:
        Lista de productos encontrados
    """
    pass

El esquema generado automáticamente:
{
  "name": "search_products",
  "description": "Buscar productos...",
  "parameters": {
    "type": "object",
    "properties": {
      "query": {"type": "string"},
      "price_max": {"type": "number"},
      "brand": {"type": "string"},
      "in_stock": {"type": "boolean"}
    },
    "required": ["query"]
  }
}
----    Args:
        query: Término de búsqueda
        price_max: Precio máximo (opcional)
        brand: Marca específica (opcional)
        in_stock: Solo en stock (default True)

    Returns:
        Lista de productos encontrados
    """
    pass

# El esquema generado automáticamente:
# {
#   "name": "search_products",
#   "description": "Buscar productos...",
#   "parameters": {
#     "type": "object",
#     "properties": {
#       "query": {"type": "string"},
#       "price_max": {"type": "number"},
#       "brand": {"type": "string"},
#       "in_stock": {"type": "boolean"}
#     },
#     "required": ["query"]
#   }
# }</code></pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_5_agentes_especializados">5. Módulo 5: Agentes Especializados</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_5_1_agentes_personalizados_avanzados">5.1. 5.1. Agentes Personalizados Avanzados</h3>
<div class="sect3">
<h4 id="_creación_de_clases_de_agentes">5.1.1. Creación de Clases de Agentes</h4>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from autogen import AssistantAgent

class CodeReviewAgent(AssistantAgent):
    """Agente especializado en revisión de código"""

    def __init__(self, name="CodeReviewer", **kwargs):
        system_message = """Eres un experto revisor de código.
        Tu trabajo es:
        1. Identificar bugs y problemas potenciales
        2. Evaluar la calidad del código
        3. Sugerir mejoras y refactoring
        4. Verificar seguridad
        5. Comprobar eficiencia

        Proporciona feedback constructivo y específico."""

        super().__init__(
            name=name,
            system_message=system_message,
            **kwargs
        )

        # Adicionar funcionalidades personalizadas
        self.review_criteria = [
            "readability",
            "efficiency",
            "security",
            "maintainability",
            "testing"
        ]

    def score_code(self, code: str) -&gt; dict:
        """Evaluar código en múltiples dimensiones"""
        scores = {}
        for criterion in self.review_criteria:
            scores[criterion] = self.evaluate_criterion(code, criterion)
        return scores

    def evaluate_criterion(self, code: str, criterion: str) -&gt; float:
        """Evaluar código en un criterio específico"""
        # Implementación de evaluación
        pass

# Uso
reviewer = CodeReviewAgent(
    llm_config={"config_list": [{"model": "gpt-4", "api_key": "..."}]}
)

user_proxy.initiate_chat(
    reviewer,
    message="¿Puedes revisar este código?\n" + code_to_review
)</code></pre>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_patrones_de_diseño">5.1.2. Patrones de Diseño</h4>
<div class="paragraph">
<p><strong>Patrón 1: Herencia Simple</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class SpecializedAssistant(AssistantAgent):
    """Base para asistentes especializados"""

    def __init__(self, specialty: str, **kwargs):
        self.specialty = specialty
        system_msg = f"Eres un experto en {specialty}"
        super().__init__(system_message=system_msg, **kwargs)

class PythonExpert(SpecializedAssistant):
    def __init__(self, **kwargs):
        super().__init__(specialty="Python", **kwargs)

class JavaScriptExpert(SpecializedAssistant):
    def __init__(self, **kwargs):
        super().__init__(specialty="JavaScript", **kwargs)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón 2: Composición</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class CompositePipeline:
    """Sistema que compone múltiples agentes"""

    def __init__(self):
        self.implementer = AssistantAgent(name="Implementador")
        self.reviewer = AssistantAgent(name="Revisor")
        self.tester = AssistantAgent(name="Tester")

    def process(self, request):
        # Flujo: implementador -&gt; revisor -&gt; tester
        impl_result = self.implementer.process(request)
        review_result = self.reviewer.process(impl_result)
        test_result = self.tester.process(review_result)
        return test_result</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Patrón 3: Decoradores</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">def with_logging(AgentClass):
    """Decorador para añadir logging a agentes"""

    class LoggedAgent(AgentClass):
        def __init__(self, *args, **kwargs):
            super().__init__(*args, **kwargs)
            self.logs = []

        def generate_response(self, message):
            self.logs.append(f"INPUT: {message}")
            response = super().generate_response(message)
            self.logs.append(f"OUTPUT: {response}")
            return response

    return LoggedAgent

@with_logging
class LoggedAssistant(AssistantAgent):
    pass</code></pre>
</div>
</div>
<div class="paragraph">
<p>Este es un documento significativamente expandido. Déjame continuar con más módulos&#8230;&#8203;</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_5_2_agentes_multi_modalidad">5.2. 5.2. Agentes Multi-Modalidad</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Agentes que pueden procesar múltiples tipos de entrada (texto, imagen, audio) y generar salidas en diferentes formatos.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Agente Multi-Modal Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class MultiModalAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.supported_formats = ["text", "image", "audio"]

    def process_image(self, image_path):
        """Procesar imagen y extraer contenido"""
        # Convertir imagen a descripción textual
        description = self.describe_image(image_path)
        return self.generate_response(f"Imagen: {description}")

    def process_audio(self, audio_path):
        """Procesar audio y transcribir"""
        # Transcribir audio a texto
        transcript = self.transcribe_audio(audio_path)
        return self.generate_response(f"Audio: {transcript}")

    def generate_multimodal_output(self, prompt):
        """Generar salida en múltiples formatos"""
        text_response = self.generate_response(prompt)
        image_url = self.generate_image(prompt)
        return {
            "text": text_response,
            "image": image_url,
            "format": "multimodal"
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Agente Multi-Modal con Vision API</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import anthropic

class VisionAgent(AssistantAgent):
    def __init__(self, name, api_key):
        super().__init__(name, api_key)
        self.client = anthropic.Anthropic(api_key=api_key)

    def analyze_image_with_vision(self, image_path, task):
        """Usar Vision API para análisis de imágenes"""
        with open(image_path, "rb") as img_file:
            image_data = img_file.read()

        message = self.client.messages.create(
            model="claude-3-vision-20240229",
            max_tokens=1024,
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/jpeg",
                                "data": image_data
                            }
                        },
                        {
                            "type": "text",
                            "text": task
                        }
                    ]
                }
            ]
        )
        return message.content[0].text

    def extract_text_from_document(self, document_path):
        """Extraer texto de documentos con OCR"""
        response = self.analyze_image_with_vision(
            document_path,
            "Extrae todo el texto visible en esta imagen"
        )
        return response</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Agente Multi-Modal Avanzado con Streaming</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class AdvancedMultiModalAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.input_queue = []
        self.output_formats = ["text", "json", "markdown", "html"]

    def process_mixed_content(self, inputs):
        """Procesar múltiples tipos de contenido en secuencia"""
        results = {}

        for input_item in inputs:
            if input_item["type"] == "text":
                results[input_item["id"]] = self.process_text(input_item["content"])
            elif input_item["type"] == "image":
                results[input_item["id"]] = self.process_image(input_item["content"])
            elif input_item["type"] == "audio":
                results[input_item["id"]] = self.process_audio(input_item["content"])

        return results

    def generate_formatted_output(self, content, output_format):
        """Generar salida en formato especificado"""
        if output_format == "json":
            return json.dumps(content, indent=2)
        elif output_format == "markdown":
            return self.to_markdown(content)
        elif output_format == "html":
            return self.to_html(content)
        else:
            return str(content)</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Procesamiento de múltiples tipos de entrada</p>
</li>
<li>
<p>✅ Generación de salidas diversas</p>
</li>
<li>
<p>✅ Integración con APIs de visión</p>
</li>
<li>
<p>✅ Manejo de formatos variados</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Casos de Uso:</strong></div>
<ul>
<li>
<p>Análisis de documentos escaneados</p>
</li>
<li>
<p>Procesamiento de imágenes médicas</p>
</li>
<li>
<p>Análisis de gráficos y diagramas</p>
</li>
<li>
<p>Transcripción de reuniones</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_5_3_agentes_de_memoria_extendida">5.3. 5.3. Agentes de Memoria Extendida</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Agentes que mantienen contexto histórico sofisticado y pueden recordar información a largo plazo.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Memoria Simple con Persistencia</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class MemoryAgent(AssistantAgent):
    def __init__(self, name, llm_config, memory_file="memory.json"):
        super().__init__(name, llm_config)
        self.memory_file = memory_file
        self.long_term_memory = self.load_memory()
        self.short_term_memory = []

    def load_memory(self):
        """Cargar memoria persistida"""
        try:
            with open(self.memory_file, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {"facts": [], "patterns": [], "relationships": []}

    def save_memory(self):
        """Guardar memoria a archivo"""
        with open(self.memory_file, 'w') as f:
            json.dump(self.long_term_memory, f, indent=2)

    def add_memory(self, category, content):
        """Agregar contenido a memoria"""
        if category not in self.long_term_memory:
            self.long_term_memory[category] = []

        memory_entry = {
            "content": content,
            "timestamp": datetime.now().isoformat(),
            "importance": self.calculate_importance(content)
        }
        self.long_term_memory[category].append(memory_entry)
        self.save_memory()

    def retrieve_memory(self, query, category=None):
        """Buscar en memoria"""
        if category:
            items = self.long_term_memory.get(category, [])
        else:
            items = sum(self.long_term_memory.values(), [])

        # Búsqueda simple (podría usar embeddings)
        results = [item for item in items if query.lower() in item["content"].lower()]
        return sorted(results, key=lambda x: x["importance"], reverse=True)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Memoria con Embeddings y Búsqueda Semántica</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class SemanticMemoryAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.memory_database = []
        self.embedding_model = self.load_embedding_model()

    def load_embedding_model(self):
        """Cargar modelo de embeddings"""
        try:
            from sentence_transformers import SentenceTransformer
            return SentenceTransformer('all-MiniLM-L6-v2')
        except ImportError:
            print("Instala: pip install sentence-transformers")
            return None

    def store_memory_with_embedding(self, content):
        """Guardar contenido con embedding"""
        embedding = self.embedding_model.encode(content)
        memory_item = {
            "content": content,
            "embedding": embedding,
            "timestamp": datetime.now().isoformat(),
            "access_count": 0
        }
        self.memory_database.append(memory_item)
        return memory_item

    def semantic_search(self, query, top_k=5):
        """Búsqueda semántica en memoria"""
        query_embedding = self.embedding_model.encode(query)

        similarities = []
        for item in self.memory_database:
            similarity = cosine_similarity(
                [query_embedding],
                [item["embedding"]]
            )[0][0]
            similarities.append((item, similarity))

        # Ordenar por similitud
        top_results = sorted(similarities, key=lambda x: x[1], reverse=True)[:top_k]

        # Actualizar contador de acceso
        for item, _ in top_results:
            item["access_count"] += 1

        return [item for item, _ in top_results]

    def get_memory_summary(self):
        """Generar resumen de memoria"""
        total_items = len(self.memory_database)
        most_accessed = sorted(
            self.memory_database,
            key=lambda x: x["access_count"],
            reverse=True
        )[:5]

        return {
            "total_memories": total_items,
            "most_accessed": [item["content"] for item in most_accessed]
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Sistema de Memoria Jerárquico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class HierarchicalMemoryAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.working_memory = []      # Información actual (corto plazo)
        self.episodic_memory = []     # Eventos/conversaciones
        self.semantic_memory = {}     # Hechos/conocimiento
        self.procedural_memory = []   # Skills/procedimientos

    def categorize_and_store(self, information, info_type):
        """Almacenar información en categoría apropiada"""
        if info_type == "current":
            self.working_memory.append({
                "content": information,
                "timestamp": datetime.now().isoformat()
            })
        elif info_type == "episode":
            self.episodic_memory.append({
                "event": information,
                "timestamp": datetime.now().isoformat()
            })
        elif info_type == "semantic":
            key = information.get("key")
            self.semantic_memory[key] = information.get("value")
        elif info_type == "procedural":
            self.procedural_memory.append({
                "procedure": information,
                "learned_at": datetime.now().isoformat()
            })

    def consolidate_memory(self):
        """Consolidar memoria de trabajo a memoria de largo plazo"""
        # Mover items importantes de working memory a episodic
        important_items = [item for item in self.working_memory
                          if self.is_important(item)]

        for item in important_items:
            self.episodic_memory.append(item)

        self.working_memory = [item for item in self.working_memory
                              if not self.is_important(item)]

    def recall_context(self, query):
        """Recuperar contexto relevante para consulta"""
        relevant_memories = {
            "semantic": [v for k, v in self.semantic_memory.items()
                        if query.lower() in str(v).lower()],
            "episodic": [e for e in self.episodic_memory
                        if query.lower() in str(e).lower()],
            "procedures": [p for p in self.procedural_memory
                          if query.lower() in str(p).lower()]
        }
        return relevant_memories</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Persistencia de información</p>
</li>
<li>
<p>✅ Búsqueda semántica</p>
</li>
<li>
<p>✅ Organización jerárquica</p>
</li>
<li>
<p>✅ Consolidación de memoria</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Aplicaciones:</strong></div>
<ul>
<li>
<p>Sistemas de soporte que mejoran con el tiempo</p>
</li>
<li>
<p>Asistentes personales</p>
</li>
<li>
<p>Análisis histórico de proyectos</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_5_4_agentes_de_aprendizaje_autónomo">5.4. 5.4. Agentes de Aprendizaje Autónomo</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Agentes que mejoran su rendimiento automáticamente a través de interacción y retroalimentación.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Agente con Aprendizaje por Refuerzo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ReinforcementLearningAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.success_count = 0
        self.failure_count = 0
        self.strategy_effectiveness = {}
        self.learning_rate = 0.1

    def learn_from_feedback(self, action, feedback, reward):
        """Aprender de retroalimentación"""
        strategy = action.get("strategy")

        if strategy not in self.strategy_effectiveness:
            self.strategy_effectiveness[strategy] = {"score": 0, "count": 0}

        # Actualizar puntuación con rata de aprendizaje
        old_score = self.strategy_effectiveness[strategy]["score"]
        new_score = old_score + self.learning_rate * (reward - old_score)

        self.strategy_effectiveness[strategy]["score"] = new_score
        self.strategy_effectiveness[strategy]["count"] += 1

        if reward &gt; 0:
            self.success_count += 1
        else:
            self.failure_count += 1

    def select_best_strategy(self, situation):
        """Seleccionar mejor estrategia basada en aprendizaje"""
        applicable_strategies = self.get_applicable_strategies(situation)

        if not applicable_strategies:
            return self.random_strategy()

        # Epsilon-greedy: exploración vs explotación
        epsilon = 0.1
        if np.random.random() &lt; epsilon:
            return np.random.choice(applicable_strategies)
        else:
            return max(applicable_strategies,
                      key=lambda s: self.strategy_effectiveness.get(s, {}).get("score", 0))

    def get_performance_metrics(self):
        """Obtener métricas de aprendizaje"""
        total = self.success_count + self.failure_count
        if total == 0:
            return {"success_rate": 0, "strategies_learned": 0}

        return {
            "success_rate": self.success_count / total,
            "total_interactions": total,
            "strategies_learned": len(self.strategy_effectiveness),
            "best_strategy": max(self.strategy_effectiveness.items(),
                               key=lambda x: x[1]["score"])[0]
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Agente con Fine-Tuning Continuo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ContinuousLearningAgent(AssistantAgent):
    def __init__(self, name, llm_config, fine_tune_threshold=10):
        super().__init__(name, llm_config)
        self.training_examples = []
        self.fine_tune_threshold = fine_tune_threshold
        self.fine_tune_count = 0

    def collect_training_example(self, input_text, correct_output, user_feedback):
        """Recolectar ejemplo para fine-tuning"""
        if user_feedback == "correct":
            example = {
                "input": input_text,
                "output": correct_output,
                "quality_score": 1.0,
                "timestamp": datetime.now().isoformat()
            }
            self.training_examples.append(example)

    def prepare_fine_tune_dataset(self):
        """Preparar dataset para fine-tuning"""
        if len(self.training_examples) &lt; self.fine_tune_threshold:
            return None

        # Filtrar ejemplos de alta calidad
        high_quality = [ex for ex in self.training_examples
                       if ex.get("quality_score", 0) &gt;= 0.8]

        return {
            "training_examples": high_quality,
            "total_examples": len(high_quality),
            "data_quality": np.mean([ex["quality_score"] for ex in high_quality])
        }

    def trigger_fine_tune(self):
        """Disparar fine-tuning si hay suficientes datos"""
        dataset = self.prepare_fine_tune_dataset()
        if dataset:
            print(f"Fine-tuning con {dataset['total_examples']} ejemplos...")
            self.fine_tune_count += 1
            # Aquí llamaría a API de fine-tuning real
            return True
        return False</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Agente con Metacognición</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class MetacognitiveAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.confidence_scores = {}
        self.error_analysis = []
        self.improvement_strategies = {}

    def reflect_on_performance(self, task, result, actual_outcome):
        """Reflexionar sobre el desempeño"""
        analysis = {
            "task": task,
            "predicted": result,
            "actual": actual_outcome,
            "correct": result == actual_outcome,
            "timestamp": datetime.now().isoformat()
        }

        if not analysis["correct"]:
            self.analyze_error(analysis)
            self.identify_improvement_strategy(analysis)

        self.error_analysis.append(analysis)
        return analysis

    def analyze_error(self, error_analysis):
        """Analizar tipos de error"""
        error_type = self.classify_error(error_analysis)

        if error_type not in self.improvement_strategies:
            self.improvement_strategies[error_type] = {
                "occurrences": 0,
                "strategies": []
            }

        self.improvement_strategies[error_type]["occurrences"] += 1

    def identify_improvement_strategy(self, error_analysis):
        """Identificar estrategia de mejora"""
        error_type = self.classify_error(error_analysis)

        strategies = {
            "insufficient_context": "Pedir más contexto antes de responder",
            "misunderstanding": "Reformular la pregunta",
            "knowledge_gap": "Admitir limitación y buscar fuente externa",
            "reasoning_error": "Explicitar el razonamiento paso a paso"
        }

        return strategies.get(error_type, "Revisar base de conocimiento")

    def get_learning_report(self):
        """Reporte de aprendizaje"""
        total_attempts = len(self.error_analysis)
        correct = sum(1 for e in self.error_analysis if e["correct"])

        return {
            "accuracy": correct / total_attempts if total_attempts &gt; 0 else 0,
            "total_attempts": total_attempts,
            "error_types": self.improvement_strategies,
            "recommendations": self.generate_recommendations()
        }

    def generate_recommendations(self):
        """Generar recomendaciones de mejora"""
        recommendations = []

        for error_type, data in self.improvement_strategies.items():
            if data["occurrences"] &gt; 3:
                recommendations.append(
                    f"Error frecuente ({error_type}): {data['occurrences']} veces. "
                    "Requiere atención especial."
                )

        return recommendations</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Aprendizaje por refuerzo</p>
</li>
<li>
<p>✅ Fine-tuning continuo</p>
</li>
<li>
<p>✅ Autorreflexión</p>
</li>
<li>
<p>✅ Mejora iterativa</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Beneficios:</strong></div>
<ul>
<li>
<p>Mejor desempeño con el tiempo</p>
</li>
<li>
<p>Adaptación a casos nuevos</p>
</li>
<li>
<p>Identificación automática de debilidades</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_5_5_agentes_de_coordinación_multi_agente">5.5. 5.5. Agentes de Coordinación Multi-Agente</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Agentes especializados que coordinan su trabajo para resolver problemas complejos de forma colaborativa.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Gestor de Coordinación Centralizado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class CentralizedCoordinatorAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.agents = {}
        self.task_queue = []
        self.result_cache = {}

    def register_agent(self, agent_id, agent, specialization):
        """Registrar agente especializado"""
        self.agents[agent_id] = {
            "agent": agent,
            "specialization": specialization,
            "status": "idle",
            "completed_tasks": 0
        }

    def decompose_task(self, task):
        """Descomponer tarea en subtareas"""
        subtasks = []

        # Analizar qué especialidades se necesitan
        required_skills = self.analyze_required_skills(task)

        for skill in required_skills:
            subtask = {
                "task": task,
                "required_skill": skill,
                "status": "pending",
                "assigned_to": None,
                "result": None
            }
            subtasks.append(subtask)

        return subtasks

    def assign_task(self, subtask):
        """Asignar subtarea al agente más apropiado"""
        required_skill = subtask["required_skill"]

        # Buscar agente con especialización
        best_agent = None
        for agent_id, agent_info in self.agents.items():
            if agent_info["specialization"] == required_skill:
                if agent_info["status"] == "idle":
                    best_agent = agent_id
                    break

        if best_agent:
            subtask["assigned_to"] = best_agent
            self.agents[best_agent]["status"] = "busy"
            return True
        return False

    def execute_subtask(self, subtask):
        """Ejecutar subtarea asignada"""
        agent_id = subtask["assigned_to"]
        agent_info = self.agents[agent_id]
        agent = agent_info["agent"]

        result = agent.generate_response(subtask["task"])
        subtask["result"] = result
        subtask["status"] = "completed"

        agent_info["status"] = "idle"
        agent_info["completed_tasks"] += 1

        return result

    def synthesize_results(self, subtasks):
        """Sintetizar resultados de subtareas"""
        results_summary = {
            "subtask_results": [st["result"] for st in subtasks],
            "synthesis": self.generate_synthesis([st["result"] for st in subtasks])
        }
        return results_summary</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Coordinación Descentralizada con Protocolo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class DecentralizedCoordinatorAgent(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.peers = []
        self.message_queue = []
        self.consensus_threshold = 0.7

    def add_peer(self, peer_agent):
        """Agregar agente peer"""
        self.peers.append(peer_agent)

    def broadcast_message(self, message, message_type="request"):
        """Enviar mensaje a todos los peers"""
        msg = {
            "sender": self.name,
            "content": message,
            "type": message_type,
            "timestamp": datetime.now().isoformat(),
            "responses": []
        }

        for peer in self.peers:
            response = peer.handle_message(msg)
            msg["responses"].append({
                "from": peer.name,
                "response": response
            })

        return msg

    def reach_consensus(self, topic):
        """Alcanzar consenso entre agentes"""
        votes = {}

        for peer in self.peers:
            opinion = peer.get_opinion_on(topic)
            votes[peer.name] = opinion

        # Contar votos
        vote_counts = {}
        for opinion in votes.values():
            vote_counts[opinion] = vote_counts.get(opinion, 0) + 1

        # Verificar umbral de consenso
        total_votes = len(votes)
        max_votes = max(vote_counts.values())

        if max_votes / total_votes &gt;= self.consensus_threshold:
            consensus_decision = max(vote_counts, key=vote_counts.get)
            return {
                "consensus_reached": True,
                "decision": consensus_decision,
                "confidence": max_votes / total_votes
            }

        return {
            "consensus_reached": False,
            "votes": vote_counts,
            "confidence": max_votes / total_votes
        }

    def conflict_resolution(self, conflicting_opinions):
        """Resolver conflictos entre opiniones"""
        # Debate estructurado
        debate_rounds = []

        for round_num in range(3):
            round_arguments = []
            for opinion, agents in conflicting_opinions.items():
                for agent in agents:
                    argument = agent.present_argument(opinion)
                    round_arguments.append(argument)

            debate_rounds.append(round_arguments)

        # Seleccionar mejor argumento
        best_argument = self.evaluate_arguments(debate_rounds)
        return best_argument</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Coordinación Jerárquica Flexible</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class FlexibleHierarchyCoordinator(AssistantAgent):
    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.hierarchy = {}  # {level: [agents]}
        self.current_leader = None

    def build_hierarchy(self, agents, criteria="capability"):
        """Construir jerarquía dinámica"""
        if criteria == "capability":
            sorted_agents = sorted(agents, key=lambda a: a.capability_score, reverse=True)
        elif criteria == "experience":
            sorted_agents = sorted(agents, key=lambda a: a.experience, reverse=True)
        else:
            sorted_agents = agents

        # Distribuir en niveles
        num_levels = 3
        self.hierarchy = {}
        agents_per_level = len(sorted_agents) // num_levels

        for level in range(num_levels):
            start_idx = level * agents_per_level
            end_idx = start_idx + agents_per_level if level &lt; num_levels - 1 else len(sorted_agents)
            self.hierarchy[level] = sorted_agents[start_idx:end_idx]

        self.current_leader = self.hierarchy[0][0]  # Top agent es líder

    def delegate_to_appropriate_level(self, task):
        """Delegar tarea al nivel apropiado"""
        complexity = self.assess_complexity(task)

        if complexity == "simple":
            agent = self.hierarchy[2][0]  # Nivel bajo
        elif complexity == "moderate":
            agent = self.hierarchy[1][0]  # Nivel medio
        else:
            agent = self.current_leader  # Nivel alto

        return agent.execute_task(task)

    def rebalance_hierarchy(self, performance_data):
        """Rebalancear jerarquía basado en desempeño"""
        # Actualizar puntuaciones basadas en desempeño
        for agent, performance in performance_data.items():
            agent.capability_score = agent.capability_score * 0.8 + performance * 0.2

        # Reconstruir si hay cambios significativos
        current_leader_performance = performance_data.get(self.current_leader, 0)
        if current_leader_performance &lt; 0.5:
            self.build_hierarchy(list(self.hierarchy[0]))  # Reconstruir</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Coordinación centralizada y descentralizada</p>
</li>
<li>
<p>✅ Resolución de conflictos</p>
</li>
<li>
<p>✅ Consenso distribuido</p>
</li>
<li>
<p>✅ Jerarquías dinámicas</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Ventajas:</strong></div>
<ul>
<li>
<p>Mayor capacidad de resolución de problemas</p>
</li>
<li>
<p>Escalabilidad</p>
</li>
<li>
<p>Robustez ante fallos individuales</p>
</li>
<li>
<p>Especialización eficiente</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_6_optimización_y_costos">6. Módulo 6: Optimización y Costos</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_6_1_gestión_de_tokens">6.1. 6.1. Gestión de Tokens</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Monitoreo y optimización del consumo de tokens para reducir costos y mejorar rendimiento.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Gestor de Tokens Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class TokenManager:
    """Gestor básico de tokens y costos"""

    def __init__(self, model="gpt-4", pricing_per_1k=0.03):
        self.model = model
        self.pricing_per_1k = pricing_per_1k
        self.tokens_used = 0
        self.cost_accumulated = 0.0

    def estimate_tokens(self, text):
        """Estimación aproximada de tokens"""
        # Aproximadamente 4 caracteres = 1 token
        return len(text) // 4

    def calculate_cost(self, tokens):
        """Calcular costo basado en tokens"""
        cost = (tokens / 1000) * self.pricing_per_1k
        self.cost_accumulated += cost
        self.tokens_used += tokens
        return cost

    def get_cost_summary(self):
        """Resumen de costos"""
        return {
            "total_tokens": self.tokens_used,
            "total_cost": self.cost_accumulated,
            "avg_token_cost": self.cost_accumulated / max(self.tokens_used, 1)
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Optimizador de Prompts Avanzado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import tiktoken

class PromptOptimizer:
    """Optimizador de prompts para reducir tokens"""

    def __init__(self, model="gpt-4"):
        self.encoding = tiktoken.encoding_for_model(model)

    def count_tokens(self, text):
        """Contar tokens exactos usando tiktoken"""
        tokens = self.encoding.encode(text)
        return len(tokens)

    def compress_prompt(self, prompt, max_tokens=2000):
        """Comprimir prompt manteniendo semántica"""
        # Eliminar espacios excesivos
        compressed = " ".join(prompt.split())

        # Si es demasiado largo, resumir
        if self.count_tokens(compressed) &gt; max_tokens:
            # Tomar primeras líneas más importantes
            lines = compressed.split(".")
            result = []
            for line in lines:
                result.append(line.strip())
                if self.count_tokens(". ".join(result)) &gt; max_tokens:
                    result.pop()
                    break
            compressed = ". ".join(result)

        return compressed

    def suggest_improvements(self, prompt):
        """Sugerencias para mejorar tokens"""
        suggestions = []
        token_count = self.count_tokens(prompt)

        if len(prompt) &gt; 1000:
            suggestions.append("Considere acortar la descripción")
        if prompt.count("\n\n") &gt; 5:
            suggestions.append("Demasiados saltos de línea")
        if len(prompt.split()) &gt; 300:
            suggestions.append("Demasiadas palabras, intente ser más conciso")

        return {"tokens": token_count, "suggestions": suggestions}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Sistema de Monitoreo en Tiempo Real</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from datetime import datetime
from collections import defaultdict

class RealTimeTokenMonitor:
    """Monitoreo en tiempo real de tokens y costos"""

    def __init__(self, budget_limit=100.0):
        self.budget_limit = budget_limit
        self.transactions = []
        self.usage_by_agent = defaultdict(lambda: {"tokens": 0, "cost": 0})
        self.hourly_stats = defaultdict(lambda: {"tokens": 0, "cost": 0})

    def log_transaction(self, agent_name, tokens, cost, timestamp=None):
        """Registrar transacción de tokens"""
        if timestamp is None:
            timestamp = datetime.now()

        hour_key = timestamp.strftime("%Y-%m-%d %H:00")

        self.transactions.append({
            "agent": agent_name,
            "tokens": tokens,
            "cost": cost,
            "timestamp": timestamp
        })

        self.usage_by_agent[agent_name]["tokens"] += tokens
        self.usage_by_agent[agent_name]["cost"] += cost

        self.hourly_stats[hour_key]["tokens"] += tokens
        self.hourly_stats[hour_key]["cost"] += cost

    def get_budget_status(self):
        """Estado del presupuesto"""
        total_cost = sum(u["cost"] for u in self.usage_by_agent.values())
        remaining = self.budget_limit - total_cost
        percentage = (total_cost / self.budget_limit) * 100

        return {
            "budget_limit": self.budget_limit,
            "spent": total_cost,
            "remaining": remaining,
            "percentage_used": percentage,
            "within_budget": remaining &gt;= 0
        }

    def get_agent_ranking(self):
        """Ranking de agentes por consumo"""
        return sorted(
            self.usage_by_agent.items(),
            key=lambda x: x[1]["cost"],
            reverse=True
        )</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Estimación exacta de tokens con tiktoken</p>
</li>
<li>
<p>✅ Cálculo preciso de costos</p>
</li>
<li>
<p>✅ Compresión inteligente de prompts</p>
</li>
<li>
<p>✅ Monitoreo en tiempo real</p>
</li>
<li>
<p>✅ Alertas de presupuesto</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Casos de Uso:</strong></div>
<ul>
<li>
<p>Control de costos en producción</p>
</li>
<li>
<p>Optimización de prompts</p>
</li>
<li>
<p>Facturación por agente</p>
</li>
<li>
<p>Detección de anomalías en consumo</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_6_2_caché_y_reutilización">6.2. 6.2. Caché y Reutilización</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Sistema de caché para reutilizar respuestas y reducir llamadas redundantes al LLM.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Caché en Memoria Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import hashlib
from functools import lru_cache

class SimpleMemoryCache:
    """Caché en memoria con TTL básico"""

    def __init__(self, max_size=1000):
        self.cache = {}
        self.max_size = max_size
        self.hits = 0
        self.misses = 0

    def _hash_key(self, prompt):
        """Generar clave hash del prompt"""
        return hashlib.md5(prompt.encode()).hexdigest()

    def get(self, prompt):
        """Obtener del caché"""
        key = self._hash_key(prompt)
        if key in self.cache:
            self.hits += 1
            return self.cache[key]
        self.misses += 1
        return None

    def set(self, prompt, response):
        """Guardar en caché"""
        if len(self.cache) &gt;= self.max_size:
            # Eliminar entrada más antigua
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]

        key = self._hash_key(prompt)
        self.cache[key] = response

    def get_stats(self):
        """Estadísticas de caché"""
        total = self.hits + self.misses
        hit_rate = (self.hits / total * 100) if total &gt; 0 else 0
        return {
            "hits": self.hits,
            "misses": self.misses,
            "hit_rate": hit_rate,
            "size": len(self.cache)
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Caché Persistente con Redis</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import redis
import json
import pickle

class RedisCacheManager:
    """Caché persistente usando Redis"""

    def __init__(self, host='localhost', port=6379, ttl=3600):
        self.redis_client = redis.Redis(
            host=host,
            port=port,
            decode_responses=True
        )
        self.ttl = ttl

    def get(self, prompt):
        """Obtener del caché Redis"""
        key = self._hash_key(prompt)
        cached = self.redis_client.get(key)
        if cached:
            return json.loads(cached)
        return None

    def set(self, prompt, response):
        """Guardar en caché Redis"""
        key = self._hash_key(prompt)
        self.redis_client.setex(
            key,
            self.ttl,
            json.dumps(response)
        )

    def _hash_key(self, prompt):
        import hashlib
        return hashlib.md5(prompt.encode()).hexdigest()

    def clear_expired(self):
        """Limpiar entradas expiradas"""
        self.redis_client.flushdb()

    def get_cache_info(self):
        """Información del caché"""
        info = self.redis_client.info()
        return {
            "memory_used": info.get('used_memory_human'),
            "keys": self.redis_client.dbsize()
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Caché Inteligente con Similaridad Semántica</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from sentence_transformers import SentenceTransformer
import numpy as np

class SemanticCache:
    """Caché que busca respuestas para prompts similares"""

    def __init__(self, similarity_threshold=0.95):
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        self.cache = []
        self.similarity_threshold = similarity_threshold

    def get(self, prompt):
        """Buscar respuesta para prompt similar"""
        if not self.cache:
            return None

        # Encodeificar prompt actual
        prompt_embedding = self.model.encode(prompt)

        # Buscar el más similar
        best_match = None
        best_similarity = 0

        for cached_prompt, cached_response, cached_embedding in self.cache:
            # Calcular similitud coseno
            similarity = np.dot(
                prompt_embedding,
                cached_embedding
            ) / (np.linalg.norm(prompt_embedding) *
                 np.linalg.norm(cached_embedding))

            if similarity &gt; best_similarity:
                best_similarity = similarity
                best_match = cached_response

        if best_similarity &gt;= self.similarity_threshold:
            return best_match

        return None

    def set(self, prompt, response):
        """Guardar con embedding"""
        embedding = self.model.encode(prompt)
        self.cache.append((prompt, response, embedding))

    def get_similar_prompts(self, prompt, top_k=5):
        """Obtener prompts similares"""
        prompt_embedding = self.model.encode(prompt)
        similarities = []

        for cached_prompt, _, cached_embedding in self.cache:
            similarity = np.dot(
                prompt_embedding,
                cached_embedding
            ) / (np.linalg.norm(prompt_embedding) *
                 np.linalg.norm(cached_embedding))
            similarities.append((cached_prompt, similarity))

        return sorted(
            similarities,
            key=lambda x: x[1],
            reverse=True
        )[:top_k]</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Caché en memoria rápido</p>
</li>
<li>
<p>✅ Persistencia con Redis</p>
</li>
<li>
<p>✅ Búsqueda semántica de similitud</p>
</li>
<li>
<p>✅ TTL automático</p>
</li>
<li>
<p>✅ Estadísticas de eficiencia</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Ventajas:</strong></div>
<ul>
<li>
<p>Reducción de costo (50-80% en casos de uso repetitivos)</p>
</li>
<li>
<p>Mejora de latencia</p>
</li>
<li>
<p>Menor carga en LLM</p>
</li>
<li>
<p>Mejor experiencia de usuario</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_6_3_modelos_locales">6.3. 6.3. Modelos Locales</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Integración de modelos open-source locales para reducir costos manteniendo calidad.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Integración Ollama Avanzada</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import requests
import json

class AdvancedOllamaClient:
    """Cliente Ollama con caché y fallback"""

    def __init__(self, base_url="http://localhost:11434"):
        self.base_url = base_url
        self.available_models = []
        self.model_capabilities = {}
        self.refresh_models()

    def refresh_models(self):
        """Actualizar lista de modelos disponibles"""
        try:
            response = requests.get(f"{self.base_url}/api/tags")
            data = response.json()
            self.available_models = [m['name'] for m in data.get('models', [])]
        except:
            self.available_models = []

    def select_best_model(self, task_type):
        """Seleccionar mejor modelo según tarea"""
        model_rankings = {
            "code": ["mistral", "llama2", "neural-chat"],
            "analysis": ["mistral", "orca-mini", "llama2"],
            "creative": ["mistral", "neural-chat", "zephyr"],
            "fast": ["orca-mini", "neural-chat", "mistral"]
        }

        preferred = model_rankings.get(task_type, self.available_models)
        for model in preferred:
            if model in self.available_models:
                return model

        return self.available_models[0] if self.available_models else "mistral"

    def generate_with_fallback(self, prompt, task_type="general"):
        """Generar con fallback automático"""
        model = self.select_best_model(task_type)

        try:
            return self.generate(prompt, model)
        except:
            # Fallback a otro modelo
            for alt_model in self.available_models:
                if alt_model != model:
                    try:
                        return self.generate(prompt, alt_model)
                    except:
                        continue

        return "Error: No models available"

    def generate(self, prompt, model="mistral", temperature=0.7):
        """Generar respuesta"""
        payload = {
            "model": model,
            "prompt": prompt,
            "temperature": temperature,
            "stream": False
        }

        response = requests.post(
            f"{self.base_url}/api/generate",
            json=payload
        )

        if response.status_code == 200:
            return response.json().get('response', '')
        raise Exception(f"Error: {response.status_code}")</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Gestor de Modelos Multi-Proveedor</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from enum import Enum

class LLMProvider(Enum):
    OLLAMA = "ollama"
    HUGGINGFACE = "huggingface"
    LLAMA_CPP = "llama_cpp"

class MultiProviderLLMManager:
    """Gestor de múltiples proveedores de LLM"""

    def __init__(self):
        self.providers = {}
        self.active_provider = None

    def register_provider(self, name, provider):
        """Registrar proveedor"""
        self.providers[name] = provider
        if self.active_provider is None:
            self.active_provider = name

    def switch_provider(self, name):
        """Cambiar proveedor activo"""
        if name in self.providers:
            self.active_provider = name
            return True
        return False

    def generate(self, prompt, **kwargs):
        """Generar con proveedor activo"""
        if self.active_provider and self.active_provider in self.providers:
            provider = self.providers[self.active_provider]
            return provider.generate(prompt, **kwargs)
        raise Exception("No active provider")

    def get_provider_stats(self):
        """Estadísticas de proveedores"""
        stats = {}
        for name, provider in self.providers.items():
            stats[name] = {
                "status": "active" if name == self.active_provider else "inactive",
                "available": hasattr(provider, 'is_available') and provider.is_available()
            }
        return stats</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Sistema de Caché Multi-Modelo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class MultiModelCacheStrategy:
    """Estrategia de caché con preferencia de modelos"""

    def __init__(self, cache_manager, ollama_client):
        self.cache = cache_manager
        self.ollama = ollama_client
        self.model_preferences = {
            "code": {"local": "mistral", "weight": 0.8},
            "analysis": {"local": "llama2", "weight": 0.7},
            "general": {"local": "mistral", "weight": 0.75}
        }

    def get_or_generate(self, prompt, task_type="general"):
        """Obtener del caché o generar"""
        # Buscar en caché
        cached = self.cache.get(prompt)
        if cached:
            return cached, "cache"

        # Generar con modelo local preferido
        model = self.model_preferences[task_type]["local"]
        response = self.ollama.generate(prompt, model)

        # Guardar en caché
        self.cache.set(prompt, response)

        return response, "generated"

    def get_cost_comparison(self, prompt):
        """Comparar costos: API vs Local"""
        api_cost = len(prompt) / 4 * 0.00002  # Estimado OpenAI
        local_cost = 0  # Después del primer entrenamiento

        return {
            "api_cost": api_cost,
            "local_cost": local_cost,
            "savings": api_cost - local_cost
        }</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Soporte multi-modelo local</p>
</li>
<li>
<p>✅ Selección automática según tarea</p>
</li>
<li>
<p>✅ Fallback inteligente</p>
</li>
<li>
<p>✅ Gestión de múltiples proveedores</p>
</li>
<li>
<p>✅ Comparación de costos</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Ventajas:</strong></div>
<ul>
<li>
<p>Costo casi cero después de inversión inicial</p>
</li>
<li>
<p>Privacidad total</p>
</li>
<li>
<p>Funciona offline</p>
</li>
<li>
<p>Control completo</p>
</li>
<li>
<p>Customización completa</p>
</li>
</ul>
</div>
<div class="ulist">
<div class="title"><strong>Casos de Uso:</strong></div>
<ul>
<li>
<p>Empresas con restricciones de privacidad</p>
</li>
<li>
<p>Casos de uso de alto volumen</p>
</li>
<li>
<p>Desarrollo local</p>
</li>
<li>
<p>Sistemas críticos que requieren independencia</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_7_1_asistente_de_programación">6.4. 7.1. Asistente de Programación</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Sistema multi-agente para generación, revisión y documentación de código.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Stack Básico de Desarrollo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class CodeGeneratorAgent(AssistantAgent):
    """Agente especializado en generación de código"""

    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.language = "python"
        self.frameworks = []

    def generate_function(self, requirements):
        """Generar función basada en requisitos"""
        prompt = f"""
        Genera una función Python que cumpla estos requisitos:
        {requirements}

        - Incluye docstring
        - Manejo de errores
        - Type hints
        """
        return self.generate_response(prompt)

    def generate_class(self, class_name, methods):
        """Generar clase con métodos"""
        methods_str = ", ".join(methods)
        prompt = f"""
        Crea una clase {class_name} con estos métodos: {methods_str}
.
        - Usa type hints
        - Docstrings claros
        - Patrón de diseño SOLID
        """
        return self.generate_response(prompt)

class CodeReviewerAgent(AssistantAgent):
    """Agente especializado en revisión de código"""

    def review_code(self, code):
        """Revisar código y sugerir mejoras"""
        prompt = f"""
        Revisa este código y sugiere mejoras:
        ```python
        {code}
        ```

        Evalúa:
.
        - Legibilidad
        - Performance
        - Seguridad
        - Type hints
        """
        return self.generate_response(prompt)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Sistema de Desarrollo Colaborativo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ProgrammingTeam:
    """Equipo de desarrollo con múltiples especialistas"""

    def __init__(self, llm_config):
        self.generator = CodeGeneratorAgent("CodeGen", llm_config)
        self.reviewer = CodeReviewerAgent("CodeReviewer", llm_config)
        self.documenter = DocumenterAgent("Documenter", llm_config)
        self.tester = TestWriterAgent("TestWriter", llm_config)

    def develop_feature(self, feature_spec):
        """Desarrollo completo de feature"""
        # 1. Generar código
        code = self.generator.generate_function(feature_spec)

        # 2. Revisar
        review = self.reviewer.review_code(code)

        # 3. Escribir tests
        tests = self.tester.generate_tests(code)

        # 4. Documentar
        docs = self.documenter.generate_docs(code)

        return {
            "code": code,
            "review": review,
            "tests": tests,
            "docs": docs
        }

    def debug_code(self, code, error_message):
        """Debugging colaborativo"""
        analysis = self.analyzer.analyze_error(code, error_message)
        fix = self.generator.generate_fix(code, analysis)
        review = self.reviewer.review_fix(fix)
        return {"fix": fix, "review": review}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: IDE Inteligente con AutoGen</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IntelligentCodeEditor:
    """Editor de código mejorado con IA"""

    def __init__(self, llm_config):
        self.code_assistant = CodeGeneratorAgent("Assistant", llm_config)
        self.context = []
        self.suggestions_cache = {}

    def suggest_completion(self, code_prefix):
        """Completación inteligente de código"""
        if code_prefix in self.suggestions_cache:
            return self.suggestions_cache[code_prefix]

        prompt = f"""
        Completa este código Python de forma inteligente:
        {code_prefix}

        - Continúa de forma natural
        - Mantén consistencia de estilo
        - Sigue el contexto
        """
        completion = self.code_assistant.generate_response(prompt)
        self.suggestions_cache[code_prefix] = completion
        return completion

    def explain_code(self, code_snippet):
        """Explicar código seleccionado"""
        prompt = f"""
        Explica este código Python de forma clara y educativa:
        ```python
        {code_snippet}
        ```
        """
        return self.code_assistant.generate_response(prompt)

    def refactor_code(self, code):
        """Refactorización automática"""
        prompt = f"""
        Refactoriza este código para mejorar:
.
        - Legibilidad
        - Mantenibilidad
        - Performance
        ```python
        {code}
        ```
        """
        return self.code_assistant.generate_response(prompt)</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Generación de código funcional</p>
</li>
<li>
<p>✅ Revisión automática de calidad</p>
</li>
<li>
<p>✅ Testing automático</p>
</li>
<li>
<p>✅ Documentación inteligente</p>
</li>
<li>
<p>✅ Debugging colaborativo</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_7_2_análisis_de_datos">6.5. 7.2. Análisis de Datos</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Sistema para procesamiento, análisis y visualización automática de datos.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Pipeline de Análisis Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import pandas as pd
import numpy as np

class DataAnalystAgent(AssistantAgent):
    """Agente especializado en análisis de datos"""

    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.data = None
        self.analysis_history = []

    def load_data(self, file_path):
        """Cargar datos"""
        self.data = pd.read_csv(file_path)
        return self.get_data_summary()

    def get_data_summary(self):
        """Resumen de datos"""
        return {
            "shape": self.data.shape,
            "columns": self.data.columns.tolist(),
            "dtypes": self.data.dtypes.to_dict(),
            "missing": self.data.isnull().sum().to_dict(),
            "stats": self.data.describe().to_dict()
        }

    def explore_data(self):
        """Exploración automática"""
        prompt = f"""
        Analiza estos datos y sugiere insights:

        Forma: {self.data.shape}
        Columnas: {self.data.columns.tolist()}
        Resumen estadístico:
        {self.data.describe()}
        """
        analysis = self.generate_response(prompt)
        self.analysis_history.append(analysis)
        return analysis

    def answer_question(self, question):
        """Responder preguntas sobre datos"""
        # Generar consulta SQL/pandas automáticamente
        prompt = f"""
        Basándote en estos datos:
        {self.data.head()}

        Pregunta: {question}

        Genera una respuesta análitica y visualización sugerida
        """
        return self.generate_response(prompt)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Sistema de Reporting Automático</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class AutomaticReportGenerator:
    """Generador de reportes automáticos"""

    def __init__(self, llm_config):
        self.analyst = DataAnalystAgent("Analyst", llm_config)
        self.visualizer = VisualizationAgent("Visualizer", llm_config)

    def generate_executive_summary(self, data):
        """Resumen ejecutivo automático"""
        summary = self.analyst.get_data_summary()

        prompt = f"""
        Crea un resumen ejecutivo de estos datos:
        {summary}

        Incluye:
        - 3 Key Performance Indicators (KPIs)
        - 3 Insights principales
        - 3 Recomendaciones
        """

        return self.analyst.generate_response(prompt)

    def generate_full_report(self, data, analysis_type="comprehensive"):
        """Reporte completo con secciones"""
        sections = {
            "executive_summary": self.generate_executive_summary(data),
            "data_overview": self.analyst.get_data_summary(),
            "detailed_analysis": self.analyst.explore_data(),
            "visualizations": self.visualizer.suggest_charts(data),
            "recommendations": self.generate_recommendations(data)
        }

        return sections

    def generate_recommendations(self, data):
        """Recomendaciones basadas en análisis"""
        prompt = f"""
        Basándote en estos datos, sugiere acciones:
        {data.describe()}

        Incluye:
        - Acciones inmediatas
        - Mejoras de medio plazo
        - Estrategia a largo plazo
        """
        return self.analyst.generate_response(prompt)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: BI Conversacional</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ConversationalBI:
    """Business Intelligence conversacional"""

    def __init__(self, llm_config):
        self.analyst = DataAnalystAgent("BiAgent", llm_config)
        self.conversation_history = []
        self.data = None

    def chat(self, user_question):
        """Chat conversacional sobre datos"""
        # Guardar en historial
        self.conversation_history.append({
            "user": user_question,
            "timestamp": datetime.now()
        })

        # Generar respuesta considerando contexto
        context = self._get_conversation_context()

        prompt = f"""
        Contexto de conversación:
        {context}

        Pregunta del usuario: {user_question}

        Datos disponibles:
        {self.data.head() if self.data is not None else "No data loaded"}

        Responde de forma natural y proporciona insights
        """

        response = self.analyst.generate_response(prompt)

        self.conversation_history[-1]["response"] = response

        return response

    def _get_conversation_context(self):
        """Contexto de conversación anterior"""
        if not self.conversation_history:
            return "Inicio de conversación"

        recent = self.conversation_history[-5:]  # Últimas 5 interacciones
        return "\n".join([
            f"Usuario: {h['user']}\nAsistente: {h.get('response', '')}"
            for h in recent
        ])</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Exploración automática de datos</p>
</li>
<li>
<p>✅ Generación de reportes</p>
</li>
<li>
<p>✅ Visualizaciones inteligentes</p>
</li>
<li>
<p>✅ Q&amp;A conversacional</p>
</li>
<li>
<p>✅ Recomendaciones automáticas</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_7_3_automatización_de_tareas">6.6. 7.3. Automatización de Tareas</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Flujos de trabajo automatizados para tareas empresariales repetitivas.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Orquestador de Tareas Simple</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from enum import Enum
from datetime import datetime

class TaskStatus(Enum):
    PENDING = "pending"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"

class TaskOrchestrator:
    """Orquestador de tareas automático"""

    def __init__(self, llm_config):
        self.tasks = []
        self.agent = AssistantAgent("TaskOrchestrator", llm_config)

    def create_workflow(self, workflow_name, steps):
        """Crear flujo de trabajo"""
        workflow = {
            "name": workflow_name,
            "steps": steps,
            "created_at": datetime.now(),
            "status": TaskStatus.PENDING
        }
        self.tasks.append(workflow)
        return workflow

    def execute_workflow(self, workflow_name):
        """Ejecutar flujo de trabajo"""
        workflow = next(w for w in self.tasks if w["name"] == workflow_name)

        results = []
        for step in workflow["steps"]:
            result = self._execute_step(step)
            results.append(result)

        workflow["status"] = TaskStatus.COMPLETED
        return results

    def _execute_step(self, step):
        """Ejecutar paso individual"""
        prompt = f"""
        Ejecuta esta tarea:
        Tipo: {step.get('type')}
        Descripción: {step.get('description')}
        Parámetros: {step.get('params')}

        Proporciona resultado y estado
        """
        return self.agent.generate_response(prompt)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Gestor de Procesos Inteligente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IntelligentProcessManager:
    """Gestor de procesos con IA"""

    def __init__(self, llm_config):
        self.processes = {}
        self.optimizer = ProcessOptimizer()
        self.monitor = ProcessMonitor()

    def automate_process(self, process_name, process_def):
        """Automatizar proceso"""
        # Analizar y optimizar
        optimized = self.optimizer.analyze(process_def)

        # Crear ejecutable
        self.processes[process_name] = {
            "definition": process_def,
            "optimized": optimized,
            "status": "ready"
        }

    def execute_process(self, process_name, inputs):
        """Ejecutar proceso"""
        process = self.processes[process_name]

        # Monitorear durante ejecución
        execution = {
            "process": process_name,
            "inputs": inputs,
            "start_time": datetime.now(),
            "status": "running"
        }

        # Ejecutar pasos
        for step in process["optimized"]["steps"]:
            execution["outputs"] = self._run_step(step, inputs)

        execution["end_time"] = datetime.now()
        execution["status"] = "completed"

        return execution

    def get_performance_report(self, process_name):
        """Reporte de performance"""
        executions = self.monitor.get_executions(process_name)

        return {
            "total_runs": len(executions),
            "avg_duration": np.mean([e["duration"] for e in executions]),
            "success_rate": sum(1 for e in executions if e["status"] == "completed") / len(executions),
            "bottlenecks": self.optimizer.identify_bottlenecks(executions)
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: RPA Inteligente</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IntelligentRPA:
    """Automatización inteligente de procesos"""

    def __init__(self, llm_config):
        self.bots = {}
        self.scheduler = BackgroundScheduler()

    def create_bot(self, bot_name, trigger_rules, actions):
        """Crear bot RPA"""
        self.bots[bot_name] = {
            "triggers": trigger_rules,
            "actions": actions,
            "active": True
        }

    def schedule_bot(self, bot_name, cron_expression):
        """Agendar bot"""
        def run_bot():
            return self._execute_bot(bot_name)

        self.scheduler.add_job(
            run_bot,
            trigger="cron",
            **self._parse_cron(cron_expression),
            id=bot_name
        )

    def _execute_bot(self, bot_name):
        """Ejecutar bot"""
        bot = self.bots[bot_name]

        for action in bot["actions"]:
            if action["type"] == "read_email":
                self._handle_email(action)
            elif action["type"] == "process_document":
                self._process_document(action)
            elif action["type"] == "update_system":
                self._update_system(action)

        return {"status": "completed", "bot": bot_name}</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Automatización de flujos</p>
</li>
<li>
<p>✅ Monitoreo en tiempo real</p>
</li>
<li>
<p>✅ Optimización de procesos</p>
</li>
<li>
<p>✅ RPA inteligente</p>
</li>
<li>
<p>✅ Reportes de performance</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_7_4_investigación_y_síntesis">6.7. 7.4. Investigación y Síntesis</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Búsqueda inteligente de información y síntesis de conocimiento.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Investigador Automático Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ResearchAgent(AssistantAgent):
    """Agente de investigación automatizada"""

    def __init__(self, name, llm_config):
        super().__init__(name, llm_config)
        self.sources = []
        self.findings = []

    def research_topic(self, topic, num_sources=5):
        """Investigar tema"""
        prompt = f"""
        Investiga el tema: {topic}

        Proporciona:
        1. Definición clara
        2. Historia y evolución
        3. Actores principales
        4. Tendencias actuales
        5. Desafíos
        6. Oportunidades
        """

        findings = self.generate_response(prompt)
        self.findings.append({
            "topic": topic,
            "findings": findings,
            "timestamp": datetime.now()
        })

        return findings

    def compare_topics(self, topic1, topic2):
        """Comparar dos temas"""
        prompt = f"""
        Compara {topic1} vs {topic2}

        Incluye:
        - Similitudes
        - Diferencias
        - Ventajas/desventajas
        - Casos de uso
        """
        return self.generate_response(prompt)

    def verify_facts(self, claims):
        """Verificar hechos"""
        prompt = f"""
        Verifica estos claims:
        {claims}

        Para cada uno:
        - Confirma o refuta
        - Proporciona evidencia
        - Indica nivel de certeza
        """
        return self.generate_response(prompt)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Sistema de Síntesis Avanzado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class KnowledgeSynthesizer:
    """Sintetizador de conocimiento"""

    def __init__(self, llm_config):
        self.researcher = ResearchAgent("Researcher", llm_config)
        self.knowledge_base = {}

    def synthesize_knowledge(self, sources):
        """Sintetizar múltiples fuentes"""
        synthesis = {
            "sources": sources,
            "key_concepts": self._extract_concepts(sources),
            "connections": self._find_connections(sources),
            "summary": self._generate_summary(sources),
            "gaps": self._identify_gaps(sources),
            "next_steps": self._suggest_next_steps(sources)
        }

        return synthesis

    def create_knowledge_graph(self, topic):
        """Crear grafo de conocimiento"""
        research = self.researcher.research_topic(topic)

        # Extraer entidades y relaciones
        prompt = f"""
        Crea un grafo de conocimiento para:
        {research}

        Identifica:
        - Nodos principales
        - Relaciones entre nodos
        - Jerarquía conceptual
        """

        return self.researcher.generate_response(prompt)

    def generate_literature_review(self, topic, num_papers=10):
        """Generar revisión de literatura"""
        research = self.researcher.research_topic(topic)

        prompt = f"""
        Basándote en esta investigación:
        {research}

        Genera una revisión de literatura que incluya:
        - Estado del arte
        - Clasificación de trabajos
        - Vacíos de investigación
        - Oportunidades futuras
        """

        return self.researcher.generate_response(prompt)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Analista Inteligente de Información</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IntelligentInformationAnalyzer:
    """Analizador inteligente de información"""

    def __init__(self, llm_config):
        self.researcher = ResearchAgent("Analyzer", llm_config)
        self.analysis_cache = {}

    def analyze_document(self, document):
        """Analizar documento"""
        if document in self.analysis_cache:
            return self.analysis_cache[document]

        prompt = f"""
        Analiza este documento:
        {document}

        Extrae:
        - Idea principal
        - Puntos clave
        - Conclusiones
        - Limitaciones
        - Validez de argumentos
        """

        analysis = self.researcher.generate_response(prompt)
        self.analysis_cache[document] = analysis
        return analysis

    def identify_misinformation(self, claim):
        """Identificar desinformación"""
        prompt = f"""
        Analiza si este claim es verdadero o falso:
        {claim}

        Proporciona:
        - Evaluación (verdadero/falso/parcial)
        - Evidencia
        - Fuentes confiables
        - Contexto completo
        """

        return self.researcher.generate_response(prompt)

    def synthesize_debate(self, topic, perspectives):
        """Sintetizar debate"""
        prompt = f"""
        Sintetiza este debate sobre {topic}:

        Perspectiva A: {perspectives['a']}
        Perspectiva B: {perspectives['b']}

        Proporciona:
        - Puntos comunes
        - Puntos de divergencia
        - Posibles consensos
        - Preguntas sin resolver
        """

        return self.researcher.generate_response(prompt)</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Investigación automatizada</p>
</li>
<li>
<p>✅ Síntesis de múltiples fuentes</p>
</li>
<li>
<p>✅ Verificación de hechos</p>
</li>
<li>
<p>✅ Análisis inteligente</p>
</li>
<li>
<p>✅ Detección de desinformación</p>
</li>
</ul>
</div>
</div>
<div class="sect2">
<h3 id="_8_1_estrategias_de_testing">6.8. 8.1. Estrategias de Testing</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Frameworks de testing para validar comportamiento y calidad de agentes.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Unit Testing Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import unittest
from unittest.mock import Mock, patch

class AgentTestCase(unittest.TestCase):
    """Casos de prueba para agentes"""

    def setUp(self):
        """Configuración de pruebas"""
        self.agent = AssistantAgent("TestAgent", llm_config)
        self.mock_llm = Mock()

    def test_agent_initialization(self):
        """Prueba inicialización de agente"""
        self.assertIsNotNone(self.agent.name)
        self.assertEqual(self.agent.name, "TestAgent")

    def test_generate_response(self):
        """Prueba generación de respuesta"""
        with patch.object(self.agent, 'generate_response') as mock_gen:
            mock_gen.return_value = "Test response"
            response = self.agent.generate_response("Test prompt")
            self.assertEqual(response, "Test response")
            mock_gen.assert_called_once()

    def test_response_format(self):
        """Prueba formato de respuesta"""
        response = self.agent.generate_response("Hola")
        self.assertIsInstance(response, str)
        self.assertGreater(len(response), 0)

    def test_error_handling(self):
        """Prueba manejo de errores"""
        with self.assertRaises(ValueError):
            self.agent.generate_response("")</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Testing de Conversaciones</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ConversationTestSuite:
    """Suite de pruebas para conversaciones multi-agente"""

    def __init__(self):
        self.test_conversations = []
        self.results = []

    def test_two_agent_conversation(self):
        """Prueba conversación de dos agentes"""
        agent1 = AssistantAgent("Alice", llm_config)
        agent2 = AssistantAgent("Bob", llm_config)

        # Simular conversación
        message1 = agent1.generate_response("Hola Bob")
        message2 = agent2.generate_response(message1)
        message3 = agent1.generate_response(message2)

        # Validaciones
        assert len(message1) &gt; 0, "Agent 1 should produce output"
        assert len(message2) &gt; 0, "Agent 2 should produce output"
        assert len(message3) &gt; 0, "Agent 1 should respond again"

        return {
            "passed": True,
            "messages": [message1, message2, message3]
        }

    def test_conversation_coherence(self, conversation):
        """Prueba coherencia de conversación"""
        # Verificar que los temas se mantienen
        for i in range(len(conversation) - 1):
            current = conversation[i]
            next_msg = conversation[i + 1]

            # Validar continuidad temática
            assert self._are_related(current, next_msg), \
                f"Messages {i} and {i+1} are not thematically related"

    def test_output_validation(self, response):
        """Validar output de agente"""
        validations = {
            "non_empty": len(response) &gt; 0,
            "valid_json": self._is_valid_json(response),
            "contains_key_terms": any(term in response for term in ["hello", "hola"]),
            "language_appropriate": self._check_language(response)
        }
        return validations

    def _are_related(self, text1, text2):
        """Verificar relación temática entre textos"""
        # Implementación simplificada
        return True

    def _is_valid_json(self, text):
        """Verificar si es JSON válido"""
        try:
            json.loads(text)
            return True
        except:
            return False

    def _check_language(self, text):
        """Verificar idioma apropiado"""
        return len(text) &gt; 10  # Simplificado</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Framework Avanzado de Testing</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class AdvancedTestFramework:
    """Framework avanzado para testing de agentes"""

    def __init__(self):
        self.test_suites = {}
        self.metrics = {}
        self.coverage = {}

    def create_test_suite(self, name, test_cases):
        """Crear suite de pruebas"""
        self.test_suites[name] = {
            "cases": test_cases,
            "results": [],
            "passed": 0,
            "failed": 0
        }

    def run_test_suite(self, suite_name):
        """Ejecutar suite completa"""
        suite = self.test_suites[suite_name]

        for test_case in suite["cases"]:
            try:
                result = test_case()
                suite["results"].append({
                    "name": test_case.__name__,
                    "status": "passed",
                    "result": result
                })
                suite["passed"] += 1
            except Exception as e:
                suite["results"].append({
                    "name": test_case.__name__,
                    "status": "failed",
                    "error": str(e)
                })
                suite["failed"] += 1

        return self._generate_report(suite)

    def measure_code_coverage(self, agents):
        """Medir cobertura de código"""
        coverage_data = {}

        for agent in agents:
            methods = [m for m in dir(agent) if not m.startswith('_')]
            tested_methods = self._get_tested_methods(agent.__class__)

            coverage_data[agent.name] = {
                "total_methods": len(methods),
                "tested_methods": len(tested_methods),
                "coverage_percentage": (len(tested_methods) / len(methods)) * 100
            }

        return coverage_data

    def _generate_report(self, suite):
        """Generar reporte de pruebas"""
        total = suite["passed"] + suite["failed"]
        pass_rate = (suite["passed"] / total * 100) if total &gt; 0 else 0

        return {
            "total_tests": total,
            "passed": suite["passed"],
            "failed": suite["failed"],
            "pass_rate": pass_rate,
            "details": suite["results"]
        }

    def _get_tested_methods(self, agent_class):
        """Obtener métodos testeados"""
        # Implementación simplificada
        return []</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Unit testing completo</p>
</li>
<li>
<p>✅ Testing de conversaciones</p>
</li>
<li>
<p>✅ Validación de outputs</p>
</li>
<li>
<p>✅ Medición de cobertura</p>
</li>
<li>
<p>✅ Reportes detallados</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_8_2_debugging">6.9. 8.2. Debugging</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Herramientas y estrategias para identificar y resolver problemas.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Sistema de Logging Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import logging
from datetime import datetime

class AgentLogger:
    """Sistema de logging para agentes"""

    def __init__(self, agent_name):
        self.agent_name = agent_name
        self.logs = []

        # Configurar logging estándar
        self.logger = logging.getLogger(agent_name)
        self.logger.setLevel(logging.DEBUG)

        # Crear handler
        handler = logging.FileHandler(f"{agent_name}.log")
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s'
        )
        handler.setFormatter(formatter)
        self.logger.addHandler(handler)

    def log_action(self, action, details=None):
        """Registrar acción"""
        log_entry = {
            "timestamp": datetime.now(),
            "action": action,
            "details": details
        }
        self.logs.append(log_entry)
        self.logger.info(f"{action}: {details}")

    def log_error(self, error, context=None):
        """Registrar error"""
        error_entry = {
            "timestamp": datetime.now(),
            "error": str(error),
            "context": context
        }
        self.logs.append(error_entry)
        self.logger.error(f"Error: {error} | Context: {context}")

    def get_trace(self, action_filter=None):
        """Obtener trazabilidad completa"""
        if action_filter:
            return [log for log in self.logs if action_filter in log["action"]]
        return self.logs

    def generate_debug_report(self):
        """Generar reporte de debug"""
        return {
            "agent": self.agent_name,
            "total_actions": len(self.logs),
            "errors": len([l for l in self.logs if "error" in l]),
            "timeline": self.logs
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Debugger Interactivo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class InteractiveDebugger:
    """Debugger interactivo para agentes"""

    def __init__(self, agent):
        self.agent = agent
        self.breakpoints = {}
        self.watched_variables = {}
        self.execution_history = []

    def set_breakpoint(self, method_name):
        """Establecer breakpoint"""
        self.breakpoints[method_name] = True
        print(f"Breakpoint set at {method_name}")

    def watch_variable(self, var_name):
        """Monitorear variable"""
        self.watched_variables[var_name] = None
        print(f"Watching {var_name}")

    def step_through(self, prompt):
        """Ejecutar paso a paso"""
        # Capturar estado inicial
        initial_state = self._capture_state()

        # Ejecutar
        result = self.agent.generate_response(prompt)

        # Capturar estado final
        final_state = self._capture_state()

        # Registrar cambios
        step_info = {
            "prompt": prompt,
            "result": result,
            "state_changes": self._compare_states(initial_state, final_state)
        }
        self.execution_history.append(step_info)

        return step_info

    def inspect_state(self):
        """Inspeccionar estado actual"""
        return {
            "agent_name": self.agent.name,
            "variables": self.watched_variables,
            "recent_actions": self.execution_history[-5:]
        }

    def _capture_state(self):
        """Capturar estado del agente"""
        return {
            "timestamp": datetime.now(),
            "variables": dict(self.watched_variables)
        }

    def _compare_states(self, state1, state2):
        """Comparar estados"""
        changes = {}
        for var in self.watched_variables:
            if var in state1["variables"] and var in state2["variables"]:
                if state1["variables"][var] != state2["variables"][var]:
                    changes[var] = {
                        "before": state1["variables"][var],
                        "after": state2["variables"][var]
                    }
        return changes</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Error Recovery y Auto-Healing</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ErrorRecoverySystem:
    """Sistema automático de recuperación de errores"""

    def __init__(self, agent):
        self.agent = agent
        self.error_patterns = {}
        self.recovery_strategies = {}
        self.error_history = []

    def register_error_pattern(self, error_type, detection_fn):
        """Registrar patrón de error"""
        self.error_patterns[error_type] = detection_fn

    def register_recovery_strategy(self, error_type, strategy_fn):
        """Registrar estrategia de recuperación"""
        self.recovery_strategies[error_type] = strategy_fn

    def execute_with_recovery(self, prompt, max_retries=3):
        """Ejecutar con recuperación automática"""
        for attempt in range(max_retries):
            try:
                result = self.agent.generate_response(prompt)
                return {"success": True, "result": result, "attempts": attempt + 1}

            except Exception as e:
                error_type = type(e).__name__

                # Detectar patrón de error
                detected_pattern = self._detect_error_pattern(e)

                if detected_pattern and detected_pattern in self.recovery_strategies:
                    # Aplicar estrategia de recuperación
                    recovery_fn = self.recovery_strategies[detected_pattern]
                    self.agent = recovery_fn(self.agent, e)
                    print(f"Applied recovery strategy: {detected_pattern}")
                else:
                    if attempt == max_retries - 1:
                        raise
                    print(f"Retry {attempt + 1}/{max_retries}...")

                self.error_history.append({
                    "attempt": attempt + 1,
                    "error": str(e),
                    "pattern": detected_pattern
                })

        return {"success": False, "error": "Max retries exceeded"}

    def _detect_error_pattern(self, error):
        """Detectar patrón de error"""
        for pattern_name, detection_fn in self.error_patterns.items():
            if detection_fn(error):
                return pattern_name
        return None

    def get_error_statistics(self):
        """Estadísticas de errores"""
        from collections import Counter
        error_types = Counter([e["pattern"] for e in self.error_history])
        return {
            "total_errors": len(self.error_history),
            "error_breakdown": dict(error_types),
            "recent_errors": self.error_history[-10:]
        }</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Logging detallado</p>
</li>
<li>
<p>✅ Debugging interactivo</p>
</li>
<li>
<p>✅ Rastreo de ejecución</p>
</li>
<li>
<p>✅ Recuperación automática</p>
</li>
<li>
<p>✅ Análisis de errores</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_8_3_evaluación_de_calidad">6.10. 8.3. Evaluación de Calidad</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Métricas y herramientas para medir y mejorar la calidad de agentes.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Framework de Métricas Básico</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class QualityMetrics:
    """Métricas de calidad para agentes"""

    def __init__(self):
        self.metrics = {}

    def measure_response_quality(self, response, expected=None):
        """Medir calidad de respuesta"""
        quality_score = {
            "length": self._score_length(response),
            "coherence": self._score_coherence(response),
            "completeness": self._score_completeness(response),
            "accuracy": self._score_accuracy(response, expected) if expected else None
        }

        overall_score = sum(
            v for v in quality_score.values() if v is not None
        ) / len([v for v in quality_score.values() if v is not None])

        return {
            "scores": quality_score,
            "overall": overall_score,
            "grade": self._calculate_grade(overall_score)
        }

    def benchmark_agents(self, agents, test_prompts):
        """Comparar rendimiento de agentes"""
        results = {}

        for agent in agents:
            scores = []
            for prompt in test_prompts:
                response = agent.generate_response(prompt)
                quality = self.measure_response_quality(response)
                scores.append(quality["overall"])

            results[agent.name] = {
                "avg_score": sum(scores) / len(scores),
                "scores": scores
            }

        # Ranking
        ranking = sorted(
            results.items(),
            key=lambda x: x[1]["avg_score"],
            reverse=True
        )

        return {
            "results": results,
            "ranking": ranking,
            "best_agent": ranking[0][0] if ranking else None
        }

    def _score_length(self, response):
        """Puntuación de longitud"""
        word_count = len(response.split())
        if 50 &lt; word_count &lt; 500:
            return 1.0
        elif 20 &lt; word_count &lt; 1000:
            return 0.8
        else:
            return 0.5

    def _score_coherence(self, response):
        """Puntuación de coherencia"""
        # Simplificado: verificar que tiene puntuación
        has_punctuation = any(p in response for p in ".!?")
        return 0.9 if has_punctuation else 0.5

    def _score_completeness(self, response):
        """Puntuación de completitud"""
        sentences = response.split(".")
        return min(len(sentences) / 3, 1.0)

    def _score_accuracy(self, response, expected):
        """Puntuación de precisión"""
        if expected.lower() in response.lower():
            return 1.0
        return 0.5

    def _calculate_grade(self, score):
        """Calcular calificación"""
        if score &gt;= 0.9:
            return "A"
        elif score &gt;= 0.8:
            return "B"
        elif score &gt;= 0.7:
            return "C"
        else:
            return "D"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Evaluación Continua</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ContinuousEvaluation:
    """Evaluación continua de agentes"""

    def __init__(self, agent):
        self.agent = agent
        self.evaluation_history = []
        self.performance_trends = {}

    def evaluate(self, test_set):
        """Evaluar agente con test set"""
        results = []

        for test_case in test_set:
            prompt = test_case["prompt"]
            expected = test_case.get("expected")

            response = self.agent.generate_response(prompt)

            # Evaluar respuesta
            score = self._evaluate_response(response, expected)
            results.append({
                "prompt": prompt,
                "response": response,
                "score": score
            })

        # Guardar evaluación
        evaluation = {
            "timestamp": datetime.now(),
            "agent": self.agent.name,
            "results": results,
            "avg_score": sum(r["score"] for r in results) / len(results)
        }

        self.evaluation_history.append(evaluation)
        self._update_trends()

        return evaluation

    def identify_weak_areas(self):
        """Identificar áreas débiles"""
        if not self.evaluation_history:
            return {}

        latest = self.evaluation_history[-1]
        weak_prompts = [
            r for r in latest["results"]
            if r["score"] &lt; 0.7
        ]

        return {
            "weak_areas": weak_prompts,
            "improvement_needed": len(weak_prompts) &gt; 0
        }

    def _evaluate_response(self, response, expected):
        """Evaluar respuesta individual"""
        if not expected:
            return 0.5  # Sin expectativa

        # Comparación simple de similitud
        response_lower = response.lower()
        expected_lower = expected.lower()

        similarity = sum(
            1 for word in expected_lower.split()
            if word in response_lower
        ) / len(expected_lower.split())

        return min(similarity, 1.0)

    def _update_trends(self):
        """Actualizar tendencias de rendimiento"""
        if len(self.evaluation_history) &gt;= 2:
            recent = self.evaluation_history[-2:]
            trend = recent[-1]["avg_score"] - recent[-2]["avg_score"]
            self.performance_trends["latest"] = trend

    def get_performance_report(self):
        """Reporte de rendimiento"""
        if not self.evaluation_history:
            return {}

        scores = [e["avg_score"] for e in self.evaluation_history]

        return {
            "evaluations": len(self.evaluation_history),
            "current_score": scores[-1],
            "avg_score": sum(scores) / len(scores),
            "best_score": max(scores),
            "trend": self.performance_trends.get("latest", 0)
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Quality Assurance Avanzado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class AdvancedQualityAssurance:
    """QA avanzado con múltiples validadores"""

    def __init__(self):
        self.validators = {}
        self.thresholds = {}
        self.quality_rules = []

    def register_validator(self, name, validator_fn, threshold=0.7):
        """Registrar validador"""
        self.validators[name] = validator_fn
        self.thresholds[name] = threshold

    def add_quality_rule(self, rule):
        """Agregar regla de calidad"""
        self.quality_rules.append(rule)

    def validate_response(self, response):
        """Validar respuesta contra todos los validadores"""
        validation_results = {}

        for name, validator_fn in self.validators.items():
            score = validator_fn(response)
            threshold = self.thresholds[name]
            validation_results[name] = {
                "score": score,
                "threshold": threshold,
                "passed": score &gt;= threshold
            }

        # Aplicar reglas
        rule_results = []
        for rule in self.quality_rules:
            passed = rule(response, validation_results)
            rule_results.append(passed)

        # Resultado general
        all_passed = all(validation_results[k]["passed"] for k in validation_results)
        all_rules_passed = all(rule_results) if rule_results else True

        return {
            "validators": validation_results,
            "rules": rule_results,
            "overall_quality": all_passed and all_rules_passed,
            "quality_score": sum(v["score"] for v in validation_results.values()) / len(validation_results) if validation_results else 0
        }</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Múltiples métricas de calidad</p>
</li>
<li>
<p>✅ Benchmarking comparativo</p>
</li>
<li>
<p>✅ Evaluación continua</p>
</li>
<li>
<p>✅ Identificación de debilidades</p>
</li>
<li>
<p>✅ Reportes de rendimiento</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_9_despliegue_en_producción">7. Módulo 9: Despliegue en Producción</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_9_1_arquitectura_de_producción">7.1. 9.1. Arquitectura de Producción</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Diseño escalable y resiliente de sistemas de agentes en producción.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Arquitectura Microservicios Básica</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from fastapi import FastAPI
from pydantic import BaseModel
import uvicorn

class AgentRequest(BaseModel):
    prompt: str
    agent_id: str

class AgentResponse(BaseModel):
    response: str
    agent_id: str
    timestamp: str

app = FastAPI()

class ProductionAgent:
    """Agente preparado para producción"""

    def __init__(self, agent_id, llm_config):
        self.agent_id = agent_id
        self.agent = AssistantAgent(agent_id, llm_config)
        self.request_queue = []
        self.response_cache = {}

    @app.post("/query")
    async def query(self, request: AgentRequest) -&gt; AgentResponse:
        """Endpoint de consulta"""
        try:
            response = self.agent.generate_response(request.prompt)

            return AgentResponse(
                response=response,
                agent_id=self.agent_id,
                timestamp=datetime.now().isoformat()
            )
        except Exception as e:
            return {"error": str(e)}

    @app.get("/health")
    async def health_check():
        """Health check"""
        return {
            "status": "healthy",
            "agent_id": self.agent_id,
            "timestamp": datetime.now().isoformat()
        }

    @app.get("/metrics")
    async def get_metrics():
        """Métricas del agente"""
        return {
            "total_requests": len(self.request_queue),
            "cache_size": len(self.response_cache)
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Sistema Distribuido Escalable</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from kubernetes import client, config
import docker

class DistributedAgentManager:
    """Gestor de agentes distribuidos"""

    def __init__(self, deployment_config):
        self.config = deployment_config
        self.agents = {}
        self.load_balancer = LoadBalancer()

    def deploy_agent(self, agent_config):
        """Desplegar agente en contenedor"""
        # Crear imagen Docker
        dockerfile_content = f"""
        FROM python:3.9
        RUN pip install autogen ollama
        COPY agent.py /app/
        WORKDIR /app
        CMD ["python", "agent.py"]
        """

        # Construir imagen
        docker_client = docker.from_env()
        image = docker_client.images.build(
            fileobj=dockerfile_content.encode(),
            tag=f"agent-{agent_config['name']}:latest"
        )

        # Desplegar en Kubernetes
        self._deploy_kubernetes(agent_config, image[0].id)

    def scale_agent(self, agent_name, replicas):
        """Escalar agente a N réplicas"""
        config.load_incluster_config()
        v1 = client.AppsV1Api()

        deployment = v1.read_namespaced_deployment(
            agent_name,
            "default"
        )

        deployment.spec.replicas = replicas
        v1.patch_namespaced_deployment(
            agent_name,
            "default",
            deployment
        )

    def route_request(self, request):
        """Enrutar solicitud a agente disponible"""
        available_agents = self._get_healthy_agents()
        selected_agent = self.load_balancer.select(available_agents)
        return selected_agent.handle_request(request)

    def _get_healthy_agents(self):
        """Obtener agentes saludables"""
        healthy = []
        for agent_name, agent in self.agents.items():
            if agent.health_check():
                healthy.append(agent)
        return healthy</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Estado Persistente y Recuperación</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
import json

class PersistentAgentState:
    """Persistencia de estado de agente"""

    def __init__(self, db_url="postgresql://user:pass@localhost/agents"):
        self.engine = create_engine(db_url)
        self.Session = sessionmaker(bind=self.engine)

    def save_conversation(self, agent_id, conversation):
        """Guardar conversación"""
        session = self.Session()
        try:
            db_conversation = ConversationRecord(
                agent_id=agent_id,
                content=json.dumps(conversation),
                created_at=datetime.now()
            )
            session.add(db_conversation)
            session.commit()
        finally:
            session.close()

    def load_conversation(self, agent_id, conversation_id):
        """Cargar conversación anterior"""
        session = self.Session()
        try:
            record = session.query(ConversationRecord).filter(
                ConversationRecord.agent_id == agent_id,
                ConversationRecord.id == conversation_id
            ).first()

            if record:
                return json.loads(record.content)
            return None
        finally:
            session.close()

    def save_agent_state(self, agent_id, state):
        """Guardar estado del agente"""
        session = self.Session()
        try:
            state_record = AgentStateRecord(
                agent_id=agent_id,
                state_data=json.dumps(state),
                saved_at=datetime.now()
            )
            session.add(state_record)
            session.commit()
            return state_record.id
        finally:
            session.close()

    def restore_agent(self, agent_id):
        """Restaurar agente desde estado guardado"""
        session = self.Session()
        try:
            latest_state = session.query(AgentStateRecord).filter(
                AgentStateRecord.agent_id == agent_id
            ).order_by(AgentStateRecord.saved_at.desc()).first()

            if latest_state:
                return json.loads(latest_state.state_data)
            return None
        finally:
            session.close()</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Microservicios escalables</p>
</li>
<li>
<p>✅ Deploymentc con contenedores</p>
</li>
<li>
<p>✅ Load balancing</p>
</li>
<li>
<p>✅ Persistencia de estado</p>
</li>
<li>
<p>✅ Alta disponibilidad</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_9_2_seguridad">7.2. 9.2. Seguridad</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Medidas de seguridad para proteger agentes en producción.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Sanitización de Entrada</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import re
from html import escape
import bleach

class InputSanitizer:
    """Sanitizador de inputs"""

    def __init__(self):
        self.max_length = 10000
        self.forbidden_patterns = [
            r'&lt;script.*?&lt;/script&gt;',  # Script tags
            r'javascript:',           # JavaScript protocol
            r'on\w+\s*=',            # Event handlers
            r'DROP\s+TABLE',         # SQL injection
            r'UNION\s+SELECT',       # SQL injection
        ]

    def sanitize(self, user_input):
        """Sanitizar entrada del usuario"""
        if not isinstance(user_input, str):
            raise ValueError("Input must be string")

        # Verificar longitud
        if len(user_input) &gt; self.max_length:
            raise ValueError(f"Input exceeds max length {self.max_length}")

        # Escapar HTML
        sanitized = escape(user_input)

        # Verificar patrones peligrosos
        for pattern in self.forbidden_patterns:
            if re.search(pattern, sanitized, re.IGNORECASE):
                raise ValueError(f"Dangerous pattern detected: {pattern}")

        # Usar bleach para limpieza adicional
        sanitized = bleach.clean(sanitized, tags=[], strip=True)

        return sanitized

    def validate_prompt(self, prompt):
        """Validar y sanitizar prompt"""
        sanitized = self.sanitize(prompt)

        # Validaciones adicionales
        if len(sanitized) &lt; 1:
            raise ValueError("Prompt cannot be empty")

        if self._has_excessive_repetition(sanitized):
            raise ValueError("Excessive character repetition detected")

        return sanitized

    def _has_excessive_repetition(self, text, max_repeat=10):
        """Detectar repetición excesiva"""
        for char in set(text):
            if char * max_repeat in text:
                return True
        return False</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Control de Ejecución</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from RestrictedPython import compile_restricted_exec
import ast

class ExecutionController:
    """Controlador de ejecución segura"""

    def __init__(self):
        self.allowed_modules = ['math', 'json', 'datetime']
        self.execution_timeout = 30
        self.memory_limit = 512  # MB

    def execute_code_safely(self, code):
        """Ejecutar código de forma segura"""
        # Compilar con restricciones
        compiled = compile_restricted_exec(code)

        if compiled.errors:
            return {"error": "Código no permitido", "details": compiled.errors}

        # Crear entorno restringido
        safe_globals = self._create_safe_globals()
        safe_locals = {}

        try:
            # Ejecutar con timeout
            exec_with_timeout(
                compiled.code,
                safe_globals,
                safe_locals,
                timeout=self.execution_timeout
            )

            return {
                "status": "success",
                "output": safe_locals.get("result")
            }

        except TimeoutError:
            return {"error": "Ejecución excedió tiempo límite"}
        except Exception as e:
            return {"error": f"Error en ejecución: {str(e)}"}

    def _create_safe_globals(self):
        """Crear globals seguros"""
        safe_globals = {
            '__builtins__': {
                'abs': abs,
                'len': len,
                'sum': sum,
                'print': print,
                'range': range,
            },
            '__name__': 'restricted_module'
        }

        return safe_globals

    def validate_code(self, code):
        """Validar código antes de ejecutar"""
        try:
            tree = ast.parse(code)

            # Verificar nodos peligrosos
            dangerous_nodes = [
                ast.Import,
                ast.ImportFrom,
                ast.Open,
                ast.Eval,
                ast.Exec
            ]

            for node in ast.walk(tree):
                if type(node) in dangerous_nodes:
                    return False

            return True
        except:
            return False</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Gestión de Secretos y Auditoría</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import os
from hashlib import sha256
from cryptography.fernet import Fernet
import logging

class SecretManager:
    """Gestor de secretos y credenciales"""

    def __init__(self):
        self.cipher = self._init_cipher()
        self.audit_log = logging.getLogger("security_audit")
        self.secrets = {}

    def store_secret(self, key, value, secret_type="api_key"):
        """Almacenar secreto encriptado"""
        encrypted = self.cipher.encrypt(value.encode())

        self.secrets[key] = {
            "value": encrypted,
            "type": secret_type,
            "created_at": datetime.now(),
            "last_accessed": None,
            "access_count": 0
        }

        self._audit_log(f"SECRET_STORED", {"key": key, "type": secret_type})

    def retrieve_secret(self, key, requester_id):
        """Recuperar secreto con auditoría"""
        if key not in self.secrets:
            self._audit_log("SECRET_NOT_FOUND", {"key": key, "requester": requester_id})
            raise ValueError(f"Secret '{key}' not found")

        secret_data = self.secrets[key]

        # Actualizar auditoría
        secret_data["last_accessed"] = datetime.now()
        secret_data["access_count"] += 1

        self._audit_log("SECRET_ACCESSED", {
            "key": key,
            "requester": requester_id,
            "access_count": secret_data["access_count"]
        })

        # Desencriptar y retornar
        decrypted = self.cipher.decrypt(secret_data["value"]).decode()
        return decrypted

    def rotate_secret(self, key):
        """Rotar secreto"""
        if key not in self.secrets:
            raise ValueError(f"Secret '{key}' not found")

        # Crear nuevo secret
        new_secret_value = os.urandom(32)

        # Actualizar
        self.secrets[key]["value"] = self.cipher.encrypt(new_secret_value)
        self.secrets[key]["rotated_at"] = datetime.now()

        self._audit_log("SECRET_ROTATED", {"key": key})

    def _init_cipher(self):
        """Inicializar cipher"""
        key = os.getenv("ENCRYPTION_KEY")
        if not key:
            raise ValueError("ENCRYPTION_KEY environment variable not set")
        return Fernet(key.encode())

    def _audit_log(self, action, details):
        """Registrar en auditoría"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "details": details
        }
        self.audit_log.info(json.dumps(log_entry))</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Sanitización de inputs</p>
</li>
<li>
<p>✅ Ejecución controlada</p>
</li>
<li>
<p>✅ Encriptación de secretos</p>
</li>
<li>
<p>✅ Auditoría completa</p>
</li>
<li>
<p>✅ Detección de anomalías</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_9_3_monitorización">7.3. 9.3. Monitorización</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Monitoreo en tiempo real de agentes y sistemas.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Logging Estructurado en Producción</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import logging
import json
from pythonjsonlogger import jsonlogger

class ProductionLogger:
    """Logger estructurado para producción"""

    def __init__(self, agent_name):
        self.agent_name = agent_name
        self.logger = logging.getLogger(agent_name)

        # Handler JSON
        logHandler = logging.FileHandler(f"{agent_name}.json")
        formatter = jsonlogger.JsonFormatter()
        logHandler.setFormatter(formatter)
        self.logger.addHandler(logHandler)

        self.logger.setLevel(logging.INFO)

    def log_request(self, request_id, prompt, agent_id):
        """Registrar solicitud"""
        self.logger.info(
            "REQUEST",
            extra={
                "request_id": request_id,
                "agent_id": agent_id,
                "prompt_length": len(prompt),
                "timestamp": datetime.now().isoformat()
            }
        )

    def log_response(self, request_id, response, latency_ms):
        """Registrar respuesta"""
        self.logger.info(
            "RESPONSE",
            extra={
                "request_id": request_id,
                "response_length": len(response),
                "latency_ms": latency_ms,
                "timestamp": datetime.now().isoformat()
            }
        )

    def log_error(self, request_id, error, error_type):
        """Registrar error"""
        self.logger.error(
            "ERROR",
            extra={
                "request_id": request_id,
                "error": str(error),
                "error_type": error_type,
                "timestamp": datetime.now().isoformat()
            }
        )</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Métricas y Alertas</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from prometheus_client import Counter, Histogram, Gauge

class MetricsCollector:
    """Colector de métricas con Prometheus"""

    def __init__(self):
        # Contadores
        self.requests_total = Counter(
            'agent_requests_total',
            'Total de solicitudes',
            ['agent_id', 'status']
        )

        self.tokens_used = Counter(
            'agent_tokens_used_total',
            'Total de tokens usados',
            ['agent_id']
        )

        # Histogramas
        self.response_time = Histogram(
            'agent_response_time_seconds',
            'Tiempo de respuesta',
            ['agent_id'],
            buckets=(0.1, 0.5, 1.0, 2.0, 5.0)
        )

        # Gauges
        self.active_conversations = Gauge(
            'agent_active_conversations',
            'Conversaciones activas',
            ['agent_id']
        )

    def record_request(self, agent_id, status, duration_seconds, tokens):
        """Registrar métrica de solicitud"""
        self.requests_total.labels(
            agent_id=agent_id,
            status=status
        ).inc()

        self.response_time.labels(
            agent_id=agent_id
        ).observe(duration_seconds)

        if tokens:
            self.tokens_used.labels(
                agent_id=agent_id
            ).inc(tokens)

class AlertManager:
    """Gestor de alertas"""

    def __init__(self, thresholds):
        self.thresholds = thresholds
        self.alerts = []

    def check_metrics(self, metrics):
        """Verificar métricas y generar alertas"""
        if metrics['response_time_ms'] &gt; self.thresholds['max_latency']:
            self.raise_alert("HIGH_LATENCY", metrics)

        if metrics['error_rate'] &gt; self.thresholds['max_error_rate']:
            self.raise_alert("HIGH_ERROR_RATE", metrics)

        if metrics['tokens_used'] &gt; self.thresholds['max_tokens']:
            self.raise_alert("HIGH_TOKEN_USAGE", metrics)

    def raise_alert(self, alert_type, details):
        """Generar alerta"""
        alert = {
            "type": alert_type,
            "details": details,
            "timestamp": datetime.now(),
            "severity": "warning"
        }

        self.alerts.append(alert)
        self._send_notification(alert)

    def _send_notification(self, alert):
        """Enviar notificación (Slack, PagerDuty, etc)"""
        # Implementación
        pass</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Dashboard de Monitoreo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from streamlit import streamlit as st
import pandas as pd

class MonitoringDashboard:
    """Dashboard de monitoreo con Streamlit"""

    def __init__(self, metrics_source):
        self.metrics = metrics_source

    def render(self):
        """Renderizar dashboard"""
        st.title("AutoGen Monitoring Dashboard")

        # Métricas principales
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Total Requests", self.metrics.total_requests)

        with col2:
            st.metric("Success Rate", f"{self.metrics.success_rate}%")

        with col3:
            st.metric("Avg Latency", f"{self.metrics.avg_latency_ms}ms")

        with col4:
            st.metric("Active Agents", self.metrics.active_agents_count)

        # Gráficos
        st.subheader("Request Timeline")
        df = pd.DataFrame(self.metrics.requests_timeline)
        st.line_chart(df)

        st.subheader("Error Rate by Agent")
        error_data = pd.DataFrame(self.metrics.error_rates_by_agent)
        st.bar_chart(error_data)

        st.subheader("Token Usage")
        token_data = pd.DataFrame(self.metrics.token_usage_by_agent)
        st.area_chart(token_data)</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Logging estructurado JSON</p>
</li>
<li>
<p>✅ Métricas con Prometheus</p>
</li>
<li>
<p>✅ Alertas automáticas</p>
</li>
<li>
<p>✅ Dashboard visual</p>
</li>
<li>
<p>✅ Análisis en tiempo real</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_9_4_cicd">7.4. 9.4. CI/CD</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Pipeline automático de integración y despliegue continuo.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Pipeline GitHub Actions</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">name: Deploy Agent

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
.
    - uses: actions/checkout@v2

    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Run tests
      run: |
        python -m pytest tests/ -v

    - name: Code coverage
      run: |
        pytest --cov=agents tests/
        codecov

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
.
    - uses: actions/checkout@v2

    - name: Build Docker image
      run: |
        docker build -t agent:latest .

    - name: Push to registry
      run: |
        docker tag agent:latest ${{ secrets.REGISTRY }}/agent:${{ github.sha }}
        docker push ${{ secrets.REGISTRY }}/agent:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
.
    - uses: actions/checkout@v2

    - name: Deploy to Kubernetes
      run: |
        kubectl set image deployment/agent \
          agent=${{ secrets.REGISTRY }}/agent:${{ github.sha }}
        kubectl rollout status deployment/agent</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Sistema de Versionado de Agentes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from dataclasses import dataclass
import semver

@dataclass
class AgentVersion:
    major: int
    minor: int
    patch: int
    agent_id: str
    timestamp: str
    changes: list

class VersionManager:
    """Gestor de versiones de agentes"""

    def __init__(self):
        self.versions = {}

    def create_version(self, agent_id, changes, version_type="patch"):
        """Crear nueva versión"""
        latest = self._get_latest_version(agent_id)

        if version_type == "major":
            latest.major += 1
            latest.minor = 0
            latest.patch = 0
        elif version_type == "minor":
            latest.minor += 1
            latest.patch = 0
        else:  # patch
            latest.patch += 1

        new_version = AgentVersion(
            major=latest.major,
            minor=latest.minor,
            patch=latest.patch,
            agent_id=agent_id,
            timestamp=datetime.now().isoformat(),
            changes=changes
        )

        if agent_id not in self.versions:
            self.versions[agent_id] = []

        self.versions[agent_id].append(new_version)
        return new_version

    def get_version_history(self, agent_id):
        """Obtener historial de versiones"""
        return self.versions.get(agent_id, [])

    def rollback_to_version(self, agent_id, version_number):
        """Revertir a versión anterior"""
        versions = self.versions.get(agent_id, [])
        if version_number &lt; len(versions):
            return versions[version_number]
        return None

    def _get_latest_version(self, agent_id):
        """Obtener versión más reciente"""
        versions = self.versions.get(agent_id, [])
        return versions[-1] if versions else AgentVersion(0, 0, 1, agent_id, "", [])</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Testing y Rollback Automático</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class AutomatedTestingPipeline:
    """Pipeline de testing automático"""

    def __init__(self):
        self.test_results = {}

    def run_test_suite(self, agent, test_cases):
        """Ejecutar suite de tests"""
        results = {
            "agent_id": agent.name,
            "tests": [],
            "passed": 0,
            "failed": 0,
            "timestamp": datetime.now()
        }

        for test in test_cases:
            try:
                result = test.execute(agent)
                results["tests"].append({
                    "name": test.name,
                    "status": "passed",
                    "duration": result.duration
                })
                results["passed"] += 1
            except Exception as e:
                results["tests"].append({
                    "name": test.name,
                    "status": "failed",
                    "error": str(e)
                })
                results["failed"] += 1

        return results

    def should_rollback(self, test_results):
        """Determinar si hacer rollback"""
        fail_rate = test_results["failed"] / (test_results["passed"] + test_results["failed"])
        return fail_rate &gt; 0.1  # Más del 10% de fallos

    def automated_rollback(self, agent_id, previous_version):
        """Rollback automático"""
        print(f"Rolling back {agent_id} to {previous_version}")

        # Ejecutar rollback
        self._execute_rollback(agent_id, previous_version)

        # Verificar salud
        if self._verify_health(agent_id):
            print(f"Rollback successful for {agent_id}")
            return True
        else:
            print(f"Rollback failed for {agent_id}")
            return False

    def _execute_rollback(self, agent_id, version):
        """Ejecutar rollback"""
        # Implementación específica
        pass

    def _verify_health(self, agent_id):
        """Verificar salud post-rollback"""
        # Implementación específica
        return True</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Pipelines automáticos</p>
</li>
<li>
<p>✅ Testing continuo</p>
</li>
<li>
<p>✅ Versionado semántico</p>
</li>
<li>
<p>✅ Rollback automático</p>
</li>
<li>
<p>✅ Monitoreo post-deploy</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_10_integraciones">8. Módulo 10: Integraciones</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_10_1_frameworks_y_librerías">8.1. 10.1. Frameworks y Librerías</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Integración con frameworks y librerías populares en el ecosistema de IA.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Integración con LangChain</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from langchain.agents import initialize_agent, Tool
from langchain.llms import OpenAI
from langchain.memory import ConversationBufferMemory

class LangChainIntegration:
    """Integración con LangChain"""

    def __init__(self):
        self.llm = OpenAI(temperature=0.7)
        self.memory = ConversationBufferMemory()
        self.tools = self._setup_tools()

    def _setup_tools(self):
        """Configurar herramientas de LangChain"""
        tools = [
            Tool(
                name="Calculator",
                func=self._calculate,
                description="Útil para matemáticas"
            ),
            Tool(
                name="Search",
                func=self._search,
                description="Buscar información"
            )
        ]
        return tools

    def create_agent(self):
        """Crear agente con LangChain"""
        agent = initialize_agent(
            self.tools,
            self.llm,
            agent="zero-shot-react-description",
            memory=self.memory,
            verbose=True
        )
        return agent

    def _calculate(self, expression):
        """Función de cálculo"""
        try:
            return str(eval(expression))
        except:
            return "Error in calculation"

    def _search(self, query):
        """Función de búsqueda"""
        # Implementación con API de búsqueda
        return f"Results for: {query}"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Integración con LlamaIndex</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from llama_index import GPTVectorStoreIndex, Document
from llama_index.llms import OpenAI

class LlamaIndexIntegration:
    """Integración con LlamaIndex"""

    def __init__(self):
        self.llm = OpenAI(temperature=0.7)
        self.indices = {}

    def create_index_from_documents(self, documents, index_name):
        """Crear índice a partir de documentos"""
        doc_objects = [
            Document(text=doc["content"], metadata=doc.get("metadata", {}))
            for doc in documents
        ]

        index = GPTVectorStoreIndex.from_documents(doc_objects)
        self.indices[index_name] = index
        return index

    def query_index(self, index_name, query):
        """Consultar índice"""
        if index_name not in self.indices:
            raise ValueError(f"Index {index_name} not found")

        index = self.indices[index_name]
        response = index.as_query_engine().query(query)
        return response

    def hybrid_search(self, index_name, query, top_k=5):
        """Búsqueda híbrida"""
        index = self.indices[index_name]

        # Vector search
        vector_results = index.as_query_engine().query(query)

        # BM25 search
        bm25_results = self._bm25_search(index, query, top_k)

        return {
            "vector_results": vector_results,
            "bm25_results": bm25_results
        }

    def _bm25_search(self, index, query, top_k):
        """Implementar BM25"""
        # Implementación simplificada
        return []</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Arquitectura Multi-Framework</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class MultiFrameworkAgent:
    """Agente que integra múltiples frameworks"""

    def __init__(self):
        self.langchain_agent = None
        self.llamaindex_client = None
        self.autogen_agent = None

    def setup(self, config):
        """Configurar integraciones"""
        # LangChain setup
        self.langchain_agent = LangChainIntegration()

        # LlamaIndex setup
        self.llamaindex_client = LlamaIndexIntegration()

        # AutoGen setup
        self.autogen_agent = AssistantAgent("Agent", config)

    def query(self, prompt, strategy="auto"):
        """Realizar query con framework óptimo"""
        if strategy == "auto":
            strategy = self._select_best_framework(prompt)

        if strategy == "langchain":
            return self.langchain_agent.create_agent().run(prompt)
        elif strategy == "llamaindex":
            return self.llamaindex_client.query_index("default", prompt)
        elif strategy == "autogen":
            return self.autogen_agent.generate_response(prompt)

    def _select_best_framework(self, prompt):
        """Seleccionar mejor framework automáticamente"""
        if "search" in prompt.lower():
            return "langchain"
        elif "document" in prompt.lower():
            return "llamaindex"
        else:
            return "autogen"</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Integración con LangChain</p>
</li>
<li>
<p>✅ Integración con LlamaIndex</p>
</li>
<li>
<p>✅ Arquitectura multi-framework</p>
</li>
<li>
<p>✅ Selección automática de herramientas</p>
</li>
<li>
<p>✅ Composición flexible</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_10_2_apis_y_servicios">8.2. 10.2. APIs y Servicios</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Integración con proveedores de LLM y servicios de IA.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Adaptadores de Múltiples LLMs</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from abc import ABC, abstractmethod
import openai
import anthropic

class LLMAdapter(ABC):
    """Adaptador base para LLMs"""

    @abstractmethod
    def generate(self, prompt, **kwargs):
        pass

class OpenAIAdapter(LLMAdapter):
    """Adaptador para OpenAI"""

    def __init__(self, api_key, model="gpt-4"):
        self.api_key = api_key
        self.model = model
        openai.api_key = api_key

    def generate(self, prompt, temperature=0.7, max_tokens=2000):
        """Generar con OpenAI"""
        response = openai.ChatCompletion.create(
            model=self.model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=max_tokens
        )
        return response.choices[0].message.content

class AnthropicAdapter(LLMAdapter):
    """Adaptador para Anthropic Claude"""

    def __init__(self, api_key, model="claude-3-opus"):
        self.api_key = api_key
        self.model = model
        self.client = anthropic.Anthropic(api_key=api_key)

    def generate(self, prompt, temperature=0.7, max_tokens=2000):
        """Generar con Claude"""
        message = self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            temperature=temperature,
            messages=[{"role": "user", "content": prompt}]
        )
        return message.content[0].text

class UnifiedLLMClient:
    """Cliente unificado para múltiples LLMs"""

    def __init__(self):
        self.adapters = {}
        self.primary_adapter = None

    def register_adapter(self, name, adapter):
        """Registrar adaptador"""
        self.adapters[name] = adapter
        if self.primary_adapter is None:
            self.primary_adapter = name

    def generate(self, prompt, adapter_name=None, **kwargs):
        """Generar con adaptador especificado o primario"""
        if adapter_name is None:
            adapter_name = self.primary_adapter

        if adapter_name not in self.adapters:
            raise ValueError(f"Adapter {adapter_name} not found")

        return self.adapters[adapter_name].generate(prompt, **kwargs)

    def generate_with_fallback(self, prompt, **kwargs):
        """Generar con fallback automático"""
        for adapter_name, adapter in self.adapters.items():
            try:
                return adapter.generate(prompt, **kwargs)
            except Exception as e:
                print(f"Error con {adapter_name}: {e}")
                continue

        raise Exception("All adapters failed")</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Gestión de Cuotas y Costos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from datetime import datetime, timedelta

class APIQuotaManager:
    """Gestor de cuotas de API"""

    def __init__(self):
        self.quotas = {}
        self.usage = {}
        self.costs = {}

    def set_quota(self, service, limit, period="day"):
        """Establecer cuota para servicio"""
        self.quotas[service] = {
            "limit": limit,
            "period": period,
            "reset_at": datetime.now() + timedelta(days=1)
        }
        self.usage[service] = 0

    def record_usage(self, service, tokens=1, cost=0.0):
        """Registrar uso"""
        if service not in self.usage:
            self.usage[service] = 0

        self.usage[service] += tokens

        if service not in self.costs:
            self.costs[service] = 0.0

        self.costs[service] += cost

    def check_quota(self, service):
        """Verificar si hay cuota disponible"""
        if service not in self.quotas:
            return True

        quota = self.quotas[service]

        # Resetear si pasó el período
        if datetime.now() &gt; quota["reset_at"]:
            self.usage[service] = 0
            quota["reset_at"] = datetime.now() + timedelta(days=1)

        return self.usage[service] &lt; quota["limit"]

    def get_usage_report(self):
        """Obtener reporte de uso"""
        report = {}
        for service in self.usage:
            quota = self.quotas.get(service, {})
            report[service] = {
                "used": self.usage[service],
                "limit": quota.get("limit"),
                "cost": self.costs.get(service, 0.0),
                "percentage": (self.usage[service] / quota.get("limit", 1)) * 100 if "limit" in quota else 0
            }
        return report</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Servicio de Recomendación de LLM</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class LLMRecommender:
    """Sistema de recomendación de LLM"""

    def __init__(self):
        self.models_db = self._init_models()

    def recommend(self, task_type, constraints=None):
        """Recomendar modelo para tarea"""
        if constraints is None:
            constraints = {}

        candidates = self._filter_models(task_type, constraints)
        scored = self._score_models(candidates, constraints)

        return sorted(scored, key=lambda x: x["score"], reverse=True)

    def _filter_models(self, task_type, constraints):
        """Filtrar modelos por tipo de tarea"""
        suitable = []
        for model_name, model_info in self.models_db.items():
            if task_type in model_info["capabilities"]:
                # Verificar restricciones
                if self._satisfies_constraints(model_info, constraints):
                    suitable.append((model_name, model_info))

        return suitable

    def _score_models(self, candidates, constraints):
        """Puntuar modelos"""
        scores = []
        for model_name, model_info in candidates:
            score = 100

            # Ajustar por costo
            if "max_cost" in constraints:
                if model_info.get("cost") &gt; constraints["max_cost"]:
                    score -= 50

            # Ajustar por latencia
            if "max_latency" in constraints:
                if model_info.get("latency") &gt; constraints["max_latency"]:
                    score -= 30

            # Ajustar por capacidad
            score += model_info.get("capability_score", 0)

            scores.append({
                "model": model_name,
                "score": score,
                "info": model_info
            })

        return scores

    def _satisfies_constraints(self, model_info, constraints):
        """Verificar si modelo satisface restricciones"""
        for constraint, value in constraints.items():
            if constraint == "min_context_length":
                if model_info.get("context_length", 0) &lt; value:
                    return False
            elif constraint == "language":
                if value not in model_info.get("languages", []):
                    return False

        return True

    def _init_models(self):
        """Inicializar base de datos de modelos"""
        return {
            "gpt-4": {
                "capabilities": ["text", "vision", "code"],
                "cost": 0.03,
                "latency": 1000,
                "context_length": 8000,
                "capability_score": 95
            },
            "claude-3-opus": {
                "capabilities": ["text", "vision"],
                "cost": 0.025,
                "latency": 800,
                "context_length": 200000,
                "capability_score": 90
            },
            "mistral": {
                "capabilities": ["text"],
                "cost": 0.0,
                "latency": 500,
                "context_length": 32000,
                "capability_score": 75
            }
        }</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Múltiples adaptadores de LLM</p>
</li>
<li>
<p>✅ Gestión de cuotas</p>
</li>
<li>
<p>✅ Fallback automático</p>
</li>
<li>
<p>✅ Recomendación de modelo</p>
</li>
<li>
<p>✅ Análisis de costos</p>
</li>
</ul>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_10_3_bases_de_datos">8.3. 10.3. Bases de Datos</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Integración con bases de datos para almacenamiento y búsqueda.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Almacenamiento Vectorial</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import numpy as np
from sentence_transformers import SentenceTransformer

class VectorStoreAdapter:
    """Adaptador para bases de datos vectoriales"""

    def __init__(self, provider="chroma", collection_name="default"):
        self.provider = provider
        self.collection_name = collection_name
        self.embedder = SentenceTransformer('all-MiniLM-L6-v2')

        if provider == "chroma":
            import chromadb
            self.client = chromadb.Client()
            self.collection = self.client.get_or_create_collection(collection_name)
        elif provider == "pinecone":
            import pinecone
            self.index = pinecone.Index("autogen-index")

    def add_documents(self, documents):
        """Agregar documentos"""
        embeddings = self.embedder.encode([d["text"] for d in documents])

        if self.provider == "chroma":
            self.collection.upsert(
                ids=[d["id"] for d in documents],
                embeddings=embeddings.tolist(),
                documents=[d["text"] for d in documents],
                metadatas=[d.get("metadata", {}) for d in documents]
            )
        elif self.provider == "pinecone":
            vectors = [
                (documents[i]["id"], embeddings[i], documents[i].get("metadata", {}))
                for i in range(len(documents))
            ]
            self.index.upsert(vectors=vectors)

    def search(self, query, top_k=5):
        """Búsqueda semántica"""
        query_embedding = self.embedder.encode(query)

        if self.provider == "chroma":
            results = self.collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=top_k
            )
            return results

        elif self.provider == "pinecone":
            results = self.index.query(
                vector=query_embedding.tolist(),
                top_k=top_k,
                include_metadata=True
            )
            return results</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Almacenamiento Relacional</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from sqlalchemy import create_engine, Column, String, Integer, Float
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker

Base = declarative_base()

class AgentInteraction(Base):
    """Modelo de interacción"""
    __tablename__ = "agent_interactions"

    id = Column(Integer, primary_key=True)
    agent_id = Column(String)
    prompt = Column(String)
    response = Column(String)
    timestamp = Column(String)
    tokens_used = Column(Integer)
    latency_ms = Column(Float)

class RelationalDataStore:
    """Almacén de datos relacional"""

    def __init__(self, db_url="sqlite:///autogen.db"):
        self.engine = create_engine(db_url)
        Base.metadata.create_all(self.engine)
        self.Session = sessionmaker(bind=self.engine)

    def save_interaction(self, agent_id, prompt, response, tokens, latency):
        """Guardar interacción"""
        session = self.Session()
        try:
            interaction = AgentInteraction(
                agent_id=agent_id,
                prompt=prompt,
                response=response,
                timestamp=datetime.now().isoformat(),
                tokens_used=tokens,
                latency_ms=latency
            )
            session.add(interaction)
            session.commit()
        finally:
            session.close()

    def query_interactions(self, agent_id, limit=100):
        """Consultar interacciones"""
        session = self.Session()
        try:
            query = session.query(AgentInteraction).filter(
                AgentInteraction.agent_id == agent_id
            ).order_by(AgentInteraction.timestamp.desc()).limit(limit)
            return query.all()
        finally:
            session.close()</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Data Lake y Analytics</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import pandas as pd

class DataLakeManager:
    """Gestor de Data Lake"""

    def __init__(self, data_dir="/data/autogen"):
        self.data_dir = data_dir

    def export_interactions(self, agent_id, format="parquet"):
        """Exportar interacciones a Data Lake"""
        interactions = self._get_interactions(agent_id)

        df = pd.DataFrame([
            {
                "agent_id": i.agent_id,
                "prompt": i.prompt,
                "response": i.response,
                "tokens": i.tokens_used,
                "latency": i.latency_ms
            }
            for i in interactions
        ])

        if format == "parquet":
            df.to_parquet(f"{self.data_dir}/{agent_id}/data.parquet")
        elif format == "csv":
            df.to_csv(f"{self.data_dir}/{agent_id}/data.csv")

        return df

    def analyze_performance(self, agent_id):
        """Analizar rendimiento"""
        df = self.export_interactions(agent_id)

        analysis = {
            "total_interactions": len(df),
            "avg_tokens": df["tokens"].mean(),
            "avg_latency": df["latency"].mean(),
            "p95_latency": df["latency"].quantile(0.95),
            "p99_latency": df["latency"].quantile(0.99)
        }

        return analysis</code></pre>
</div>
</div>
<div class="ulist">
<div class="title"><strong>Características Clave:</strong></div>
<ul>
<li>
<p>✅ Almacenamiento vectorial escalable</p>
</li>
<li>
<p>✅ Datos relacionales con SQL</p>
</li>
<li>
<p>✅ Data Lake para análisis</p>
</li>
<li>
<p>✅ Búsqueda semántica</p>
</li>
<li>
<p>✅ Analytics y reportes</p>
</li>
</ul>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_módulo_11_proyecto_final">9. Módulo 11: Proyecto Final</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_11_1_definición_del_proyecto">9.1. 11.1. Definición del Proyecto</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Metodología para definir, planificar e implementar un proyecto completo con AutoGen.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Análisis de Requisitos</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ProjectRequirementsAnalyzer:
    """Analizador de requisitos de proyecto"""

    def __init__(self):
        self.requirements = {}
        self.constraints = {}
        self.success_criteria = {}

    def analyze_use_case(self, use_case_description):
        """Analizar caso de uso"""
        analysis = {
            "agents_needed": self._identify_agents(use_case_description),
            "data_requirements": self._identify_data(use_case_description),
            "integration_needs": self._identify_integrations(use_case_description),
            "performance_targets": self._set_performance_targets(use_case_description),
            "timeline": self._estimate_timeline(use_case_description)
        }

        return analysis

    def create_architecture_plan(self, analysis):
        """Crear plan de arquitectura"""
        plan = {
            "agent_roles": [
                {"name": agent, "responsibility": self._get_responsibility(agent)}
                for agent in analysis["agents_needed"]
            ],
            "data_flow": self._create_data_flow(analysis),
            "integration_points": analysis["integration_needs"],
            "deployment_strategy": self._select_deployment_strategy(analysis)
        }

        return plan

    def _identify_agents(self, description):
        """Identificar agentes necesarios"""
        # Implementación simplificada
        return ["coordinator", "data_processor", "response_formatter"]

    def _identify_data(self, description):
        """Identificar requisitos de datos"""
        return {"input": "text", "output": "json"}

    def _identify_integrations(self, description):
        """Identificar integraciones necesarias"""
        return ["database", "api", "logging"]

    def _set_performance_targets(self, description):
        """Establecer objetivos de rendimiento"""
        return {
            "max_latency_ms": 5000,
            "max_cost_per_request": 0.50,
            "success_rate": 0.95
        }

    def _estimate_timeline(self, description):
        """Estimar cronograma"""
        return {
            "phase_1_analysis": "1 week",
            "phase_2_development": "2 weeks",
            "phase_3_testing": "1 week",
            "phase_4_deployment": "1 week"
        }

    def _get_responsibility(self, agent):
        """Obtener responsabilidad de agente"""
        responsibilities = {
            "coordinator": "Orquestar flujo de trabajo",
            "data_processor": "Procesar datos de entrada",
            "response_formatter": "Formatear respuesta final"
        }
        return responsibilities.get(agent, "General task")

    def _create_data_flow(self, analysis):
        """Crear diagrama de flujo de datos"""
        return {
            "input": analysis["data_requirements"]["input"],
            "processing": "Multi-step transformation",
            "output": analysis["data_requirements"]["output"]
        }

    def _select_deployment_strategy(self, analysis):
        """Seleccionar estrategia de despliegue"""
        if "high" in str(analysis):
            return "kubernetes"
        return "docker"</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Plan de Implementación</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">from datetime import datetime, timedelta

class ImplementationPlanner:
    """Planificador de implementación"""

    def __init__(self, project_name):
        self.project_name = project_name
        self.milestones = []
        self.tasks = []
        self.dependencies = {}

    def create_implementation_plan(self, architecture):
        """Crear plan detallado"""
        plan = {
            "milestone_1_agent_development": {
                "duration_days": 7,
                "tasks": [
                    "Design agent interfaces",
                    "Implement agent logic",
                    "Add logging and monitoring"
                ]
            },
            "milestone_2_integration": {
                "duration_days": 5,
                "tasks": [
                    "Integrate with databases",
                    "Connect to external APIs",
                    "Setup event handlers"
                ]
            },
            "milestone_3_testing": {
                "duration_days": 5,
                "tasks": [
                    "Unit testing",
                    "Integration testing",
                    "Load testing"
                ]
            },
            "milestone_4_deployment": {
                "duration_days": 3,
                "tasks": [
                    "Pre-production validation",
                    "Deployment",
                    "Post-deployment verification"
                ]
            }
        }

        return plan

    def track_progress(self):
        """Rastrear progreso"""
        progress = {
            "completed": len([t for t in self.tasks if t.get("status") == "done"]),
            "in_progress": len([t for t in self.tasks if t.get("status") == "in_progress"]),
            "pending": len([t for t in self.tasks if t.get("status") == "pending"]),
            "total": len(self.tasks),
            "percentage": (len([t for t in self.tasks if t.get("status") == "done"]) / len(self.tasks)) * 100 if self.tasks else 0
        }

        return progress</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Especificaciones Técnicas</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class TechnicalSpecification:
    """Generador de especificaciones técnicas"""

    def __init__(self, project_architecture):
        self.architecture = project_architecture

    def generate_api_spec(self):
        """Generar especificación de API"""
        return {
            "endpoints": [
                {
                    "path": "/query",
                    "method": "POST",
                    "request": {"prompt": "string"},
                    "response": {"result": "string", "latency": "integer"}
                },
                {
                    "path": "/health",
                    "method": "GET",
                    "response": {"status": "string"}
                }
            ],
            "authentication": "API_KEY",
            "rate_limit": "100 req/minute"
        }

    def generate_db_spec(self):
        """Generar especificación de base de datos"""
        return {
            "tables": [
                {
                    "name": "agent_interactions",
                    "columns": [
                        {"name": "id", "type": "integer", "primary_key": True},
                        {"name": "agent_id", "type": "string"},
                        {"name": "prompt", "type": "text"},
                        {"name": "response", "type": "text"},
                        {"name": "timestamp", "type": "datetime"}
                    ]
                }
            ],
            "indexes": [
                {"table": "agent_interactions", "columns": ["agent_id", "timestamp"]}
            ]
        }

    def generate_security_spec(self):
        """Generar especificación de seguridad"""
        return {
            "authentication": "OAuth2",
            "encryption": "TLS 1.3",
            "input_validation": "Strict",
            "rate_limiting": "Enabled",
            "audit_logging": "All requests",
            "secret_management": "Vault"
        }</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_11_2_desarrollo">9.2. 11.2. Desarrollo</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Proceso iterativo de desarrollo, testing y refinamiento.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Desarrollo Iterativo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IterativeDevelopmentCycle:
    """Ciclo iterativo de desarrollo"""

    def __init__(self, sprint_length_days=7):
        self.sprint_length = sprint_length_days
        self.sprints = []
        self.current_sprint = None

    def start_sprint(self, sprint_number, objectives):
        """Iniciar sprint"""
        sprint = {
            "number": sprint_number,
            "objectives": objectives,
            "start_date": datetime.now(),
            "end_date": datetime.now() + timedelta(days=self.sprint_length),
            "tasks": [],
            "status": "in_progress"
        }

        self.current_sprint = sprint
        self.sprints.append(sprint)
        return sprint

    def add_task(self, task_name, story_points, assignee):
        """Agregar tarea al sprint"""
        task = {
            "name": task_name,
            "story_points": story_points,
            "assignee": assignee,
            "status": "todo",
            "created_at": datetime.now()
        }

        if self.current_sprint:
            self.current_sprint["tasks"].append(task)
        return task

    def complete_sprint(self):
        """Completar sprint"""
        if self.current_sprint:
            self.current_sprint["status"] = "completed"
            self.current_sprint["end_date"] = datetime.now()

    def get_velocity(self):
        """Obtener velocidad del equipo"""
        completed_sprints = [s for s in self.sprints if s["status"] == "completed"]
        if not completed_sprints:
            return 0

        total_points = sum(
            sum(t.get("story_points", 0) for t in s.get("tasks", []))
            for s in completed_sprints
        )

        return total_points / len(completed_sprints)</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Testing Integrado</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class IntegratedTestingSuite:
    """Suite de testing integrada"""

    def __init__(self, project):
        self.project = project
        self.test_results = []

    def run_unit_tests(self, agent):
        """Ejecutar unit tests"""
        tests = {
            "test_agent_initialization": self._test_init(agent),
            "test_generate_response": self._test_generate(agent),
            "test_error_handling": self._test_errors(agent)
        }

        return {"unit_tests": tests}

    def run_integration_tests(self):
        """Ejecutar integration tests"""
        tests = {
            "test_agent_communication": self._test_communication(),
            "test_database_integration": self._test_database(),
            "test_api_endpoints": self._test_api()
        }

        return {"integration_tests": tests}

    def run_performance_tests(self):
        """Ejecutar performance tests"""
        metrics = {
            "latency": self._measure_latency(),
            "throughput": self._measure_throughput(),
            "memory_usage": self._measure_memory()
        }

        return {"performance_metrics": metrics}

    def _test_init(self, agent):
        return {"passed": agent is not None}

    def _test_generate(self, agent):
        response = agent.generate_response("Test")
        return {"passed": len(response) &gt; 0}

    def _test_errors(self, agent):
        return {"passed": True}

    def _test_communication(self):
        return {"passed": True}

    def _test_database(self):
        return {"passed": True}

    def _test_api(self):
        return {"passed": True}

    def _measure_latency(self):
        return {"avg_ms": 150, "p95_ms": 300}

    def _measure_throughput(self):
        return {"requests_per_second": 100}

    def _measure_memory(self):
        return {"peak_mb": 256}</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Refinamiento Continuo</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ContinuousRefinement:
    """Sistema de refinamiento continuo"""

    def __init__(self, agent):
        self.agent = agent
        self.improvements = []
        self.feedback_log = []

    def collect_feedback(self, feedback_item):
        """Recopilar feedback"""
        self.feedback_log.append({
            "timestamp": datetime.now(),
            "feedback": feedback_item,
            "addressed": False
        })

    def analyze_feedback(self):
        """Analizar feedback recibido"""
        patterns = {}
        for feedback in self.feedback_log:
            if not feedback["addressed"]:
                category = self._categorize_feedback(feedback["feedback"])
                patterns[category] = patterns.get(category, 0) + 1

        return patterns

    def implement_improvement(self, improvement_description):
        """Implementar mejora"""
        improvement = {
            "description": improvement_description,
            "implemented_at": datetime.now(),
            "impact": "pending"
        }

        self.improvements.append(improvement)
        return improvement

    def measure_improvement_impact(self, improvement):
        """Medir impacto de mejora"""
        # Comparar métricas antes y después
        impact = {
            "latency_reduction": 10,
            "accuracy_improvement": 5,
            "cost_reduction": 2
        }

        improvement["impact"] = impact
        return impact

    def _categorize_feedback(self, feedback):
        """Categorizar feedback"""
        if "slow" in feedback.lower():
            return "performance"
        elif "error" in feedback.lower():
            return "reliability"
        else:
            return "feature"</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_11_3_presentación">9.3. 11.3. Presentación</h3>
<div class="paragraph">
<p><strong>Concepto:</strong> Documentación, demostración y análisis de resultados del proyecto.</p>
</div>
<div class="paragraph">
<p><strong>Opción 1: Documentación Técnica</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class TechnicalDocumentationGenerator:
    """Generador de documentación técnica"""

    def __init__(self, project):
        self.project = project

    def generate_architecture_doc(self):
        """Generar documento de arquitectura"""
        doc = f"""
# Arquitectura del Proyecto {self.project.name}

## Componentes Principales
- **Agentes**: Componentes autónomos que toman decisiones
- **LLM**: Motor de razonamiento basado en modelos de lenguaje
- **Almacenamiento**: Persistencia de datos y estado
- **APIs**: Interfaz de comunicación externa

## Flujo de Datos
[Diagrama ASCII de flujo]

## Decisiones Técnicas
- Framework: AutoGen
- LLM: Ollama local (Mistral)
- Base de datos: PostgreSQL + ChromaDB
        """
        return doc

    def generate_agent_doc(self, agent):
        """Generar documentación de agente"""
        doc = f"""
# Agente: {agent.name}

## Responsabilidades
{agent.responsibilities}

## Interfaces
.
- Input: {agent.input_format}
- Output: {agent.output_format}

## Métodos Principales
{self._list_methods(agent)}
        """
        return doc

    def _list_methods(self, agent):
        methods = [m for m in dir(agent) if not m.startswith('_')]
        return "\n".join([f"- {m}" for m in methods[:5]])</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 2: Demostración del Sistema</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class SystemDemonstration:
    """Demostración del sistema"""

    def __init__(self, project):
        self.project = project
        self.demo_scenarios = []

    def create_demo_scenario(self, name, description, steps):
        """Crear escenario de demostración"""
        scenario = {
            "name": name,
            "description": description,
            "steps": steps,
            "results": []
        }

        self.demo_scenarios.append(scenario)
        return scenario

    def execute_demo(self, scenario_name):
        """Ejecutar demostración"""
        scenario = next(s for s in self.demo_scenarios if s["name"] == scenario_name)

        results = []
        for step in scenario["steps"]:
            result = self._execute_step(step)
            results.append(result)
            scenario["results"].append(result)

        return results

    def _execute_step(self, step):
        """Ejecutar paso de demostración"""
        return {
            "step": step,
            "output": f"Output for: {step}",
            "duration_ms": 100
        }</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>Opción 3: Análisis y Reportes</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">class ProjectAnalysisReporter:
    """Reportero de análisis del proyecto"""

    def __init__(self, project):
        self.project = project

    def generate_final_report(self):
        """Generar reporte final"""
        report = {
            "project_name": self.project.name,
            "timeline": self._analyze_timeline(),
            "budget": self._analyze_budget(),
            "performance": self._analyze_performance(),
            "lessons_learned": self._extract_lessons(),
            "recommendations": self._generate_recommendations()
        }

        return report

    def _analyze_timeline(self):
        return {
            "planned_duration": "4 weeks",
            "actual_duration": "4.2 weeks",
            "variance": "+2%"
        }

    def _analyze_budget(self):
        return {
            "planned_cost": "$10,000",
            "actual_cost": "$9,800",
            "variance": "-2%"
        }

    def _analyze_performance(self):
        return {
            "success_rate": "98%",
            "avg_latency": "150ms",
            "throughput": "100 req/s"
        }

    def _extract_lessons(self):
        return [
            "AutoGen provides excellent abstraction for multi-agent systems",
            "Proper monitoring is critical in production",
            "Testing early prevents major refactoring late"
        ]

    def _generate_recommendations(self):
        return [
            "Consider scaling horizontally with Kubernetes",
            "Implement more sophisticated caching strategies",
            "Expand agent capabilities with domain-specific knowledge"
        ]</code></pre>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_anexos">10. Anexos</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_a_recursos_adicionales">10.1. A. Recursos Adicionales</h3>
<div class="paragraph">
<p><strong>Documentación Oficial:</strong>
- AutoGen Documentation: <a href="https://microsoft.github.io/autogen/" class="bare">https://microsoft.github.io/autogen/</a>
- Ollama Documentation: <a href="https://github.com/ollama/ollama" class="bare">https://github.com/ollama/ollama</a>
- LangChain Documentation: <a href="https://python.langchain.com/" class="bare">https://python.langchain.com/</a>
- LlamaIndex Documentation: <a href="https://docs.llamaindex.ai/" class="bare">https://docs.llamaindex.ai/</a></p>
</div>
<div class="paragraph">
<p><strong>Repositorios de Ejemplo:</strong>
- AutoGen Examples: <a href="https://github.com/microsoft/autogen/tree/main/examples" class="bare">https://github.com/microsoft/autogen/tree/main/examples</a>
- Ollama Examples: <a href="https://github.com/ollama/examples" class="bare">https://github.com/ollama/examples</a>
- Community Projects: <a href="https://github.com/topics/autogen" class="bare">https://github.com/topics/autogen</a></p>
</div>
<div class="paragraph">
<p><strong>Comunidad y Foros:</strong>
- AutoGen GitHub Discussions
- Stack Overflow: Tags autogen, langchain
- Reddit: r/LanguageModels</p>
</div>
<div class="paragraph">
<p><strong>Artículos y Papers:</strong>
- "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation"
- Papers on arxiv.org related to agent systems
- Blog posts on Medium and Dev.to</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_b_glosario_de_términos">10.2. B. Glosario de Términos</h3>
<div class="paragraph">
<p><strong>Terminología de AutoGen:</strong>
- <strong>Agent</strong>: Entidad autónoma que interactúa con otros agentes
- <strong>Conversation</strong>: Intercambio de mensajes entre agentes
- <strong>UserProxyAgent</strong>: Agente que representa al usuario
- <strong>AssistantAgent</strong>: Agente que responde usando un LLM</p>
</div>
<div class="paragraph">
<p><strong>Conceptos de LLM:</strong>
- <strong>Token</strong>: Unidad atómica de texto (palabra o subpalabra)
- <strong>Prompt</strong>: Entrada de texto para el LLM
- <strong>Temperature</strong>: Parámetro que controla aleatoriedad (0-1)
- <strong>Context Window</strong>: Número máximo de tokens en una conversación</p>
</div>
<div class="paragraph">
<p><strong>Arquitectura de Agentes:</strong>
- <strong>Reasoning</strong>: Proceso de deducción del agente
- <strong>Acting</strong>: Ejecución de acciones del agente
- <strong>Learning</strong>: Mejora del agente con experiencia
- <strong>Coordination</strong>: Sincronización entre múltiples agentes</p>
</div>
<div class="paragraph">
<p><strong>Referencias Técnicas:</strong>
- <strong>Ollama</strong>: Herramienta para ejecutar LLMs localmente
- <strong>Mistral</strong>: Modelo de lenguaje abierto
- <strong>Embeddings</strong>: Representaciones vectoriales de texto
- <strong>Vector Database</strong>: BD especializada en búsqueda vectorial</p>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_c_mejores_prácticas">10.3. C. Mejores Prácticas</h3>
<div class="paragraph">
<p><strong>Patrones de Diseño:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>Single Responsibility Pattern</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Cada agente tiene una responsabilidad clara</p>
</li>
<li>
<p>Facilita testing y mantenimiento</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Observer Pattern</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Agentes observan cambios en el estado</p>
</li>
<li>
<p>Comunicación desacoplada</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>Factory Pattern</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Crear agentes de forma programática</p>
</li>
<li>
<p>Configuración centralizada</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Anti-patrones a Evitar:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>❌ <strong>Monolithic Agent</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Todos los agentes en uno</p>
</li>
<li>
<p>Difícil de probar y mantener</p>
</li>
</ul>
</div>
</li>
<li>
<p>❌ <strong>No Error Handling</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Sin manejo de excepciones</p>
</li>
<li>
<p>Sistema frágil</p>
</li>
</ul>
</div>
</li>
<li>
<p>❌ <strong>Hardcoded Configuration</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Sin separación de configuración</p>
</li>
<li>
<p>Difícil de desplegar</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Optimización de Rendimiento:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Implementar caché para respuestas frecuentes</p>
</li>
<li>
<p>Usar embeddings para búsqueda rápida</p>
</li>
<li>
<p>Monitorear latencia y tokens continuamente</p>
</li>
<li>
<p>Implementar rate limiting</p>
</li>
<li>
<p>Usar connection pooling para BD</p>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Guías de Estilo:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># ✅ Bueno
class DataProcessingAgent(AssistantAgent):
    """Agente especializado en procesamiento de datos"""

    def process_data(self, data: dict) -&gt; dict:
        """Procesar datos de entrada"""
        # Implementación clara
        pass

# ❌ Malo
class A(AssistantAgent):
    def p(self, d):  # Nombres poco claros
        pass</code></pre>
</div>
</div>
<hr>
</div>
<div class="sect2">
<h3 id="_d_troubleshooting">10.4. D. Troubleshooting</h3>
<div class="paragraph">
<p><strong>Problemas Comunes:</strong></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p><strong>"Ollama connection refused"</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Solución: Verificar que Ollama esté ejecutándose</p>
</li>
<li>
<p>Comando: <code>ollama serve</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>"Model not found"</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Solución: Descargar el modelo</p>
</li>
<li>
<p>Comando: <code>ollama pull mistral</code></p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>"Token limit exceeded"</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Solución: Usar modelo con mayor context window</p>
</li>
<li>
<p>O: Implementar compresión de contexto</p>
</li>
</ul>
</div>
</li>
<li>
<p><strong>"Memory usage too high"</strong>
.</p>
<div class="ulist">
<ul>
<li>
<p>Solución: Reducir batch size</p>
</li>
<li>
<p>O: Implementar paginación</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p><strong>Soluciones Rápidas:</strong></p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Debug mode
import logging
logging.basicConfig(level=logging.DEBUG)

# Health check
from ollama_utils import test_ollama_connection
if test_ollama_connection():
    print("Ollama is working!")

# Monitor resources
import psutil
print(f"Memory: {psutil.virtual_memory().percent}%")</code></pre>
</div>
</div>
<div class="paragraph">
<p><strong>FAQ:</strong></p>
</div>
<div class="paragraph">
<p><strong>P: ¿Cuál es la diferencia entre AssistantAgent y UserProxyAgent?</strong>
R: AssistantAgent usa LLM para responder, UserProxyAgent representa al usuario.</p>
</div>
<div class="paragraph">
<p><strong>P: ¿Puedo usar AutoGen sin Ollama?</strong>
R: Sí, pero requieres una API key de OpenAI o similar.</p>
</div>
<div class="paragraph">
<p><strong>P: ¿Cómo escalalo a producción?</strong>
R: Usar Kubernetes con múltiples réplicas de agentes.</p>
</div>
<div class="paragraph">
<p><strong>P: ¿Cuál es el costo típico?</strong>
R: Depende del proveedor. Ollama local = $0. OpenAI = $0.001-0.1 por request.</p>
</div>
<div class="paragraph">
<p><strong>Soporte y Ayuda:</strong></p>
</div>
<div class="ulist">
<ul>
<li>
<p>GitHub Issues: <a href="https://github.com/microsoft/autogen/issues" class="bare">https://github.com/microsoft/autogen/issues</a></p>
</li>
<li>
<p>Discussions: <a href="https://github.com/microsoft/autogen/discussions" class="bare">https://github.com/microsoft/autogen/discussions</a></p>
</li>
<li>
<p>Email: <a href="mailto:autogen@microsoft.com">autogen@microsoft.com</a> (si aplica)</p>
</li>
</ul>
</div>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2025-11-16 22:42:50 +0100
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code[data-lang]')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>