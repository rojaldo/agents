# Contenidos DidÃ¡cticos: EvaluaciÃ³n y Testing de Agentes IA

## ğŸ“š Ãndice
1. [MÃ³dulo 1: MÃ©tricas de DesempeÃ±o](#mÃ³dulo-1)
2. [MÃ³dulo 2: Benchmarks y Datasets](#mÃ³dulo-2)
3. [MÃ³dulo 3: Testing Funcional](#mÃ³dulo-3)
4. [MÃ³dulo 4: Debugging y Monitoreo](#mÃ³dulo-4)

---

## <a name="mÃ³dulo-1"></a>MÃ³dulo 1: MÃ©tricas de DesempeÃ±o de Agentes

### Â¿Por QuÃ© MÃ©tricas?

Imagina que construiste un agente de IA. Â¿CÃ³mo sabes si es BUENO?

```
Pregunta: "Â¿Mi agente es bueno?"

Respuestas MALAS:
  âŒ "Parece que funciona"
  âŒ "La mayorÃ­a de veces acierta"
  âŒ "Mis amigos dicen que estÃ¡ bien"

Respuestas BUENAS:
  âœ… "Accuracy del 94.3% en 10,000 muestras"
  âœ… "Latencia P95 de 120ms"
  âœ… "Maneja fallos en 99.9% de casos"
```

Las MÃ‰TRICAS nos permiten MEDIR y COMPARAR.

### 1.1 Framework General de MÃ©tricas

```python
class MetricFramework:
    """
    CATEGORÃAS DE MÃ‰TRICAS

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ 1. EFECTIVIDAD: Â¿Hace lo que debe?      â”‚
    â”‚    - Accuracy, Precision, Recall, F1    â”‚
    â”‚                                          â”‚
    â”‚ 2. EFICIENCIA: Â¿A quÃ© costo?             â”‚
    â”‚    - Latencia, Throughput, Recursos     â”‚
    â”‚                                          â”‚
    â”‚ 3. ROBUSTEZ: Â¿QuÃ© tan resiliente?       â”‚
    â”‚    - Error Rate, Recovery Time          â”‚
    â”‚                                          â”‚
    â”‚ 4. SEGURIDAD: Â¿Es seguro?               â”‚
    â”‚    - Violaciones, Fairness, Adversarial â”‚
    â”‚                                          â”‚
    â”‚ 5. ESCALABILIDAD: Â¿Funciona mÃ¡s grande? â”‚
    â”‚    - Performance con + carga            â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    """

    def __init__(self):
        self.metrics = {}
        self.measurements = []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1ï¸âƒ£ MÃ‰TRICAS DE EFECTIVIDAD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class EffectivenessMetrics:
    """
    Â¿QUÃ‰ TAN BIEN HACE LO QUE DEBE?

    CASO: Agente clasifica emails en Spam / No-Spam

    Matriz de confusiÃ³n:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Predice SPAM     â”‚ Predice NO-SPAM  â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ TP: 95 Correcto  â”‚ FN: 5 Perdidos   â”‚ Realmente SPAM
    â”‚ (detectÃ³ spam)   â”‚ (no detectÃ³)     â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚ FP: 3 Error      â”‚ TN: 97 Correcto  â”‚ Realmente NO-SPAM
    â”‚ (falsa alarma)   â”‚ (detectÃ³ bien)   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Donde:
    - TP (True Positive): Predijo SPAM, era SPAM âœ“
    - TN (True Negative): Predijo NO-SPAM, era NO-SPAM âœ“
    - FP (False Positive): Predijo SPAM, era NO-SPAM âœ—
    - FN (False Negative): Predijo NO-SPAM, era SPAM âœ—
    """

    def __init__(self, true_positives, true_negatives,
                 false_positives, false_negatives):
        self.TP = true_positives      # 95
        self.TN = true_negatives      # 97
        self.FP = false_positives     # 3
        self.FN = false_negatives     # 5

    def accuracy(self):
        """
        ACCURACY: Â¿CuÃ¡ntas predicciones fueron correctas?

        FÃ³rmula: (TP + TN) / Total

        Rango: 0% (todos mal) â†’ 100% (todos bien)

        InterpretaciÃ³n: De 200 emails, Â¿cuÃ¡ntos clasificÃ³ bien?
        """
        total = self.TP + self.TN + self.FP + self.FN
        acc = (self.TP + self.TN) / total * 100
        return f"Accuracy: {acc:.1f}%"

        # Ejemplo:
        # (95 + 97) / 200 = 192/200 = 96%
        # El agente clasifica BIEN el 96% de emails

    def precision(self):
        """
        PRECISION: De los que predijo como SPAM, Â¿cuÃ¡ntos eran realmente SPAM?

        Pregunta: Si te digo "es SPAM", Â¿confÃ­o?

        FÃ³rmula: TP / (TP + FP)

        Rango: 0% (sin confianza) â†’ 100% (muy confiable)
        """
        if self.TP + self.FP == 0:
            return 0

        prec = self.TP / (self.TP + self.FP) * 100
        return f"Precision: {prec:.1f}%"

        # Ejemplo:
        # TP=95, FP=3 â†’ 95/(95+3) = 95/98 = 96.9%
        # Si te digo "es SPAM", tengo 96.9% de confianza

    def recall(self):
        """
        RECALL: De TODOS los SPAMs reales, Â¿cuÃ¡ntos detectÃ©?

        Pregunta: Â¿De cuÃ¡ntos spams reales me entero?

        FÃ³rmula: TP / (TP + FN)

        Rango: 0% (no detecta) â†’ 100% (detecta todos)
        """
        if self.TP + self.FN == 0:
            return 0

        rec = self.TP / (self.TP + self.FN) * 100
        return f"Recall: {rec:.1f}%"

        # Ejemplo:
        # TP=95, FN=5 â†’ 95/(95+5) = 95/100 = 95%
        # DetectÃ© el 95% de todos los spams

    def f1_score(self):
        """
        F1-SCORE: Promedio armÃ³nico de Precision y Recall

        Usa esto cuando PRECISION y RECALL son igualmente importantes

        FÃ³rmula: 2 * (precision * recall) / (precision + recall)

        Rango: 0 (terrible) â†’ 1 (perfecto)
        """
        prec = self.TP / (self.TP + self.FP) if (self.TP + self.FP) > 0 else 0
        rec = self.TP / (self.TP + self.FN) if (self.TP + self.FN) > 0 else 0

        if prec + rec == 0:
            return 0

        f1 = 2 * (prec * rec) / (prec + rec)
        return f"F1-Score: {f1:.2f}"

        # Ejemplo: Precision=0.969, Recall=0.95
        # F1 = 2 * (0.969 * 0.95) / (0.969 + 0.95)
        #    = 2 * 0.920 / 1.919
        #    = 0.960

    def compare_agents(self):
        """
        ComparaciÃ³n prÃ¡ctica entre dos agentes
        """

        print("""
        AGENTE A vs AGENTE B

        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ MÃ©trica     â”‚ Agente A   â”‚ Agente B   â”‚
        â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â”‚ Accuracy    â”‚ 96.0%      â”‚ 92.0%      â”‚ Mejor: A
        â”‚ Precision   â”‚ 96.9%      â”‚ 99.0%      â”‚ Mejor: B (menos falsos positivos)
        â”‚ Recall      â”‚ 95.0%      â”‚ 89.0%      â”‚ Mejor: A (detecta mÃ¡s spams)
        â”‚ F1-Score    â”‚ 0.960      â”‚ 0.940      â”‚ Mejor: A (balance general)
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

        DECISIÃ“N:
        - Â¿Importa mÃ¡s NO dejar pasar spam? â†’ Agente B (alta precision)
        - Â¿Importa detectar todo spam posible? â†’ Agente A (alto recall)
        - Â¿Queremos balance? â†’ Agente A (F1 mayor)
        """)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2ï¸âƒ£ MÃ‰TRICAS DE EFICIENCIA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class EfficiencyMetrics:
    """
    Â¿A QUÃ‰ COSTO DE RECURSOS?
    """

    def __init__(self):
        self.requests = []      # [(request_time, response_time), ...]
        self.cpu_usage = []
        self.memory_usage = []
        self.cost_per_request = []

    def latency(self):
        """
        LATENCIA: Â¿CuÃ¡nto tarda en responder?

        Medidas clave: P50, P95, P99 (percentiles)

        EJEMPLO: 1000 requests ordenados por tiempo
        """

        response_times = [50, 55, 60, ..., 150, 200]  # 1000 valores

        # P50: 50% de requests son â‰¤ este tiempo
        p50 = sorted(response_times)[len(response_times) // 2]
        # â†’ "50% de requests responden en â‰¤ 100ms"

        # P95: 95% de requests son â‰¤ este tiempo
        p95 = sorted(response_times)[int(len(response_times) * 0.95)]
        # â†’ "95% de requests responden en â‰¤ 150ms"

        # P99: 99% de requests son â‰¤ este tiempo
        p99 = sorted(response_times)[int(len(response_times) * 0.99)]
        # â†’ "99% de requests responden en â‰¤ 200ms"

        print(f"""
        LATENCIA:
        - P50 (mediana): {p50}ms - Tiempo tÃ­pico
        - P95: {p95}ms - Tiempo lentitud tolerable
        - P99: {p99}ms - Peor caso aceptable
        """)

        return {'p50': p50, 'p95': p95, 'p99': p99}

    def throughput(self):
        """
        THROUGHPUT: Â¿CuÃ¡ntas requests por segundo?

        RPS = Requests Per Second

        EJEMPLO:
        - Agente A: 1000 RPS
        - Agente B: 500 RPS
        â†’ Agente A es 2x mÃ¡s rÃ¡pido
        """

        total_time = 100  # segundos
        num_requests = 50000

        rps = num_requests / total_time
        print(f"Throughput: {rps} RPS")

        return rps

    def resource_usage(self):
        """
        CONSUMO DE RECURSOS

        Medir:
        - CPU: % utilizaciÃ³n
        - Memory: MB / GB usados
        - Disk: I/O operaciones
        """

        resources = {
            'cpu_percent': 45,      # 45% de CPU
            'memory_mb': 512,       # 512 MB de RAM
            'memory_percent': 25,   # 25% del total
            'disk_io_ops': 1000,    # 1000 operaciones/sec
        }

        print(f"""
        RECURSOS:
        - CPU: {resources['cpu_percent']}%
        - Memoria: {resources['memory_mb']}MB ({resources['memory_percent']}%)
        - Disk I/O: {resources['disk_io_ops']} ops/sec
        """)

        return resources

    def cost_per_operation(self):
        """
        COSTO MONETARIO

        Importante si usas APIs pagas (OpenAI, etc.)

        EJEMPLO: GPT-4 cuesta por token
        """

        inputs_tokens = 150
        outputs_tokens = 50
        price_input = 0.03 / 1000  # $0.03 por 1000 tokens
        price_output = 0.06 / 1000  # $0.06 por 1000 tokens

        cost = (inputs_tokens * price_input +
                outputs_tokens * price_output)

        print(f"Costo por request: ${cost:.4f}")
        return cost


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3ï¸âƒ£ MÃ‰TRICAS DE ROBUSTEZ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class RobustnessMetrics:
    """
    Â¿QUÃ‰ TAN RESILIENTE ES?
    """

    def __init__(self):
        self.total_requests = 10000
        self.failed_requests = 15
        self.failures = []  # timestamps of failures

    def error_rate(self):
        """
        ERROR RATE: Â¿CuÃ¡ntas requests fallan?

        Target tÃ­pico: < 0.1%
        """
        error_rate = self.failed_requests / self.total_requests * 100
        print(f"Error Rate: {error_rate:.3f}%")

        if error_rate < 0.1:
            print("âœ“ Excelente: < 0.1%")
        elif error_rate < 0.5:
            print("âœ“ Bueno: < 0.5%")
        elif error_rate < 1:
            print("âš  Aceptable: < 1%")
        else:
            print("âœ— Inaceptable: > 1%")

    def mean_time_between_failures(self):
        """
        MTBF: Promedio de tiempo entre fallos

        EJEMPLO:
        - 10 fallos en 100 horas de operaciÃ³n
        - MTBF = 100 / 10 = 10 horas
        â†’ Fallo cada 10 horas

        Mayor MTBF = MÃ¡s confiable
        """
        uptime_hours = 1000
        num_failures = 10

        mtbf = uptime_hours / num_failures
        print(f"MTBF: {mtbf} horas entre fallos")

        return mtbf

    def recovery_time(self):
        """
        RECOVERY TIME: Â¿CuÃ¡nto tarda en recuperarse?

        EJEMPLO:
        - Fallo detectado: 14:00:00
        - Sistema recuperado: 14:02:30
        - Recovery time: 150 segundos
        """
        detection_time = 14.0  # 14:00
        recovery_time = 14.042  # 14:02:30

        downtime = (recovery_time - detection_time) * 60 * 60  # segundos
        print(f"Downtime: {downtime:.0f} segundos ({downtime/60:.1f} minutos)")

        return downtime

    def consistency_check(self):
        """
        CONSISTENCY: Â¿Da misma respuesta para mismo input?

        Importante para debugging
        """

        def query_agent(input_data):
            # Agente responde
            return "response"

        # Hacer same query 10 veces
        input_data = "What is 2+2?"
        responses = set()

        for i in range(10):
            response = query_agent(input_data)
            responses.add(response)

        if len(responses) == 1:
            print("âœ“ Determinista: Siempre da misma respuesta")
        else:
            print(f"âš  No-determinista: Da {len(responses)} respuestas diferentes")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RESUMEN: TABLA DE MÃ‰TRICAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

print("""
MÃ‰TRICA               FÃ“RMULA              IDEAL       CUÃNDO USAR
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
EFECTIVIDAD:
Accuracy             (TP+TN)/Total        â†‘ Alto      Clases balanceadas
Precision            TP/(TP+FP)           â†‘ Alto      Falsos pos. costosos
Recall               TP/(TP+FN)           â†‘ Alto      Falsos neg. costosos
F1-Score             Promedio             â†‘ Alto      Balance importante

EFICIENCIA:
Latency (P95)        Percentil 95%        â†“ Bajo      User experience
Throughput (RPS)     Req/segundo          â†‘ Alto      Capacidad
Memory usage         MB / % total         â†“ Bajo      Escalabilidad
Cost/op              Dinero/request       â†“ Bajo      APIs pagas

ROBUSTEZ:
Error rate           Fallos/total         â†“ <0.1%     Confiabilidad
MTBF                 Horas/fallo          â†‘ Alto      Disponibilidad
Recovery time        Seg hasta funcionar   â†“ Bajo      Tolerancia fallos
Consistency          % mismas respuestas   â†‘ 100%      Debugging
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
""")
```

### 1.2 ElecciÃ³n de MÃ©tricas

```python
class ChooseMetrics:
    """
    Â¿QUÃ‰ MÃ‰TRICAS USAR?

    REGLA DE ORO:
    Las mÃ©tricas deben alinearse con OBJETIVOS DE NEGOCIO

    NO elijas arbitrariamente
    """

    @staticmethod
    def case_email_spam_filter():
        """
        CASO: Filtro de spam de email

        OBJETIVOS:
        1. No dejar pasar spam (alta recall)
        2. No marcar email legÃ­timo como spam (alta precision)
        3. Responder rÃ¡pido (baja latencia)

        MÃ‰TRICAS:
        âœ“ Recall: Detecta 95%+ de spam
        âœ“ Precision: Solo 1% falsas alarmas
        âœ“ Latency P95: < 100ms
        âœ“ Throughput: > 10000 RPS
        """
        pass

    @staticmethod
    def case_medical_diagnosis():
        """
        CASO: Agente diagnosticador mÃ©dico

        OBJETIVOS:
        1. No perder ninguna enfermedad crÃ­tica (recall >> precision)
        2. Respuestas consistentes (doctors revisarÃ¡n)
        3. NO importa tanto la velocidad (es medicina, no urgente)

        MÃ‰TRICAS:
        âœ“ Recall: â‰¥ 98% (No perder enfermedades)
        âœ“ Consistency: 100% (Determinista)
        âœ“ Robustness: 99.99% uptime
        âœ— Latency: No importante
        âœ— Throughput: No importante
        """
        pass

    @staticmethod
    def case_autonomous_vehicles():
        """
        CASO: Agente conducciÃ³n autÃ³noma

        OBJETIVOS:
        1. MÃ¡xima seguridad (casi 100% correcto)
        2. Muy bajo latency (decisiones en ms)
        3. MÃ¡xima robustez (no puede fallar)

        MÃ‰TRICAS:
        âœ“ Accuracy: > 99.9%
        âœ“ Latency P99: < 50ms
        âœ“ Error rate: < 0.001%
        âœ“ MTBF: > 1000000 horas
        âœ“ Adversarial robustness: Resiste ataques
        âœ— Cost: No importante
        """
        pass
```

---

## <a name="mÃ³dulo-2"></a>MÃ³dulo 2: Benchmarks y Datasets

### 2.1 Creando Buen Benchmark

```python
class BenchmarkDesign:
    """
    UN BENCHMARK es un CONJUNTO DE PRUEBAS
    que permite medir desempeÃ±o de forma estÃ¡ndar y reproducible
    """

    def __init__(self):
        self.test_cases = []
        self.expected_outputs = []

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CARACTERÃSTICA 1: REPRESENTATIVO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def create_representative_benchmark(self):
        """
        El benchmark debe cubrir CASOS TÃPICOS

        EJEMPLO: Spam filter
        - 60% emails legÃ­timos normales
        - 30% spam obvio
        - 7% spam sofisticado
        - 3% edge cases (emails muy cortos, etc.)

        IGUAL A la distribuciÃ³n en PRODUCCIÃ“N
        """

        benchmark_spam = {
            'normal_legitimate': 600,      # 60%
            'obvious_spam': 300,           # 30%
            'sophisticated_spam': 70,      # 7%
            'edge_cases': 30                # 3%
        }

        total = sum(benchmark_spam.values())
        print(f"Benchmark total: {total} casos")
        print("DistribuciÃ³n representa mundo real âœ“")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CARACTERÃSTICA 2: DESAFIANTE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def create_challenging_benchmark(self):
        """
        El benchmark debe SER DIFÃCIL

        NO: Todos los agentes sacan > 99%
        SÃ: Diferencia entre agentes buenos y malos
        """

        # âœ— BENCHMARK FÃCIL (malo):
        easy_cases = [
            ("Compra viagra aquÃ­", "SPAM"),
            ("Hola, Â¿cÃ³mo estÃ¡s?", "NOT_SPAM"),
            ("GANAR MILLONES AHORA", "SPAM"),
        ]

        # Agente A: 100% accuracy (trivial!)
        # Agente B: 100% accuracy (trivial!)
        # No podemos distinguir calidad

        # âœ“ BENCHMARK DIFÃCIL (bueno):
        hard_cases = [
            ("Ãšnete a nuestro programa de loyalidad", "?"),  # PodrÃ­a ser
            ("Te ofrezco excelentes resultados en marketing", "?"),  # Ambiguo
            ("Cambio de polÃ­tica en nuestro servicio", "?"),  # LegÃ­timo o spam?
        ]

        # Agente A: 85% accuracy
        # Agente B: 92% accuracy
        # Podemos ver diferencia

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CARACTERÃSTICA 3: REPRODUCIBLE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def create_reproducible_benchmark(self):
        """
        MISMOS RESULTADOS cada vez que ejecuto

        Requisitos:
        1. Fijar random seed
        2. Documentar exactamente las pruebas
        3. Usar datos pÃºblicos o guardados
        """

        import random
        import numpy as np

        # Fijar seeds para reproducibilidad
        random.seed(42)
        np.random.seed(42)

        # Generar benchmark (determinÃ­stico ahora)
        benchmark_cases = []
        for i in range(1000):
            case = {
                'email': f"email_{i}",
                'is_spam': random.choice([True, False])
            }
            benchmark_cases.append(case)

        # PrÃ³xima ejecuciÃ³n con seed=42 darÃ¡ EXACTAMENTE lo mismo
        print("âœ“ Reproducible: Mismos resultados siempre")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CARACTERÃSTICA 4: INTERPRETABLE
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def create_interpretable_benchmark(self):
        """
        FÃ¡cil de entender DÃ“NDE FALLA

        MALO: "Accuracy 92%"
        BUENO:
        """

        results = {
            'overall_accuracy': '92%',
            'breakdown': {
                'legitimate_emails': '98% accuracy',
                'obvious_spam': '99% accuracy',
                'sophisticated_spam': '75% accuracy',  # â† DÃ‰BIL AQUÃ
                'edge_cases': '60% accuracy',          # â† MUY DÃ‰BIL
            },
            'error_analysis': {
                'false_negatives': 15,  # Spam no detectado
                'false_positives': 8,   # LegÃ­timos marcados spam
            }
        }

        print("""
        ANÃLISIS DETALLADO:
        - Muy bueno con spam obvio
        - Malo con spam sofisticado â† MEJORA AQUÃ
        - Muy malo con edge cases â† FOCO FUTURO
        """)

        return results
```

### 2.2 Datasets PÃºblicos

```python
class PublicDatasets:
    """
    Datasets existentes para evaluar agentes
    """

    @staticmethod
    def text_classification():
        """
        CLASIFICACIÃ“N DE TEXTO
        """
        print("""
        Dataset: IMDB
        - 50,000 reviews de pelÃ­culas
        - Etiquetas: Positivo/Negativo
        - Tarea: Sentiment analysis
        - Baseline: 88% accuracy

        Dataset: 20 Newsgroups
        - 18,846 documentos de noticias
        - 20 categorÃ­as
        - Tarea: ClasificaciÃ³n temÃ¡tica
        - Baseline: 75% accuracy
        """)

    @staticmethod
    def question_answering():
        """
        RESPUESTA DE PREGUNTAS
        """
        print("""
        Dataset: SQuAD (Stanford Question Answering Dataset)
        - 100,000+ preguntas sobre Wikipedia
        - Formato: Pregunta + PÃ¡rrafo + Respuesta
        - Tarea: Encontrar respuesta en texto
        - MÃ©trica: F1-score
        - SOTA: 95.5+ F1-score

        Dataset: Natural Questions
        - 300,000 preguntas reales de usuarios
        - MÃºltiples pÃ¡rrafos candidatos
        - Tarea: Ranking de pÃ¡rrafos
        """)

    @staticmethod
    def dialogue_systems():
        """
        SISTEMAS DE DIÃLOGO
        """
        print("""
        Dataset: BLEU scores
        - Para evaluar traducciÃ³n/parÃ¡frasis
        - Compara contra referencias
        - Rango: 0-100 (100 = perfecto)

        Dataset: ROUGE scores
        - Para resÃºmenes
        - Overlap de palabras vs referencia

        Dataset: Human Evaluation
        - Lo mejor: Personas califican respuestas
        - Caro pero definitivo
        """)
```

---

## <a name="mÃ³dulo-3"></a>MÃ³dulo 3: Testing Funcional

### 3.1 Unit Tests para Agentes

```python
import unittest

class AgentTests(unittest.TestCase):
    """
    TESTING de componentes individuales del agente
    """

    def setUp(self):
        """PreparaciÃ³n antes de cada test"""
        self.agent = SimpleAgent(name="TestAgent")

    def test_perception_works(self):
        """
        TEST: Â¿Percibe correctamente?
        """
        environment = {'temperature': 25, 'light': 100}

        percepts = self.agent.perceive(environment)

        # Asegurarse que percibiÃ³
        self.assertIn('temperature', percepts)
        self.assertEqual(percepts['temperature'], 25)

    def test_reasoning_with_data(self):
        """
        TEST: Â¿Razona correctamente?
        """
        test_data = {'temperature': 30}

        decision = self.agent.reason(test_data)

        # Si temperatura > 28, deberÃ­a decidir enfriar
        self.assertEqual(decision, 'cool_down')

    def test_action_execution(self):
        """
        TEST: Â¿Ejecuta acciones correctamente?
        """
        # Si decide enfriar, deberÃ­a activar AC
        result = self.agent.act('cool_down')

        self.assertTrue(result['success'])
        self.assertEqual(result['action'], 'ac_on')

    def test_state_updates(self):
        """
        TEST: Â¿Actualiza estado correctamente?
        """
        initial_state = self.agent.state.copy()

        # Ejecutar una acciÃ³n
        self.agent.step({'temperature': 30})

        # Estado deberÃ­a cambiar
        self.assertNotEqual(self.agent.state, initial_state)


class MultiAgentTests(unittest.TestCase):
    """
    TESTING de interacciÃ³n entre agentes
    """

    def test_communication_delivery(self):
        """
        TEST: Â¿Se entregan mensajes?
        """
        agentA = Agent('A')
        agentB = Agent('B')

        # A envÃ­a mensaje a B
        message = {'content': 'Hello', 'to': 'B'}
        agentA.send(message)

        # B deberÃ­a recibir
        received = agentB.inbox.get_nowait()
        self.assertEqual(received['content'], 'Hello')

    def test_coordination_protocol(self):
        """
        TEST: Â¿Protocolo de coordinaciÃ³n funciona?
        """
        # Dos agentes deben coordinar acceso a recurso
        resource = SharedResource()
        agentA = Agent('A')
        agentB = Agent('B')

        # A adquiere recurso
        success_a = agentA.acquire(resource)
        self.assertTrue(success_a)

        # B no deberÃ­a poder adquirir (A lo tiene)
        success_b = agentB.acquire(resource, timeout=1)
        self.assertFalse(success_b)

        # A libera
        agentA.release(resource)

        # Ahora B deberÃ­a poder adquirir
        success_b = agentB.acquire(resource)
        self.assertTrue(success_b)


# Ejecutar tests:
# python -m unittest discover
```

### 3.2 Integration Tests

```python
class IntegrationTests(unittest.TestCase):
    """
    TESTING de TODO el sistema junto
    """

    def setUp(self):
        """Crear sistema completo"""
        self.system = MultiAgentSystem()
        self.system.add_agent(ProducerAgent('P1'))
        self.system.add_agent(ConsumerAgent('C1'))

    def test_end_to_end_transaction(self):
        """
        TEST: Â¿Flujo completo funciona?

        Escenario: Productor crea item, consumidor lo consume
        """
        # Productor crea item
        item = self.system.agents['P1'].produce('data')
        self.assertIsNotNone(item)

        # Sistema distribuye
        self.system.distribute()

        # Consumidor recibiÃ³
        self.assertTrue(self.system.agents['C1'].has_item(item))

    def test_fault_tolerance(self):
        """
        TEST: Â¿Sistema tolera fallos?
        """
        # Sistema funciona inicialmente
        result1 = self.system.process()
        self.assertTrue(result1)

        # Simular fallo de un agente
        self.system.agents['P1'].fail()

        # Sistema continÃºa (otros agentes trabajan)
        result2 = self.system.process()
        # DeberÃ­a funcionar parcialmente
        self.assertTrue(result2 or len(self.system.agents) > 1)
```

---

## <a name="mÃ³dulo-4"></a>MÃ³dulo 4: Debugging y Monitoreo

### 4.1 Logging EstratÃ©gico

```python
import logging
from datetime import datetime

class AgentLogger:
    """
    LOGGING para entender QUÃ‰ HACE el agente
    """

    def __init__(self, agent_name):
        self.agent_name = agent_name
        self.logger = logging.getLogger(agent_name)

    def log_perception(self, percepts):
        """Log: QuÃ© percibiÃ³"""
        self.logger.info(f"PERCEPTS: {percepts}")

    def log_decision(self, decision, reasoning):
        """Log: QuÃ© decidiÃ³ y por quÃ©"""
        self.logger.info(f"DECISION: {decision} (reason: {reasoning})")

    def log_action(self, action, result):
        """Log: QuÃ© hizo y resultado"""
        self.logger.info(f"ACTION: {action} â†’ {result}")

    def log_error(self, error, context):
        """Log: Errores con contexto"""
        self.logger.error(f"ERROR: {error} in {context}")

    # Ejemplo de uso:
    def example(self):
        """
        Logs de una sesiÃ³n tÃ­pica:

        INFO: PERCEPTS: {'temp': 25, 'light': 100}
        INFO: DECISION: cool_down (reason: temp > 24)
        INFO: ACTION: turn_on_ac â†’ success
        ERROR: CONNECTION_TIMEOUT to AgentB in coordination_step
        """
        pass


# Configurar logging
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('agent.log'),  # Guardar en archivo
        logging.StreamHandler()             # TambiÃ©n en consola
    ]
)

# ANÃLISIS DE LOGS:
print("""
CUÃNDO REVISAR LOGS:

1. Comportamiento extraÃ±o:
   "Â¿Por quÃ© el agente hizo X?"
   â†’ Revisar DECISION logs

2. Rendimiento lento:
   "Â¿Por quÃ© tarda tanto?"
   â†’ Revisar timestamps entre eventos

3. Error intermitente:
   "Â¿CuÃ¡ndo falla exactamente?"
   â†’ Buscar ERROR logs cercanos

4. DecisiÃ³n incorrecta:
   "Â¿CÃ³mo llegÃ³ a esa conclusiÃ³n?"
   â†’ Ver PERCEPTS â†’ DECISION chain
""")
```

### 4.2 Monitoreo en ProducciÃ³n

```python
class ProductionMonitoring:
    """
    MONITOREO DE AGENTE EN PRODUCCIÃ“N
    """

    def __init__(self, agent_name):
        self.agent_name = agent_name
        self.metrics = {
            'requests_total': 0,
            'requests_success': 0,
            'requests_error': 0,
            'avg_latency': 0,
            'last_error': None,
            'uptime': 0
        }

    def track_request(self, success, latency, error=None):
        """Rastrear cada request"""
        self.metrics['requests_total'] += 1

        if success:
            self.metrics['requests_success'] += 1
        else:
            self.metrics['requests_error'] += 1
            self.metrics['last_error'] = error

        # Actualizar latency promedio
        old_avg = self.metrics['avg_latency']
        self.metrics['avg_latency'] = (
            (old_avg * (self.metrics['requests_total'] - 1) + latency) /
            self.metrics['requests_total']
        )

    def alert_if_threshold_exceeded(self):
        """Alerta si mÃ©tricas salen de control"""

        alerts = []

        # Error rate > 1%
        error_rate = (self.metrics['requests_error'] /
                      self.metrics['requests_total'] * 100)
        if error_rate > 1:
            alerts.append(f"âš ï¸  Error rate {error_rate:.1f}% (umbral: 1%)")

        # Latency > 500ms
        if self.metrics['avg_latency'] > 500:
            alerts.append(f"âš ï¸  Latency {self.metrics['avg_latency']:.0f}ms "
                         f"(umbral: 500ms)")

        # No responde en 10 minutos
        # ...

        return alerts

    def generate_report(self):
        """Generar reporte de salud"""
        print(f"""
        HEALTH REPORT: {self.agent_name}
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        Total requests: {self.metrics['requests_total']}
        Success: {self.metrics['requests_success']} âœ“
        Errors: {self.metrics['requests_error']} âœ—
        Error rate: {self.metrics['requests_error']/self.metrics['requests_total']*100:.2f}%
        Avg latency: {self.metrics['avg_latency']:.0f}ms
        Last error: {self.metrics['last_error']}
        â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        Alerts: {self.alert_if_threshold_exceeded() or 'None'}
        """)
```

---

## Resumen Completo

```
EVALUACIÃ“N Y TESTING = Verificar que agente funciona como se espera

NIVELES:

1. MÃ‰TRICAS
   â†’ Cuantificar desempeÃ±o
   â†’ Ejemplos: Accuracy, Latency, Error rate

2. TESTS
   â†’ Automatizar verificaciÃ³n
   â†’ Unit tests, Integration tests

3. BENCHMARKS
   â†’ Comparar mÃºltiples agentes
   â†’ Conjunto de pruebas estÃ¡ndar

4. MONITOREO
   â†’ Vigilar en producciÃ³n
   â†’ Alertas si algo falla

TODO JUNTO = CONFIANZA EN AGENTE
```

